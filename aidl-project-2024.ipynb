{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eBHSisFoq68z"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader,TensorDataset\n","\n","import math\n","import numpy as np\n","#import seaborn as sns\n","import matplotlib.pylab as plt\n","\n","#Especifico para el gym+dataset \"D4RL_Pybullet\"\n","import gym\n","import d4rl_pybullet\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"slKJSnX_u_gt"},"source":["## Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbZahVUHu4Nq"},"outputs":[],"source":["model_cfg = {\n","    \"state_dim\": 4*30,\n","    \"act_dim\": 30 , # act_dim=Contextlength?\n","    \"ffn_dim\": 12,  #FeedForwardNetwork Dimension\n","    \"embed_dim\": 128,\n","    \"num_heads\": 16,\n","    \"num_blocks\": 1,\n","    \"max_timesteps\": 4096,\n","    \"mlp_ratio\": 4,\n","    \"dropout\": 0.1,\n","    \"vocab_size\": 4,\n","    \"rtg_dim\": 1\n","\n","}"]},{"cell_type":"markdown","metadata":{"id":"Ve3rd14BrRV_"},"source":["## Masked Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPFpaUDnrOVV"},"outputs":[],"source":["class MaskedSelfAttention(nn.Module):\n","\n","    def __init__(self, embed_dim, num_heads, seq_len, dropout):\n","        super().__init__()\n","\n","        self.embed_dim = embed_dim # embeding dimensionality, includes all heads\n","        self.num_heads = num_heads #  num heads\n","        assert self.embed_dim % self.num_heads == 0 , \\\n","            \"Embedding dimension must be multiple of the number of heads.\"\n","\n","        self.seq_len = seq_len\n","\n","        # key, query, value projections\n","        self.proj_q = nn.Linear(embed_dim, embed_dim)\n","        self.proj_k = nn.Linear(embed_dim, embed_dim)\n","        self.proj_v = nn.Linear(embed_dim, embed_dim)\n","\n","        # output projection\n","        self.proj_out = nn.Linear(self.embed_dim, self.embed_dim)\n","        # regularization\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.resid_dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B, T, C = x.shape # batch size, sequence length, embedding dimensionality (embed_dim)\n","        #head_size = self.num_heads, C // self.num_heads\n","\n","        # calculate query, key, values\n","        q = self.proj_q(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","        k = self.proj_k(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","        v = self.proj_v(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","\n","        # causal self-attention; Self-attend: (B, numHeads, seqLen, headSize) x (B, numHeads, headSize, seqLen) -> (B, numHeads, seqLen, seqLen)\n","        # scaled_dot_product\n","        attn_logits = (q @ k.transpose(-2, -1))\n","        attn_logits = attn_logits / torch.sqrt(torch.tensor(k.size(-1)))\n","        # apply mask\n","\n","        mask = torch.zeros(x.shape[1], x.shape[0]).bool() #toDevice\n","        subsequent_mask = torch.triu(torch.ones(B, T, T), 1).bool() #toDevice\n","        selfattn_mask = subsequent_mask + mask.unsqueeze(-2)\n","        attn_logits = attn_logits.masked_fill(selfattn_mask, float('-inf'))\n","\n","        softmax = nn.Softmax(dim=-1)\n","        attention = softmax(attn_logits)\n","\n","        attention = attention @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        out = self.attn_dropout(attention)\n","\n","        out = out.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n","\n","        # output projection\n","        y = self.resid_dropout(self.proj_out(out))\n","        return y"]},{"cell_type":"markdown","metadata":{"id":"wmU9xYierVZH"},"source":["## MLP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUTPd1LCrVwz"},"outputs":[],"source":["class MLP(nn.Module):\n","\n","    def __init__(self, embed_dim, ffn_dim, dropout):\n","        super().__init__()\n","        self.fc1 = nn.Linear(embed_dim, ffn_dim)\n","        self.act = nn.GELU()\n","        self.fc2 = nn.Linear(ffn_dim, embed_dim)\n","        self.drop= nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        x = self.act(self.fc1(x))\n","        x = self.drop(self.fc2(x))\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"2jeC6poirbbz"},"source":["## Decoder block"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9GpR2yhrbxr"},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","\n","    def __init__(self, embed_dim, num_heads, seq_len, mlp_ratio, dropout):\n","        super().__init__()\n","\n","        self.attn = MaskedSelfAttention(embed_dim, num_heads, seq_len, dropout)\n","        self.ln1 = nn.LayerNorm(embed_dim)\n","        self.mlp = MLP(embed_dim, int(embed_dim * mlp_ratio),dropout)\n","        self.ln_2 = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","        x = self.ln1(x) # normalize\n","        x = self.attn(x) + x # add residual\n","        x = self.ln2(x)\n","        x = self.mlp(x) + x\n","\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"LNPb3mxWrj1Z"},"source":["## Decision Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dxv3FQCMri-q"},"outputs":[],"source":["class DecisionTransformer(nn.Module):\n","    def __init__(self, state_dim, act_dim, ffn_dim, embed_dim, num_heads, num_blocks, max_timesteps, mlp_ratio, dropout, vocab_size, rtg_dim=1):\n","        super().__init__()\n","\n","        self.ffn_dim = ffn_dim   #NÂº de Layers \"nn.Linear\" ~~ \"ffn_dim\"\n","        self.seq_len = act_dim   # Omar/Shuang-> Provisional, revisar esta linea.\n","        # Construct embedding layer\n","        self.state_embed = nn.Linear(in_features=state_dim, out_features=ffn_dim)\n","        self.act_embed = nn.Linear(in_features=act_dim, out_features=ffn_dim)\n","        self.rtg_embed = nn.Linear(in_features=rtg_dim, out_features=ffn_dim)\n","        self.pos_embed = nn.Embedding(num_embeddings=max_timesteps, embedding_dim=ffn_dim)\n","\n","        self.norm = nn.LayerNorm(ffn_dim)\n","\n","        #TODO: Complete Basic Transformer parameters\n","        self.transformerGPT = nn.ModuleList([DecoderBlock(embed_dim, num_heads, self.seq_len, mlp_ratio, dropout) for _ in range(num_blocks)])\n","\n","        self.rtg_pred = nn.Linear(in_features=ffn_dim, out_features=1)\n","        self.state_pred = nn.Linear(in_features=ffn_dim, out_features=state_dim)\n","        self.act_pred = nn.Sequential(\n","            nn.Linear(ffn_dim, act_dim),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, timestep, max_timesteps, states, actions, returns_to_go):\n","\n","        B, T, _ = states.shape # [batch size, seq length, embed_dim]\n","\n","        pos_embedding = self.pos_embed(max_timesteps, timestep)\n","\n","        state_embedding = self.state_embed(states)\n","        act_embedding = self.act_embed(actions)\n","        rtg_embedding = self.rtg_embed(returns_to_go)\n","\n","        state_embedding += pos_embedding\n","        act_embedding += pos_embedding\n","        returns_to_go += pos_embedding\n","\n","        # (R{1}, S{1}, A{1}, ..., R{i}, S{i}, A{i}, ..., R{n}, S{n}, A{n}) | 1 < i < n\n","        stacked_inputs = torch.stack((rtg_embedding, state_embedding, act_embedding), dim=1) # [B, rtg_dim, state_dim, act_dim]\n","        stacked_inputs = stacked_inputs.permute(0, 2, 1, 3) #[B, state_dim, rtg_dim, act_dim]\n","        stacked_inputs = stacked_inputs.reshape(B, 3*T, self.ffn_dim) # [B, 3*T, hidden_size]  Nota: ffn_dim a.k.a \"hidden_size\"\n","\n","        x = self.norm(stacked_inputs)\n","\n","        #TODO: Complete Basic Transformer\n","        out = self.transformerGPT(x)\n","        out = out.reshape(B, T, 3, self.ffn_dim).permute(0, 2, 1, 3)  #[B, T, 3, hidden_size] --> [B, 3, T, hidden_size]     Nota: ffn_dim a.k.a \"hidden_size\"\n","\n","        returns_to_go_preds = self.rtg_pred(out[:,2])     # predict next return given state and action [0 state, 1 action, 2 rtg]\n","        state_preds = self.state_pred(out[:,2])           # predict next state given state and action  [0, 1, 2 rtg]\n","        act_preds = self.act_pred(out[:,1])               # predict next action given state            [0, 1, 2]\n","\n","        return returns_to_go, state_preds, act_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfPJEc6x44D3"},"outputs":[],"source":["#Creamos instancia decision transformer con nuestra config\n","model_dt = DecisionTransformer(**model_cfg)\n","model_dt"]},{"cell_type":"markdown","metadata":{"id":"2NApHsQGt2bw"},"source":["## DataSet\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2695,"status":"ok","timestamp":1707244731722,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"FVJsd0cKb_FT","outputId":"f8abb7b0-9f00-4e9e-8d0a-f8cd1eb0e3e8"},"outputs":[],"source":["#Source:  https://github.com/takuseno/d4rl-pybullet\n","\n","# dataset will be automatically downloaded into ~/.d4rl/datasets\n","env = gym.make('hopper-bullet-medium-v0')\n","\n","# interaction with its environment\n","dataset = env.get_dataset()\n","\n","#Hacemos print de Observations/Actions/Rewards/Terminals\n","print(\"\\n Observations:\", dataset['observations'][0]) # observation data in N x dim_observation. O.Aguilera: Mostramos la Observation en el timestep \"num_timestep\" ->[num_timestep]\n","print(\"\\n Actions:\", dataset['actions'][0]) # action data in N x dim_action. O.Aguilera: Mostramos la Action en el timestep \"num_timestep\" ->[num_timestep]\n","print(\"\\n Rewards:\", dataset['rewards'][0]) # reward data in N x 1. O.Aguilera: Mostramos la Rewards \"num_timestep\" ->[num_timestep]\n","print(\"\\n Terminals:\", dataset['terminals'][0]) # terminal flags in N x 1. O.Aguilera: Mostramos la Terminals \"num_timestep\" ->[num_timestep]. Indica si ha terminat l'episodi (Todo FALSE menos ultimo TRUE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707249331205,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"B4QqwPe_-ckc","outputId":"6f4eec90-4651-46d7-bb3e-3e9cec42c661"},"outputs":[],"source":["tensorObs = torch.tensor(dataset['observations'][0])\n","tensorAct = torch.tensor(dataset['actions'][0])\n","tensorRew = torch.tensor(dataset['rewards'][0])\n","tensorTerm = torch.tensor(dataset['terminals'])\n","tensorObs,tensorAct,tensorRew, tensorTerm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Contamos los episodios para el dataset importado\n","def _get_num_episodes():\n","  terminals = dataset['terminals'].astype('int32')\n","  #Las posiciones donde estan los Terminal=1\n","  if terminals[-1] == 0 : \n","    terminals[-1] = 1  \n","  terminal_pos = np.where(terminals==1)[0]\n","  return len(terminal_pos),  terminal_pos.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x, y = _get_num_episodes()\n","print('NUM EPISODED: ', x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_rtgs(t_positions, rewards):\n","    # Initialize the starting index of the sub-list in B\n","    start_idx = 0\n","    rtgs = []\n","\n","    \n","    for t in t_positions:\n","        end_idx = t + 1\n","        sub_list = rewards[start_idx:end_idx]\n","        #print(sub_list)\n","        for i in range(0, len(sub_list)):\n","            rtgs.append(sum(sub_list[i+1:]))\n","        start_idx = end_idx\n","    return rtgs\n","\n","def optimized_get_rtgs(t_positions, rewards):\n","\n","    rewards = np.array(rewards, dtype=np.float64)\n","    t_positions = np.array(t_positions)\n","\n","    cumsum_rewards = np.cumsum(rewards)\n","    \n","    # Initialize an array to hold the RTGs\n","    rtgs = np.array([], dtype=int)\n","    \n","    # Keep track of the start index of the sub-list in rewards\n","    start_idx = 0\n","    for end_idx in t_positions:\n","        \n","        segment_rtgs = cumsum_rewards[end_idx] - cumsum_rewards[start_idx:end_idx]\n","        segment_rtgs = np.append(segment_rtgs, 0)\n","        rtgs = np.concatenate((rtgs, segment_rtgs))\n","    \n","        start_idx = end_idx+1\n","    return rtgs.tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rewards = dataset['rewards']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["og_rtgs = calculate_rtg(y, rewards)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optimized_rtgs = optimized_function(y, rowa)ldd = len(_rtgs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Mostramos los maximos rewards para los Terminal=1 recogidos en \"terminal_pos\"\n","\n","sample=terminal_pos[0]\n","print(\"\\nRewards example:\",arrayRewards[sample])\n","\n","#Construimos el array de rewards to go\n","arrayReturnToGo = []\n","\n","for i in terminal_pos:\n","    arrayReturnToGo.append(arrayRewards[i])\n","\n","len(arrayReturnToGo)\n","\n","#Creamos tensor de Returnstogo\n","tensorReturnToGo = torch.FloatTensor(arrayReturnToGo)\n","tensorReturnToGo.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos un array \"timesteps\" donde se identificaran los timesteps para cada episodio respecto al total del dataset\n","start_index = 0\n","arrayTimesteps = np.zeros(len(arrayActions), dtype=int)\n","for i in terminal_pos:\n","    arrayTimesteps[start_index:i] = np.arange(i - start_index)\n","    start_index = i\n","print(\"\\nEl array Timesteps tendra la misma dimension que las samples del dataset:\",len(arrayTimesteps),\" samples\")\n","print(\"\\nEjemplo muestreo hasta el episodio 25:\\n\", arrayTimesteps[0:25])\n","\n","#Comprovamos en el dataset (concretamente en el arrayTimesteps), cual es el episodio mas largo. Ese sera nuestro \"max_timesteps\"\n","max_timesteps = max(arrayTimesteps)\n","print(\"\\nEl episodio con mayor numero de timesteps de nuestro dataset durÃ³ un total de\",max_timesteps,\"timesteps\")\n","\n","#Lo convertimos a tensor\n","tensorTimesteps = torch.FloatTensor(arrayTimesteps)\n","#tensorTimesteps.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prueba_omar = np.unique(arrayActions[0:20])\n","print('action possible numbers: ',prueba_omar )\n","#assert hparams['vocab_size'] == len(np.unique(arrayActions))\n","len(prueba_omar)\n","\n","arrayActions[0:20]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#We transform all the arrays to Float tensors\n","if torch.cuda.is_available():\n","  tensorObservations = torch.cuda.FloatTensor(arrayObservations)\n","  tensorActions = torch.cuda.FloatTensor(arrayActions)\n","  tensorRewards = torch.cuda.FloatTensor(arrayRewards)\n","  tensorTerminals = torch.cuda.FloatTensor(arrayTerminals)\n","  print(\"\\n Tensors in the GPU\")\n","  print(\"\\n////////////////////////////////////////////////////////////////////////////////\")\n","else:\n","  tensorObservations = torch.FloatTensor(arrayObservations)\n","  tensorActions = torch.FloatTensor(arrayActions)\n","  tensorRewards = torch.FloatTensor(arrayRewards)\n","  tensorTerminals = torch.FloatTensor(arrayTerminals)\n","  print(\"\\n Tensors in the CPU\")\n","\n","# Tensors shape\n","print(\"\\nObservations shape:\",tensorObservations.shape)\n","print(\"\\nActions shape:\",tensorActions.shape)\n","print(\"\\nRewards shape:\",tensorRewards.shape)\n","print(\"\\nTerminals shape:\",tensorTerminals.shape)\n","print(\"\\n////////////////////////////////////////////////////////////////////////////////\")\n","\n","sample = 59343\n","# Tensors content at certain timestep\n","print(\"\\nObservations example:\",tensorObservations[sample])\n","print(\"\\nActions example:\",tensorActions[sample])\n","print(\"\\nRewards example:\",tensorRewards[sample])\n","print(\"\\nTerminals example:\",tensorTerminals[sample])"]},{"cell_type":"markdown","metadata":{"id":"ZfbaABN2gpMP"},"source":["# Pasar este dataset al DT (Shuang/Omar)!!!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4476,"status":"ok","timestamp":1707075864981,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"9X78mWt6iwIR","outputId":"a1025993-822d-4118-834a-29fe7e38aca3"},"outputs":[],"source":["#Source: PyBullet Environment: https://pybullet.org/wordpress/\n","#                              https://github.com/bulletphysics/bullet3/tree/master\n","\n","import numpy as np\n","import gym\n","import pybullet_envs\n","import argparse\n","import os\n","import torch\n","\n","from tqdm import tqdm\n","#from .sac import SAC, seed_everything\n","#from .utility import save_buffer\n","\n","\n","def collect(env, sac, logdir, final_step, deterministic):\n","    buffer = []\n","    frames = []\n","\n","    step = 0\n","    pbar = tqdm(total=final_step)\n","    while step < final_step:\n","        obs_t = env.reset()\n","        ter_t = False\n","        rew_t = 0.0\n","\n","\n","        while step < final_step and not ter_t:\n","            #act_t = sac.act([obs_t], deterministic=deterministic)[0] #SAC (Soft Actor Critic) es un algoritmo de RL\n","            frames.append(env.render(mode=\"rgb_array\"))\n","            act_t = env.action_space.sample() # Temporal. Aqui tendriamos que la salida/action del DT.\n","            buffer.append([obs_t, act_t, [rew_t], [ter_t]])\n","\n","            obs_t, rew_t, ter_t, _ = env.step(act_t)   #O.Aguilera (04/02/2024): La dimensio no es correcte.\n","\n","            step += 1\n","            pbar.update(1)\n","\n","        if ter_t:\n","            buffer.append([obs_t, np.zeros_like(act_t), [rew_t], [ter_t]])\n","\n","    #save_buffer(buffer[:final_step], logdir)\n","\n","    print('Collected data has been saved.')\n","    return frames\n","\n","''' if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--env', type=str)\n","    parser.add_argument('--seed', type=int, default=0)\n","    parser.add_argument('--final-step', type=int, default=1000000) #\n","    parser.add_argument('--load', type=str)\n","    parser.add_argument('--gpu', action='store_true')\n","    args = parser.parse_args() '''\n","\n","#env = gym.make(args.env)\n","env = gym.make('hopper-bullet-mixed-v0')\n","#env.seed(args.seed)\n","env.seed(1)\n","#seed_everything(args.seed)\n","#seed_everything(1)\n","\n","observation_size = env.observation_space.shape[0]\n","action_size = env.action_space.shape[0]\n","device = 'cuda:0'\n","\n","#sac = SAC(observation_size, action_size, device)\n","'''\n","if args.load:\n","    sac.load(args.load)\n","    name = 'medium'\n","    deterministic = True\n","else:'''\n","name = 'random'\n","deterministic = False\n","\n","#logdir = os.path.join('logs', '{}_{}_{}'.format(args.env, name, args.seed))\n","#os.makedirs(logdir)\n","\n","\n","prova=collect(env, None, None, 100, deterministic)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1707075893010,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"5ZZdymFuo-CM","outputId":"63bc8868-19a7-4e82-bbda-8b6448e3cac2"},"outputs":[],"source":["prova[0]\n","prova[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":2268,"status":"ok","timestamp":1707075967418,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"0qz16feApxN-","outputId":"8ecd95c7-f127-463b-918e-2d7b7a0f144b"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","plt.imshow(prova[0], interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793},"executionInfo":{"elapsed":13985,"status":"ok","timestamp":1707076061860,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"hWjXpRikoxHC","outputId":"d4c4a8f8-df3d-4f22-ec96-2754eeef1197"},"outputs":[],"source":["!apt-get install ffmpeg\n","!pip install notebook-video-writer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":17,"status":"error","timestamp":1707242998732,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"cO_CMXRVqdUd","outputId":"d04f2456-fd48-465c-e041-c33bd1401157"},"outputs":[],"source":["from notebook_video_writer import VideoWriter\n","with VideoWriter(fps=40) as vw:\n","    for i in range(len(prova)):\n","        vw.add(prova[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1707076908060,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"87dKrBuaoJFq","outputId":"c3495c99-361a-4c49-b51f-3b9862b31903"},"outputs":[],"source":["env = gym.make('hopper-bullet-mixed-v0')\n","print(env.action_space.sample())"]},{"cell_type":"markdown","metadata":{"id":"Na1sduHdtoOe"},"source":["## Notas Google Meet Domingo 04/02/2024\n","\n","\n","Edgar Planell\n","19:33\n","https://github.com/takuseno/d4rl-pybullet/blob/master/requirements.txt\n","\n","Edgar Planell\n","19:37\n","pip install git+https://github.com/takuseno/d4rl-pybullet\n","\n","Edgar Planell\n","19:59\n","pip setuptools wheel\n","\n","TÃº\n","19:59\n","brew install hdf5\n","\n","Edgar Planell\n","20:01\n","versioned-hdf5\n","\n","Edgar Planell\n","20:13\n","    import numpy as np\n","    import gym\n","    import pybullet_envs\n","    import argparse\n","    import os\n","\n","    from tqdm import tqdm\n","    from .sac import SAC, seed_everything\n","    from .utility import save_buffer\n","\n","\n","    def collect(env, sac, logdir, final_step, deterministic):\n","        buffer = []\n","\n","        step = 0\n","        pbar = tqdm(total=final_step)\n","        while step < final_step:\n","            obs_t = env.reset()\n","            ter_t = False\n","            rew_t = 0.0\n","            while step < final_step and not ter_t:\n","                act_t = sac.act([obs_t], deterministic=determin\n","\n","      import numpy as np\n","      import gym\n","      import pybullet_envs\n","      import argparse\n","      import os\n","\n","      from tqdm import tqdm\n","      from .sac import SAC, seed_everything\n","      from .utility import save_buffer\n","\n","\n","      def collect(env, sac, logdir, final_step, deterministic):\n","          buffer = []\n","\n","          step = 0\n","          pbar = tqdm(total=final_step)\n","          while step < final_step:\n","              obs_t = env.reset()\n","              ter_t = False\n","              rew_t = 0.0\n","              while step < final_step and not ter_t:\n","                  act_t = sac.act([obs_t], deterministic=determin\n","https://github.com/takuseno/d4rl-pybullet/blob/master/d4rl_pybullet/collect.py\n","\n","Edgar Planell\n","20:30\n","https://github.com/bulletphysics/bullet3/tree/master\n","\n","Edgar Planell\n","20:32\n","https://github.com/bulletphysics/bullet3/blob/master/examples/pybullet/gym/pybullet_examples/biped2d_pybullet.py\n","\n","Edgar Planell\n","20:37\n","https://github.com/benelot/pybullet-gym/tree/master\n","\n","Josep Maria Bach RamÃ­rez\n","20:43\n","env.render(mode=\"rgb_array\")\n","\n","Josep Maria Bach RamÃ­rez\n","20:45\n","from matplotlib import pyplot as plt\n","plt.imshow(prova[0], interpolation='nearest')\n","plt.show()\n","\n","Josep Maria Bach RamÃ­rez\n","20:47\n","!apt-get install ffmpeg\n","!pip install notebook-video-writer\n","\n","Josep Maria Bach RamÃ­rez\n","20:48\n","from notebook_video_writer import VideoWriter\n","with VideoWriter(fps=40) as vw:\n","    for i in range(len(prova)):\n","        vw.add(prova[i])\n","        \n","Josep Maria Bach RamÃ­rez\n","20:52\n","https://gymnasium.farama.org/api/env/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Og2T3r8m_YR"},"outputs":[],"source":["''' import pybullet as p\n","import pybullet_data\n","import os\n","import time\n","GRAVITY = -9.8\n","dt = 1e-3\n","iters = 2000\n","import pybullet_data\n","\n","physicsClient = p.connect(p.GUI)\n","p.setAdditionalSearchPath(pybullet_data.getDataPath())\n","p.resetSimulation()\n","#p.setRealTimeSimulation(True)\n","p.setGravity(0, 0, GRAVITY)\n","p.setTimeStep(dt)\n","planeId = p.loadURDF(\"plane.urdf\")\n","cubeStartPos = [0, 0, 1.13]\n","cubeStartOrientation = p.getQuaternionFromEuler([0., 0, 0])\n","botId = p.loadURDF(\"biped/biped2d_pybullet.urdf\", cubeStartPos, cubeStartOrientation)\n","\n","#disable the default velocity motors\n","#and set some position control with small force to emulate joint friction/return to a rest pose\n","jointFrictionForce = 1\n","for joint in range(p.getNumJoints(botId)):\n","  p.setJointMotorControl2(botId, joint, p.POSITION_CONTROL, force=jointFrictionForce)\n","\n","#for i in range(10000):\n","#     p.setJointMotorControl2(botId, 1, p.TORQUE_CONTROL, force=1098.0)\n","#     p.stepSimulation()\n","#import ipdb\n","#ipdb.set_trace()\n","import time\n","p.setRealTimeSimulation(1)\n","while (1):\n","  #p.stepSimulation()\n","  #p.setJointMotorControl2(botId, 1, p.TORQUE_CONTROL, force=1098.0)\n","  p.setGravity(0, 0, GRAVITY)\n","  time.sleep(1 / 240.)\n","time.sleep(1000) '''"]}],"metadata":{"colab":{"provenance":[{"file_id":"11OpZevRdnWN9dDLwj3OdXT2sDwBwxJec","timestamp":1707249437132}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
