{"cells":[{"cell_type":"code","execution_count":139,"metadata":{"id":"eBHSisFoq68z"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader,TensorDataset\n","\n","import math\n","import numpy as np\n","#import seaborn as sns\n","import matplotlib.pylab as plt\n","\n","#Especifico para el gym+dataset \"D4RL_Pybullet\"\n","import gym\n","import d4rl_pybullet\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"slKJSnX_u_gt"},"source":["## Config"]},{"cell_type":"code","execution_count":140,"metadata":{"id":"fbZahVUHu4Nq"},"outputs":[],"source":["model_cfg = {\n","    \"state_dim\": 4*30,\n","    \"act_dim\": 30 , # act_dim=Contextlength?\n","    \"ffn_dim\": 12,  #FeedForwardNetwork Dimension\n","    \"embed_dim\": 128,\n","    \"num_heads\": 16,\n","    \"num_blocks\": 1,\n","    \"max_timesteps\": 4096,\n","    \"mlp_ratio\": 4,\n","    \"dropout\": 0.1,\n","    \"vocab_size\": 4,\n","    \"rtg_dim\": 1\n","\n","}"]},{"cell_type":"markdown","metadata":{"id":"Ve3rd14BrRV_"},"source":["## Masked Attention"]},{"cell_type":"code","execution_count":141,"metadata":{"id":"pPFpaUDnrOVV"},"outputs":[],"source":["class MaskedSelfAttention(nn.Module):\n","\n","    def __init__(self, embed_dim, num_heads, seq_len, dropout):\n","        super().__init__()\n","\n","        self.embed_dim = embed_dim # embeding dimensionality, includes all heads\n","        self.num_heads = num_heads #  num heads\n","        assert self.embed_dim % self.num_heads == 0 , \\\n","            \"Embedding dimension must be multiple of the number of heads.\"\n","\n","        self.seq_len = seq_len\n","\n","        # key, query, value projections\n","        self.proj_q = nn.Linear(embed_dim, embed_dim)\n","        self.proj_k = nn.Linear(embed_dim, embed_dim)\n","        self.proj_v = nn.Linear(embed_dim, embed_dim)\n","\n","        # output projection\n","        self.proj_out = nn.Linear(self.embed_dim, self.embed_dim)\n","        # regularization\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.resid_dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        print(\"T FORWARD (tocho)\")\n","        B, T, C = x.shape # batch size, sequence length, embedding dimensionality (embed_dim)\n","        #head_size = self.num_heads, C // self.num_heads\n","\n","        # calculate query, key, values\n","        q = self.proj_q(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","        k = self.proj_k(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","        v = self.proj_v(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","\n","        # causal self-attention; Self-attend: (B, numHeads, seqLen, headSize) x (B, numHeads, headSize, seqLen) -> (B, numHeads, seqLen, seqLen)\n","        # scaled_dot_product\n","        attn_logits = (q @ k.transpose(-2, -1))\n","        attn_logits = attn_logits / torch.sqrt(torch.tensor(k.size(-1)))\n","        # apply mask\n","\n","        mask = torch.zeros(x.shape[1], x.shape[0]).bool() #toDevice\n","        subsequent_mask = torch.triu(torch.ones(B, T, T), 1).bool() #toDevice\n","        selfattn_mask = subsequent_mask + mask.unsqueeze(-2)\n","        attn_logits = attn_logits.masked_fill(selfattn_mask, float('-inf'))\n","\n","        softmax = nn.Softmax(dim=-1)\n","        attention = softmax(attn_logits)\n","\n","        attention = attention @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        out = self.attn_dropout(attention)\n","\n","        out = out.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n","\n","        # output projection\n","        y = self.resid_dropout(self.proj_out(out))\n","        return y"]},{"cell_type":"markdown","metadata":{"id":"wmU9xYierVZH"},"source":["## MLP"]},{"cell_type":"code","execution_count":142,"metadata":{"id":"NUTPd1LCrVwz"},"outputs":[],"source":["class MLP(nn.Module):\n","\n","    def __init__(self, embed_dim, ffn_dim, dropout):\n","        super().__init__()\n","        self.fc1 = nn.Linear(embed_dim, ffn_dim)\n","        self.act = nn.GELU()\n","        self.fc2 = nn.Linear(ffn_dim, embed_dim)\n","        self.drop= nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        print(\"MLP FORWARD\")\n","        x = self.act(self.fc1(x))\n","        x = self.drop(self.fc2(x))\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"2jeC6poirbbz"},"source":["## Decoder block"]},{"cell_type":"code","execution_count":143,"metadata":{"id":"v9GpR2yhrbxr"},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","\n","    def __init__(self, embed_dim, num_heads, seq_len, mlp_ratio, dropout):\n","        super().__init__()\n","\n","        self.attn = MaskedSelfAttention(embed_dim, num_heads, seq_len, dropout)\n","        self.ln1 = nn.LayerNorm(embed_dim)\n","        self.mlp = MLP(embed_dim, int(embed_dim * mlp_ratio),dropout)\n","        self.ln_2 = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","        print(\"DECODER BLOCK FORWARD\")\n","        x = self.ln1(x) # normalize\n","        x = self.attn(x) + x # add residual\n","        x = self.ln2(x)\n","        x = self.mlp(x) + x\n","\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"LNPb3mxWrj1Z"},"source":["## Decision Transformer"]},{"cell_type":"code","execution_count":144,"metadata":{"id":"Dxv3FQCMri-q"},"outputs":[],"source":["class DecisionTransformer(nn.Module):\n","    def __init__(self, state_dim, act_dim, ffn_dim, embed_dim, num_heads, num_blocks, max_timesteps, mlp_ratio, dropout, vocab_size, rtg_dim=1):\n","        super().__init__()\n","\n","        self.ffn_dim = ffn_dim   #NÂº de Layers \"nn.Linear\" ~~ \"ffn_dim\"\n","        self.seq_len = act_dim   # Omar/Shuang-> Provisional, revisar esta linea.\n","        # Construct embedding layer\n","        self.state_embed = nn.Linear(in_features=state_dim, out_features=ffn_dim)\n","        self.act_embed = nn.Linear(in_features=act_dim, out_features=ffn_dim)\n","        self.rtg_embed = nn.Linear(in_features=rtg_dim, out_features=ffn_dim)\n","        self.pos_embed = nn.Embedding(num_embeddings=max_timesteps, embedding_dim=ffn_dim)\n","\n","        self.norm = nn.LayerNorm(ffn_dim)\n","\n","        #TODO: Complete Basic Transformer parameters\n","        self.transformerGPT = nn.ModuleList([DecoderBlock(embed_dim, num_heads, self.seq_len, mlp_ratio, dropout) for _ in range(num_blocks)])\n","\n","        self.rtg_pred = nn.Linear(in_features=ffn_dim, out_features=1)\n","        self.state_pred = nn.Linear(in_features=ffn_dim, out_features=state_dim)\n","        self.act_pred = nn.Sequential(\n","            nn.Linear(ffn_dim, act_dim),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, timestep, max_timesteps, states, actions, returns_to_go):\n","        print(\"DT FORWARD\")\n","        print(timestep)\n","        print(max_timesteps)\n","        print(states)\n","        print(actions)\n","        print(returns_to_go)\n","        B, T, _ = states.shape # [batch size, seq length, embed_dim]\n","\n","        pos_embedding = self.pos_embed(max_timesteps, timestep)\n","        print(\"DEBUG 1\")\n","        state_embedding = self.state_embed(states)\n","        act_embedding = self.act_embed(actions)\n","        rtg_embedding = self.rtg_embed(returns_to_go)\n","        print(\"DEBUG 2\")\n","        state_embedding += pos_embedding\n","        act_embedding += pos_embedding\n","        returns_to_go += pos_embedding\n","        print(\"DEBUG 3\")\n","        # (R{1}, S{1}, A{1}, ..., R{i}, S{i}, A{i}, ..., R{n}, S{n}, A{n}) | 1 < i < n\n","        stacked_inputs = torch.stack((rtg_embedding, state_embedding, act_embedding), dim=1) # [B, rtg_dim, state_dim, act_dim]\n","        stacked_inputs = stacked_inputs.permute(0, 2, 1, 3) #[B, state_dim, rtg_dim, act_dim]\n","        stacked_inputs = stacked_inputs.reshape(B, 3*T, self.ffn_dim) # [B, 3*T, hidden_size]  Nota: ffn_dim a.k.a \"hidden_size\"\n","        print(\"DEBUG 4\")\n","        x = self.norm(stacked_inputs)\n","        if torch.is_tensor(x):\n","            print(\"SHAP INPUT TRANSFORMER TOCHO: \", x.shape)\n","        else:\n","            print(\"LEN INPUT T: \", len(x))\n","        print(x)\n","        #TODO: Complete Basic Transformer\n","        out = self.transformerGPT(x)\n","        out = out.reshape(B, T, 3, self.ffn_dim).permute(0, 2, 1, 3)  #[B, T, 3, hidden_size] --> [B, 3, T, hidden_size]     Nota: ffn_dim a.k.a \"hidden_size\"\n","\n","        returns_to_go_preds = self.rtg_pred(out[:,2])     # predict next return given state and action [0 state, 1 action, 2 rtg]\n","        state_preds = self.state_pred(out[:,2])           # predict next state given state and action  [0, 1, 2 rtg]\n","        act_preds = self.act_pred(out[:,1])               # predict next action given state            [0, 1, 2]\n","\n","        return returns_to_go, state_preds, act_preds"]},{"cell_type":"code","execution_count":145,"metadata":{"id":"SfPJEc6x44D3"},"outputs":[{"data":{"text/plain":["DecisionTransformer(\n","  (state_embed): Linear(in_features=120, out_features=12, bias=True)\n","  (act_embed): Linear(in_features=30, out_features=12, bias=True)\n","  (rtg_embed): Linear(in_features=1, out_features=12, bias=True)\n","  (pos_embed): Embedding(4096, 12)\n","  (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n","  (transformerGPT): ModuleList(\n","    (0): DecoderBlock(\n","      (attn): MaskedSelfAttention(\n","        (proj_q): Linear(in_features=128, out_features=128, bias=True)\n","        (proj_k): Linear(in_features=128, out_features=128, bias=True)\n","        (proj_v): Linear(in_features=128, out_features=128, bias=True)\n","        (proj_out): Linear(in_features=128, out_features=128, bias=True)\n","        (attn_dropout): Dropout(p=0.1, inplace=False)\n","        (resid_dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (mlp): MLP(\n","        (fc1): Linear(in_features=128, out_features=512, bias=True)\n","        (act): GELU(approximate='none')\n","        (fc2): Linear(in_features=512, out_features=128, bias=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (rtg_pred): Linear(in_features=12, out_features=1, bias=True)\n","  (state_pred): Linear(in_features=12, out_features=120, bias=True)\n","  (act_pred): Sequential(\n","    (0): Linear(in_features=12, out_features=30, bias=True)\n","    (1): Tanh()\n","  )\n",")"]},"execution_count":145,"metadata":{},"output_type":"execute_result"}],"source":["#Creamos instancia decision transformer con nuestra config\n","model_dt = DecisionTransformer(**model_cfg)\n","model_dt"]},{"cell_type":"markdown","metadata":{"id":"2NApHsQGt2bw"},"source":["## DataSet\n"]},{"cell_type":"code","execution_count":146,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2695,"status":"ok","timestamp":1707244731722,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"FVJsd0cKb_FT","outputId":"f8abb7b0-9f00-4e9e-8d0a-f8cd1eb0e3e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Observations: [ 0.          0.          1.          0.          0.          0.\n","  0.         -0.          0.93191123  0.          1.0711064   0.\n","  0.03378947  0.          0.        ]\n","\n"," Actions: [-0.62974405 -0.26923758  0.07317858]\n","\n"," Rewards: 0.0\n","\n"," Terminals: 0.0\n"]},{"name":"stderr","output_type":"stream","text":["/home/shuanglong/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"]}],"source":["#Source:  https://github.com/takuseno/d4rl-pybullet\n","\n","# dataset will be automatically downloaded into ~/.d4rl/datasets\n","env = gym.make('hopper-bullet-medium-v0')\n","\n","# interaction with its environment\n","dataset = env.get_dataset()\n","\n","#Hacemos print de Observations/Actions/Rewards/Terminals\n","print(\"\\n Observations:\", dataset['observations'][0]) # observation data in N x dim_observation. O.Aguilera: Mostramos la Observation en el timestep \"num_timestep\" ->[num_timestep]\n","print(\"\\n Actions:\", dataset['actions'][0]) # action data in N x dim_action. O.Aguilera: Mostramos la Action en el timestep \"num_timestep\" ->[num_timestep]\n","print(\"\\n Rewards:\", dataset['rewards'][0]) # reward data in N x 1. O.Aguilera: Mostramos la Rewards \"num_timestep\" ->[num_timestep]\n","print(\"\\n Terminals:\", dataset['terminals'][0]) # terminal flags in N x 1. O.Aguilera: Mostramos la Terminals \"num_timestep\" ->[num_timestep]. Indica si ha terminat l'episodi (Todo FALSE menos ultimo TRUE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707249331205,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"B4QqwPe_-ckc","outputId":"6f4eec90-4651-46d7-bb3e-3e9cec42c661"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":147,"metadata":{},"outputs":[],"source":["#Automatically download and return the dataset\n","dataset = env.get_dataset()\n","\n","#We can acces the dataset, and we will obtain Numpy arrays\n","arrayObservations = dataset['observations'] # Observation data in a [N x dim_observation] numpy array  ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 15]\n","arrayActions = dataset['actions'] # Action data in [N x dim_action] numpy array ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 3]\n","arrayRewards = dataset['rewards'] # Reward data in a [N x 1] numpy array ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 1]\n","arrayTerminals = dataset['terminals'] # Terminal flags in a [N x 1] numpy array ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 1]"]},{"cell_type":"code","execution_count":148,"metadata":{},"outputs":[],"source":["#Contamos los episodios para el dataset importado\n","def get_episodes():\n","    terminals = dataset['terminals'].astype('int32')\n","    #Las posiciones donde estan los Terminal=1\n","    if terminals[-1] == 0 : \n","        terminals[-1] = 1  \n","    terminal_pos = np.where(terminals==1)[0]\n","    return terminal_pos.tolist(), len(terminal_pos)\n","\n","def get_rtgs(t_positions, rewards):\n","    # Initialize the starting index of the sub-list in B\n","    start_idx = 0\n","    rtgs = []\n","\n","    \n","    for t in t_positions:\n","        end_idx = t + 1\n","        sub_list = rewards[start_idx:end_idx]\n","        #print(sub_list)\n","        for i in range(0, len(sub_list)):\n","            rtgs.append(sum(sub_list[i+1:]))\n","        start_idx = end_idx\n","    return rtgs\n","\n","def optimized_get_rtgs(t_positions, rewards):\n","\n","    rewards = np.array(rewards, dtype=np.float64)\n","    t_positions = np.array(t_positions)\n","\n","    cumsum_rewards = np.cumsum(rewards)\n","    \n","    # Initialize an array to hold the RTGs\n","    rtgs = np.array([], dtype=int)\n","    \n","    # Keep track of the start index of the sub-list in rewards\n","    start_idx = 0\n","    for end_idx in t_positions:\n","        \n","        segment_rtgs = cumsum_rewards[end_idx] - cumsum_rewards[start_idx:end_idx]\n","        segment_rtgs = np.append(segment_rtgs, 0)\n","        rtgs = np.concatenate((rtgs, segment_rtgs))\n","    \n","        start_idx = end_idx+1\n","    return rtgs.tolist()\n","\n","def get_timestep(terminal_pos):\n","    start_index = 0\n","    arrayTimesteps = np.zeros(len(dataset['rewards']), dtype=int)\n","    for i in terminal_pos:\n","        arrayTimesteps[start_index:(i+1)] = np.arange((i+1) - start_index)\n","        start_index = i\n","    return arrayTimesteps\n"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[],"source":["terminals_pos, num_episodes = get_episodes()"]},{"cell_type":"code","execution_count":150,"metadata":{},"outputs":[],"source":["rtgs = optimized_get_rtgs(terminals_pos, dataset['rewards'])"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[],"source":["timesteps = get_timestep(terminals_pos)"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","El episodio con mayor numero de timesteps de nuestro dataset durÃ³ un total de 1000 timesteps\n"]}],"source":["max_timesteps = max(timesteps)\n","print(\"\\nEl episodio con mayor numero de timesteps de nuestro dataset durÃ³ un total de\",max_timesteps,\"timesteps\")"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class MyDataset(Dataset):\n","    def __init__(self, observations, actions, steps, rtgs, terminals, blocks):\n","        self.observations = observations\n","        self.actions = actions\n","        self.steps = steps\n","        self.rtgs = rtgs\n","        self.terminals = terminals\n","        self.blocks = blocks\n","\n","    def __len__(self):\n","        return len(self.observations)\n","\n","    def __getitem__(self, idx):\n","        # to avoid blocks in between of 2 trajectories, if the idx is too close to the end of a trajectory, re-position\n","        # the idx to a block_size away to the end of the trajectory\n","        episode_ends = np.array(self.terminals)\n","        episode_starts=np.roll(episode_ends, shift=1) + 1\n","        episode_starts[0] = 0\n","\n","        print(\"episode start\", len(episode_starts))\n","        print(\"episode end\", len(episode_ends))\n","        print(idx)\n","        start, end = list(zip(episode_starts, episode_ends +1))[idx]\n","\n","        episode_length = end - start\n","\n","        # Sample a start point for the sequence within the episode\n","        if episode_length >= self.blocks:\n","            seq_start = np.random.randint(start, end - self.blocks + 1)\n","            seq_end = seq_start + self.blocks\n","            n_padding = 0\n","        else:\n","            seq_start = start\n","            seq_end = start + episode_length - 1\n","            n_padding = self.blocks - episode_length + 1\n","        \n","\n","        states = (self.observations[seq_start : seq_end])\n","        actions = (self.actions[seq_start : seq_end])\n","        rtgs = (self.rtgs[seq_start : seq_end])\n","        steps = (self.steps)\n","        \n","        if n_padding > 0:\n","            padding = np.zeros(n_padding)\n","\n","            states = np.concatenate(states, padding)\n","            actions = np.concatenate(actions, padding)\n","            rtgs = np.concatenate(rtgs, padding)\n","            steps = np.concatenate(steps, padding)\n","        \n","        states = torch.FloatTensor(states)\n","        actions = torch.FloatTensor(actions)\n","        rtgs = torch.FloatTensor(rtgs)\n","        steps = torch.FloatTensor(steps)\n","\n","        return states, actions, rtgs, steps"]},{"cell_type":"markdown","metadata":{},"source":["### DataSet && DataLoader"]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[],"source":["blocks = 16\n","dataset = MyDataset(arrayObservations, arrayActions, timesteps, rtgs, terminals_pos, blocks)\n","\n","DTDataLoader = DataLoader(dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":155,"metadata":{},"outputs":[],"source":["\n","# Definimos la funciÃ³n de pÃ©rdida\n","criterion = nn.MSELoss()\n","\n","# Definir el optimizador\n","optimizer = optim.Adam(model_dt.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["### Train"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["episode start 1134\n","episode end 1134\n","0\n","DT FORWARD\n","tensor([[  0.,   1.,   2.,  ..., 771., 772., 773.]])\n","1000\n","tensor([[[-1.1402e-01,  0.0000e+00,  1.0000e+00,  2.6657e-01,  0.0000e+00,\n","           1.5391e-01,  0.0000e+00, -5.9406e-01,  5.2290e-01, -7.6663e-02,\n","           2.9781e-01,  1.1515e-01,  6.7559e-01,  5.9427e-01,  0.0000e+00],\n","         [-1.0670e-01,  0.0000e+00,  1.0000e+00,  2.6703e-01,  0.0000e+00,\n","           9.8699e-02,  0.0000e+00, -5.9259e-01,  5.1246e-01, -8.6378e-02,\n","           3.1258e-01,  1.1823e-01,  8.0514e-01,  6.3000e-01,  0.0000e+00],\n","         [-1.0235e-01,  0.0000e+00,  1.0000e+00,  2.6077e-01,  0.0000e+00,\n","           4.6834e-02,  0.0000e+00, -5.9226e-01,  5.0206e-01, -8.0101e-02,\n","           3.2642e-01,  1.0460e-01,  9.3531e-01,  6.1354e-01,  0.0000e+00],\n","         [-1.0087e-01,  0.0000e+00,  1.0000e+00,  2.4937e-01,  0.0000e+00,\n","           6.1250e-02,  0.0000e+00, -5.9338e-01,  4.8681e-01, -2.3669e-01,\n","           3.4424e-01,  2.7352e-01,  1.0234e+00, -1.1131e-01,  0.0000e+00],\n","         [-9.8993e-02,  0.0000e+00,  1.0000e+00,  2.5282e-01,  0.0000e+00,\n","          -1.6534e-02,  0.0000e+00, -6.1304e-01,  4.4903e-01, -3.3864e-01,\n","           3.8200e-01,  3.1716e-01,  1.0096e+00, -4.5591e-02,  0.0000e+00],\n","         [-1.0102e-01,  0.0000e+00,  1.0000e+00,  2.4679e-01,  0.0000e+00,\n","          -7.8941e-02,  0.0000e+00, -6.3961e-01,  4.0687e-01, -3.3250e-01,\n","           4.2029e-01,  2.9624e-01,  1.0039e+00, -1.8674e-02,  0.0000e+00],\n","         [-1.0625e-01,  0.0000e+00,  1.0000e+00,  2.3329e-01,  0.0000e+00,\n","          -1.2883e-01,  0.0000e+00, -6.6426e-01,  3.7124e-01, -2.5320e-01,\n","           4.5197e-01,  2.2438e-01,  1.0016e+00, -7.6490e-03,  0.0000e+00],\n","         [-1.1419e-01,  0.0000e+00,  1.0000e+00,  2.1701e-01,  0.0000e+00,\n","          -1.7493e-01,  0.0000e+00, -6.8267e-01,  3.4666e-01, -1.6057e-01,\n","           4.7335e-01,  1.3660e-01,  1.0007e+00, -3.1330e-03,  0.0000e+00],\n","         [-1.2474e-01,  0.0000e+00,  1.0000e+00,  1.9574e-01,  0.0000e+00,\n","          -2.2229e-01,  0.0000e+00, -6.9466e-01,  3.3420e-01, -6.2035e-02,\n","           4.8208e-01,  2.8812e-02,  1.0003e+00, -1.2833e-03,  0.0000e+00],\n","         [-1.3816e-01,  0.0000e+00,  1.0000e+00,  1.6290e-01,  0.0000e+00,\n","          -2.8142e-01,  0.0000e+00, -7.0205e-01,  3.3348e-01,  2.8081e-02,\n","           4.7468e-01, -1.1111e-01,  1.0001e+00, -5.2563e-04,  0.0000e+00],\n","         [-1.5495e-01,  0.0000e+00,  1.0000e+00,  1.2988e-01,  0.0000e+00,\n","          -3.4622e-01,  0.0000e+00, -7.0786e-01,  3.4260e-01,  9.8930e-02,\n","           4.5042e-01, -2.4069e-01,  1.0000e+00, -2.1530e-04,  0.0000e+00],\n","         [-1.7529e-01,  0.0000e+00,  1.0000e+00,  1.0950e-01,  0.0000e+00,\n","          -4.1015e-01,  0.0000e+00, -7.1378e-01,  3.5746e-01,  1.2911e-01,\n","           4.1452e-01, -3.1058e-01,  1.0000e+00, -8.8187e-05,  0.0000e+00],\n","         [-1.9904e-01,  0.0000e+00,  1.0000e+00,  9.7182e-02,  0.0000e+00,\n","          -4.6869e-01,  0.0000e+00, -7.1993e-01,  3.7598e-01,  1.5754e-01,\n","           3.7196e-01, -3.5350e-01,  1.0000e+00, -3.6121e-05,  0.0000e+00],\n","         [-2.2586e-01,  0.0000e+00,  1.0000e+00,  9.6121e-02,  0.0000e+00,\n","          -5.1992e-01,  0.0000e+00, -7.2487e-01,  3.9685e-01,  1.7039e-01,\n","           3.2722e-01, -3.5571e-01,  1.0000e+00, -1.4795e-05,  0.0000e+00],\n","         [-2.5503e-01,  0.0000e+00,  1.0000e+00,  1.1619e-01,  0.0000e+00,\n","          -5.0537e-01,  0.0000e+00, -7.2676e-01,  4.1433e-01,  4.8360e-02,\n","           2.8724e-01, -3.1449e-01,  1.0044e+00,  8.4550e-02,  0.0000e+00],\n","         [-2.7323e-01,  0.0000e+00,  1.0000e+00,  1.1074e-01,  0.0000e+00,\n","          -1.9354e-01,  0.0000e+00, -7.6330e-01,  3.7562e-01, -3.6354e-01,\n","           2.6507e-01, -1.1626e-01,  1.0154e+00, -3.8664e-02,  1.0000e+00]]])\n","tensor([[[-0.0133,  0.0024,  0.0612],\n","         [-0.0177, -0.0464, -0.0205],\n","         [-0.0333, -0.0691, -0.0496],\n","         [-0.0850,  0.0025,  0.3873],\n","         [-0.0280, -0.0506,  0.2968],\n","         [ 0.0100, -0.0899,  0.2527],\n","         [ 0.0142, -0.1072,  0.2137],\n","         [ 0.0015, -0.1447,  0.1878],\n","         [-0.0505, -0.2350,  0.1869],\n","         [-0.0687, -0.2415,  0.1902],\n","         [-0.0557, -0.1543,  0.1736],\n","         [-0.0272, -0.0959,  0.1413],\n","         [ 0.0032, -0.0108,  0.1277],\n","         [ 0.0888,  0.1923,  0.0550],\n","         [ 0.2218,  0.2390, -0.0205],\n","         [ 0.5045,  0.4135, -0.7510]]])\n","tensor([[267.9630, 266.3467, 264.6938, 263.1253, 261.2570, 259.2615, 257.3098,\n","         255.4736, 253.7497, 252.1354, 250.5934, 249.0604, 247.5240, 245.9913,\n","         244.5480, 242.7666]])\n"]},{"ename":"TypeError","evalue":"forward() takes 2 positional arguments but 3 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[156], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Paso 2: PropagaciÃ³n hacia adelante (Forward pass)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m _, _, act_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_dt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtgs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# timestep, max_timesteps, states, actions, returns_to_go\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#outputs = model(batch_obs)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Paso 3: Calcular la pÃ©rdida\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(act_preds, actions)\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[144], line 34\u001b[0m, in \u001b[0;36mDecisionTransformer.forward\u001b[0;34m(self, timestep, max_timesteps, states, actions, returns_to_go)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(returns_to_go)\n\u001b[1;32m     32\u001b[0m B, T, _ \u001b[38;5;241m=\u001b[39m states\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;66;03m# [batch size, seq length, embed_dim]\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m pos_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m state_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_embed(states)\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"]}],"source":["#Bucle de training\n","\n","num_epochs = 5\n","timestep = 0\n","max_timesteps = max_timesteps #Calculated according to the longest episode in the dataset/env loaded.\n","for epoch in range(num_epochs):\n","    total_loss = 0.0  # Inicializar la pÃ©rdida total para el epoch\n","\n","    # IteraciÃ³n sobre los lotes de datos\n","\n","    for states, actions, rtgs, steps in DTDataLoader:\n","        # Paso 1: Reiniciar los gradientes\n","        #timestep += 1 ==> No es necesario para el training, solo para evaluation\n","        optimizer.zero_grad()\n","\n","        # Paso 2: PropagaciÃ³n hacia adelante (Forward pass)\n","        _, _, act_preds = model_dt(steps, max_timesteps, states, actions, rtgs) # timestep, max_timesteps, states, actions, returns_to_go\n","        #outputs = model(batch_obs)\n","\n","        # Paso 3: Calcular la pÃ©rdida\n","        loss = criterion(act_preds, actions)\n","\n","        # Paso 4: PropagaciÃ³n hacia atrÃ¡s (Backward pass)\n","        loss.backward()\n","\n","        # Paso 5: ActualizaciÃ³n de los parÃ¡metros del modelo\n","        optimizer.step()\n","\n","        # Sumar la pÃ©rdida del batch a la pÃ©rdida total del epoch\n","        total_loss += loss.item()\n","\n","    # Calcular la pÃ©rdida media del epoch\n","    epoch_loss = total_loss / len(DTDataLoader)\n","\n","    # Imprimir la pÃ©rdida media del epoch\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n","\n","    # Paso 6 (Opcional): EvaluaciÃ³n del modelo en un conjunto de datos de evaluaciÃ³n\n","    # AquÃ­ puedes agregar cÃ³digo para evaluar el modelo en un conjunto de datos de evaluaciÃ³n si lo tienes disponible\n","\n","# Paso 7 (Opcional): VisualizaciÃ³n de resultados o mÃ©tricas de rendimiento\n","# AquÃ­ puedes agregar cÃ³digo para mostrar otras mÃ©tricas de rendimiento que desees analizar"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["episode_ends = np.array([3,7,15])\n","episode_starts = np.roll(A, shift=1)+ 1"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 4, 8])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["episode_starts\n","episode_starts[0] = 0\n","episode_starts"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["[(0, 4), (4, 8), (8, 16)]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["a = list(zip(episode_starts, episode_ends +1))\n","a\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Mostramos los maximos rewards para los Terminal=1 recogidos en \"terminal_pos\"\n","\n","sample=terminal_pos[0]\n","print(\"\\nRewards example:\",arrayRewards[sample])\n","\n","#Construimos el array de rewards to go\n","arrayReturnToGo = []\n","\n","for i in terminal_pos:\n","    arrayReturnToGo.append(arrayRewards[i])\n","\n","len(arrayReturnToGo)\n","\n","#Creamos tensor de Returnstogo\n","tensorReturnToGo = torch.FloatTensor(arrayReturnToGo)\n","tensorReturnToGo.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos un array \"timesteps\" donde se identificaran los timesteps para cada episodio respecto al total del dataset\n","def get_timestep():\n","    start_index = 0\n","    arrayTimesteps = np.zeros(len(arrayActions), dtype=int)\n","    for i in terminal_pos:\n","        arrayTimesteps[start_index:i] = np.arange(i - start_index)\n","        start_index = i\n","    return arrayTimesteps\n","print(\"\\nEl array Timesteps tendra la misma dimension que las samples del dataset:\",len(arrayTimesteps),\" samples\")\n","print(\"\\nEjemplo muestreo hasta el episodio 25:\\n\", arrayTimesteps[0:25])\n","\n","#Comprovamos en el dataset (concretamente en el arrayTimesteps), cual es el episodio mas largo. Ese sera nuestro \"max_timesteps\"\n","max_timesteps = max(arrayTimesteps)\n","print(\"\\nEl episodio con mayor numero de timesteps de nuestro dataset durÃ³ un total de\",max_timesteps,\"timesteps\")\n","\n","#Lo convertimos a tensor\n","tensorTimesteps = torch.FloatTensor(arrayTimesteps)\n","#tensorTimesteps.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prueba_omar = np.unique(arrayActions[0:20])\n","print('action possible numbers: ',prueba_omar )\n","#assert hparams['vocab_size'] == len(np.unique(arrayActions))\n","len(prueba_omar)\n","\n","arrayActions[0:20]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#We transform all the arrays to Float tensors\n","if torch.cuda.is_available():\n","  tensorObservations = torch.cuda.FloatTensor(arrayObservations)\n","  tensorActions = torch.cuda.FloatTensor(arrayActions)\n","  tensorRewards = torch.cuda.FloatTensor(arrayRewards)\n","  tensorTerminals = torch.cuda.FloatTensor(arrayTerminals)\n","  print(\"\\n Tensors in the GPU\")\n","  print(\"\\n////////////////////////////////////////////////////////////////////////////////\")\n","else:\n","  tensorObservations = torch.FloatTensor(arrayObservations)\n","  tensorActions = torch.FloatTensor(arrayActions)\n","  tensorRewards = torch.FloatTensor(arrayRewards)\n","  tensorTerminals = torch.FloatTensor(arrayTerminals)\n","  print(\"\\n Tensors in the CPU\")\n","\n","# Tensors shape\n","print(\"\\nObservations shape:\",tensorObservations.shape)\n","print(\"\\nActions shape:\",tensorActions.shape)\n","print(\"\\nRewards shape:\",tensorRewards.shape)\n","print(\"\\nTerminals shape:\",tensorTerminals.shape)\n","print(\"\\n////////////////////////////////////////////////////////////////////////////////\")\n","\n","sample = 59343\n","# Tensors content at certain timestep\n","print(\"\\nObservations example:\",tensorObservations[sample])\n","print(\"\\nActions example:\",tensorActions[sample])\n","print(\"\\nRewards example:\",tensorRewards[sample])\n","print(\"\\nTerminals example:\",tensorTerminals[sample])"]},{"cell_type":"markdown","metadata":{"id":"ZfbaABN2gpMP"},"source":["# Pasar este dataset al DT (Shuang/Omar)!!!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4476,"status":"ok","timestamp":1707075864981,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"9X78mWt6iwIR","outputId":"a1025993-822d-4118-834a-29fe7e38aca3"},"outputs":[],"source":["#Source: PyBullet Environment: https://pybullet.org/wordpress/\n","#                              https://github.com/bulletphysics/bullet3/tree/master\n","\n","import numpy as np\n","import gym\n","import pybullet_envs\n","import argparse\n","import os\n","import torch\n","\n","from tqdm import tqdm\n","#from .sac import SAC, seed_everything\n","#from .utility import save_buffer\n","\n","\n","def collect(env, sac, logdir, final_step, deterministic):\n","    buffer = []\n","    frames = []\n","\n","    step = 0\n","    pbar = tqdm(total=final_step)\n","    while step < final_step:\n","        obs_t = env.reset()\n","        ter_t = False\n","        rew_t = 0.0\n","\n","\n","        while step < final_step and not ter_t:\n","            #act_t = sac.act([obs_t], deterministic=deterministic)[0] #SAC (Soft Actor Critic) es un algoritmo de RL\n","            frames.append(env.render(mode=\"rgb_array\"))\n","            act_t = env.action_space.sample() # Temporal. Aqui tendriamos que la salida/action del DT.\n","            buffer.append([obs_t, act_t, [rew_t], [ter_t]])\n","\n","            obs_t, rew_t, ter_t, _ = env.step(act_t)   #O.Aguilera (04/02/2024): La dimensio no es correcte.\n","\n","            step += 1\n","            pbar.update(1)\n","\n","        if ter_t:\n","            buffer.append([obs_t, np.zeros_like(act_t), [rew_t], [ter_t]])\n","\n","    #save_buffer(buffer[:final_step], logdir)\n","\n","    print('Collected data has been saved.')\n","    return frames\n","\n","''' if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--env', type=str)\n","    parser.add_argument('--seed', type=int, default=0)\n","    parser.add_argument('--final-step', type=int, default=1000000) #\n","    parser.add_argument('--load', type=str)\n","    parser.add_argument('--gpu', action='store_true')\n","    args = parser.parse_args() '''\n","\n","#env = gym.make(args.env)\n","env = gym.make('hopper-bullet-mixed-v0')\n","#env.seed(args.seed)\n","env.seed(1)\n","#seed_everything(args.seed)\n","#seed_everything(1)\n","\n","observation_size = env.observation_space.shape[0]\n","action_size = env.action_space.shape[0]\n","device = 'cuda:0'\n","\n","#sac = SAC(observation_size, action_size, device)\n","'''\n","if args.load:\n","    sac.load(args.load)\n","    name = 'medium'\n","    deterministic = True\n","else:'''\n","name = 'random'\n","deterministic = False\n","\n","#logdir = os.path.join('logs', '{}_{}_{}'.format(args.env, name, args.seed))\n","#os.makedirs(logdir)\n","\n","\n","prova=collect(env, None, None, 100, deterministic)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1707075893010,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"5ZZdymFuo-CM","outputId":"63bc8868-19a7-4e82-bbda-8b6448e3cac2"},"outputs":[],"source":["prova[0]\n","prova[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":2268,"status":"ok","timestamp":1707075967418,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"0qz16feApxN-","outputId":"8ecd95c7-f127-463b-918e-2d7b7a0f144b"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","plt.imshow(prova[0], interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793},"executionInfo":{"elapsed":13985,"status":"ok","timestamp":1707076061860,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"hWjXpRikoxHC","outputId":"d4c4a8f8-df3d-4f22-ec96-2754eeef1197"},"outputs":[],"source":["!apt-get install ffmpeg\n","!pip install notebook-video-writer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":17,"status":"error","timestamp":1707242998732,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"cO_CMXRVqdUd","outputId":"d04f2456-fd48-465c-e041-c33bd1401157"},"outputs":[],"source":["from notebook_video_writer import VideoWriter\n","with VideoWriter(fps=40) as vw:\n","    for i in range(len(prova)):\n","        vw.add(prova[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1707076908060,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"87dKrBuaoJFq","outputId":"c3495c99-361a-4c49-b51f-3b9862b31903"},"outputs":[],"source":["env = gym.make('hopper-bullet-mixed-v0')\n","print(env.action_space.sample())"]},{"cell_type":"markdown","metadata":{"id":"Na1sduHdtoOe"},"source":["## Notas Google Meet Domingo 04/02/2024\n","\n","\n","Edgar Planell\n","19:33\n","https://github.com/takuseno/d4rl-pybullet/blob/master/requirements.txt\n","\n","Edgar Planell\n","19:37\n","pip install git+https://github.com/takuseno/d4rl-pybullet\n","\n","Edgar Planell\n","19:59\n","pip setuptools wheel\n","\n","TÃº\n","19:59\n","brew install hdf5\n","\n","Edgar Planell\n","20:01\n","versioned-hdf5\n","\n","Edgar Planell\n","20:13\n","    import numpy as np\n","    import gym\n","    import pybullet_envs\n","    import argparse\n","    import os\n","\n","    from tqdm import tqdm\n","    from .sac import SAC, seed_everything\n","    from .utility import save_buffer\n","\n","\n","    def collect(env, sac, logdir, final_step, deterministic):\n","        buffer = []\n","\n","        step = 0\n","        pbar = tqdm(total=final_step)\n","        while step < final_step:\n","            obs_t = env.reset()\n","            ter_t = False\n","            rew_t = 0.0\n","            while step < final_step and not ter_t:\n","                act_t = sac.act([obs_t], deterministic=determin\n","\n","      import numpy as np\n","      import gym\n","      import pybullet_envs\n","      import argparse\n","      import os\n","\n","      from tqdm import tqdm\n","      from .sac import SAC, seed_everything\n","      from .utility import save_buffer\n","\n","\n","      def collect(env, sac, logdir, final_step, deterministic):\n","          buffer = []\n","\n","          step = 0\n","          pbar = tqdm(total=final_step)\n","          while step < final_step:\n","              obs_t = env.reset()\n","              ter_t = False\n","              rew_t = 0.0\n","              while step < final_step and not ter_t:\n","                  act_t = sac.act([obs_t], deterministic=determin\n","https://github.com/takuseno/d4rl-pybullet/blob/master/d4rl_pybullet/collect.py\n","\n","Edgar Planell\n","20:30\n","https://github.com/bulletphysics/bullet3/tree/master\n","\n","Edgar Planell\n","20:32\n","https://github.com/bulletphysics/bullet3/blob/master/examples/pybullet/gym/pybullet_examples/biped2d_pybullet.py\n","\n","Edgar Planell\n","20:37\n","https://github.com/benelot/pybullet-gym/tree/master\n","\n","Josep Maria Bach RamÃ­rez\n","20:43\n","env.render(mode=\"rgb_array\")\n","\n","Josep Maria Bach RamÃ­rez\n","20:45\n","from matplotlib import pyplot as plt\n","plt.imshow(prova[0], interpolation='nearest')\n","plt.show()\n","\n","Josep Maria Bach RamÃ­rez\n","20:47\n","!apt-get install ffmpeg\n","!pip install notebook-video-writer\n","\n","Josep Maria Bach RamÃ­rez\n","20:48\n","from notebook_video_writer import VideoWriter\n","with VideoWriter(fps=40) as vw:\n","    for i in range(len(prova)):\n","        vw.add(prova[i])\n","        \n","Josep Maria Bach RamÃ­rez\n","20:52\n","https://gymnasium.farama.org/api/env/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Og2T3r8m_YR"},"outputs":[],"source":["''' import pybullet as p\n","import pybullet_data\n","import os\n","import time\n","GRAVITY = -9.8\n","dt = 1e-3\n","iters = 2000\n","import pybullet_data\n","\n","physicsClient = p.connect(p.GUI)\n","p.setAdditionalSearchPath(pybullet_data.getDataPath())\n","p.resetSimulation()\n","#p.setRealTimeSimulation(True)\n","p.setGravity(0, 0, GRAVITY)\n","p.setTimeStep(dt)\n","planeId = p.loadURDF(\"plane.urdf\")\n","cubeStartPos = [0, 0, 1.13]\n","cubeStartOrientation = p.getQuaternionFromEuler([0., 0, 0])\n","botId = p.loadURDF(\"biped/biped2d_pybullet.urdf\", cubeStartPos, cubeStartOrientation)\n","\n","#disable the default velocity motors\n","#and set some position control with small force to emulate joint friction/return to a rest pose\n","jointFrictionForce = 1\n","for joint in range(p.getNumJoints(botId)):\n","  p.setJointMotorControl2(botId, joint, p.POSITION_CONTROL, force=jointFrictionForce)\n","\n","#for i in range(10000):\n","#     p.setJointMotorControl2(botId, 1, p.TORQUE_CONTROL, force=1098.0)\n","#     p.stepSimulation()\n","#import ipdb\n","#ipdb.set_trace()\n","import time\n","p.setRealTimeSimulation(1)\n","while (1):\n","  #p.stepSimulation()\n","  #p.setJointMotorControl2(botId, 1, p.TORQUE_CONTROL, force=1098.0)\n","  p.setGravity(0, 0, GRAVITY)\n","  time.sleep(1 / 240.)\n","time.sleep(1000) '''"]}],"metadata":{"colab":{"provenance":[{"file_id":"11OpZevRdnWN9dDLwj3OdXT2sDwBwxJec","timestamp":1707249437132}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
