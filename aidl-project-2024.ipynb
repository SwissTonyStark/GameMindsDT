{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"eBHSisFoq68z"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader,TensorDataset\n","\n","import math\n","import numpy as np\n","#import seaborn as sns\n","import matplotlib.pylab as plt\n","import logging\n","\n","#Especifico para el gym+dataset \"D4RL_Pybullet\"\n","import gym\n","import d4rl_pybullet\n","from tabulate import tabulate\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO)"]},{"cell_type":"markdown","metadata":{"id":"slKJSnX_u_gt"},"source":["## Config"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"fbZahVUHu4Nq"},"outputs":[],"source":["model_cfg = {\n","    \"state_dim\": 4*30,\n","    \"act_dim\": 30 , # act_dim=Contextlength?\n","    \"ffn_dim\": 12,  #FeedForwardNetwork Dimension\n","    \"embed_dim\": 128,\n","    \"num_heads\": 16,\n","    \"num_blocks\": 1,\n","    \"max_timesteps\": 4096,\n","    \"mlp_ratio\": 4,\n","    \"dropout\": 0.1,\n","    \"vocab_size\": 4,\n","    \"rtg_dim\": 1\n","\n","}"]},{"cell_type":"markdown","metadata":{"id":"Ve3rd14BrRV_"},"source":["## Masked Attention"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"pPFpaUDnrOVV"},"outputs":[],"source":["class MaskedSelfAttention(nn.Module):\n","\n","    def __init__(self, embed_dim, num_heads, seq_len, dropout):\n","        super().__init__()\n","\n","        self.embed_dim = embed_dim # embeding dimensionality, includes all heads\n","        self.num_heads = num_heads #  num heads\n","        assert self.embed_dim % self.num_heads == 0 , \\\n","            \"Embedding dimension must be multiple of the number of heads.\"\n","\n","        self.seq_len = seq_len\n","\n","        # key, query, value projections\n","        self.proj_q = nn.Linear(embed_dim, embed_dim)\n","        self.proj_k = nn.Linear(embed_dim, embed_dim)\n","        self.proj_v = nn.Linear(embed_dim, embed_dim)\n","\n","        # output projection\n","        self.proj_out = nn.Linear(self.embed_dim, self.embed_dim)\n","        # regularization\n","        self.attn_dropout = nn.Dropout(dropout)\n","        self.resid_dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        print(\"T FORWARD (tocho)\")\n","        B, T, C = x.shape # batch size, sequence length, embedding dimensionality (embed_dim)\n","        #head_size = self.num_heads, C // self.num_heads\n","\n","        # calculate query, key, values\n","        q = self.proj_q(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","        k = self.proj_k(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","        v = self.proj_v(x).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n","\n","        # causal self-attention; Self-attend: (B, numHeads, seqLen, headSize) x (B, numHeads, headSize, seqLen) -> (B, numHeads, seqLen, seqLen)\n","        # scaled_dot_product\n","        attn_logits = (q @ k.transpose(-2, -1))\n","        attn_logits = attn_logits / torch.sqrt(torch.tensor(k.size(-1)))\n","        # apply mask\n","\n","        mask = torch.zeros(x.shape[1], x.shape[0]).bool() #toDevice\n","        subsequent_mask = torch.triu(torch.ones(B, T, T), 1).bool() #toDevice\n","        selfattn_mask = subsequent_mask + mask.unsqueeze(-2)\n","        attn_logits = attn_logits.masked_fill(selfattn_mask, float('-inf'))\n","\n","        softmax = nn.Softmax(dim=-1)\n","        attention = softmax(attn_logits)\n","\n","        attention = attention @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        out = self.attn_dropout(attention)\n","\n","        out = out.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n","\n","        # output projection\n","        y = self.resid_dropout(self.proj_out(out))\n","        return y"]},{"cell_type":"markdown","metadata":{"id":"wmU9xYierVZH"},"source":["## MLP"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"NUTPd1LCrVwz"},"outputs":[],"source":["class MLP(nn.Module):\n","\n","    def __init__(self, embed_dim, ffn_dim, dropout):\n","        super().__init__()\n","        self.fc1 = nn.Linear(embed_dim, ffn_dim)\n","        self.act = nn.GELU()\n","        self.fc2 = nn.Linear(ffn_dim, embed_dim)\n","        self.drop= nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        print(\"MLP FORWARD\")\n","        x = self.act(self.fc1(x))\n","        x = self.drop(self.fc2(x))\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"2jeC6poirbbz"},"source":["## Decoder block"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"v9GpR2yhrbxr"},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","\n","    def __init__(self, embed_dim, num_heads, seq_len, mlp_ratio, dropout):\n","        super().__init__()\n","\n","        self.attn = MaskedSelfAttention(embed_dim, num_heads, seq_len, dropout)\n","        self.ln1 = nn.LayerNorm(embed_dim)\n","        self.mlp = MLP(embed_dim, int(embed_dim * mlp_ratio),dropout)\n","        self.ln_2 = nn.LayerNorm(embed_dim)\n","\n","    def forward(self, x):\n","        print(\"DECODER BLOCK FORWARD\")\n","        x = self.ln1(x) # normalize\n","        x = self.attn(x) + x # add residual\n","        x = self.ln2(x)\n","        x = self.mlp(x) + x\n","\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"LNPb3mxWrj1Z"},"source":["## Decision Transformer"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"Dxv3FQCMri-q"},"outputs":[],"source":["class DecisionTransformer(nn.Module):\n","    def __init__(self, state_dim, act_dim, ffn_dim, embed_dim, num_heads, num_blocks, max_timesteps, mlp_ratio, dropout, vocab_size, rtg_dim=1):\n","        super().__init__()\n","\n","        self.ffn_dim = ffn_dim   #NÂº de Layers \"nn.Linear\" ~~ \"ffn_dim\"\n","        self.seq_len = act_dim   # Omar/Shuang-> Provisional, revisar esta linea.\n","        # Construct embedding layer\n","        self.state_embed = nn.Linear(in_features=state_dim, out_features=ffn_dim)\n","        self.act_embed = nn.Linear(in_features=act_dim, out_features=ffn_dim)\n","        self.rtg_embed = nn.Linear(in_features=rtg_dim, out_features=ffn_dim)\n","        self.pos_embed = nn.Embedding(num_embeddings=max_timesteps, embedding_dim=ffn_dim)\n","\n","        self.norm = nn.LayerNorm(ffn_dim)\n","\n","        #TODO: Complete Basic Transformer parameters\n","        self.transformerGPT = nn.ModuleList([DecoderBlock(embed_dim, num_heads, self.seq_len, mlp_ratio, dropout) for _ in range(num_blocks)])\n","\n","        self.rtg_pred = nn.Linear(in_features=ffn_dim, out_features=1)\n","        self.state_pred = nn.Linear(in_features=ffn_dim, out_features=state_dim)\n","        self.act_pred = nn.Sequential(\n","            nn.Linear(ffn_dim, act_dim),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, timestep, max_timesteps, states, actions, returns_to_go):\n","        print(\"DT FORWARD\")\n","        print(timestep)\n","        print(max_timesteps)\n","        print(states)\n","        print(actions)\n","        print(returns_to_go)\n","        B, T, _ = states.shape # [batch size, seq length, embed_dim]\n","\n","        pos_embedding = self.pos_embed(max_timesteps, timestep)\n","        print(\"DEBUG 1\")\n","        state_embedding = self.state_embed(states)\n","        act_embedding = self.act_embed(actions)\n","        rtg_embedding = self.rtg_embed(returns_to_go)\n","        print(\"DEBUG 2\")\n","        state_embedding += pos_embedding\n","        act_embedding += pos_embedding\n","        returns_to_go += pos_embedding\n","        print(\"DEBUG 3\")\n","        # (R{1}, S{1}, A{1}, ..., R{i}, S{i}, A{i}, ..., R{n}, S{n}, A{n}) | 1 < i < n\n","        stacked_inputs = torch.stack((rtg_embedding, state_embedding, act_embedding), dim=1) # [B, rtg_dim, state_dim, act_dim]\n","        stacked_inputs = stacked_inputs.permute(0, 2, 1, 3) #[B, state_dim, rtg_dim, act_dim]\n","        stacked_inputs = stacked_inputs.reshape(B, 3*T, self.ffn_dim) # [B, 3*T, hidden_size]  Nota: ffn_dim a.k.a \"hidden_size\"\n","        print(\"DEBUG 4\")\n","        x = self.norm(stacked_inputs)\n","        if torch.is_tensor(x):\n","            print(\"SHAP INPUT TRANSFORMER TOCHO: \", x.shape)\n","        else:\n","            print(\"LEN INPUT T: \", len(x))\n","        print(x)\n","        #TODO: Complete Basic Transformer\n","        out = self.transformerGPT(x)\n","        out = out.reshape(B, T, 3, self.ffn_dim).permute(0, 2, 1, 3)  #[B, T, 3, hidden_size] --> [B, 3, T, hidden_size]     Nota: ffn_dim a.k.a \"hidden_size\"\n","\n","        returns_to_go_preds = self.rtg_pred(out[:,2])     # predict next return given state and action [0 state, 1 action, 2 rtg]\n","        state_preds = self.state_pred(out[:,2])           # predict next state given state and action  [0, 1, 2 rtg]\n","        act_preds = self.act_pred(out[:,1])               # predict next action given state            [0, 1, 2]\n","\n","        return returns_to_go, state_preds, act_preds"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"SfPJEc6x44D3"},"outputs":[{"data":{"text/plain":["DecisionTransformer(\n","  (state_embed): Linear(in_features=120, out_features=12, bias=True)\n","  (act_embed): Linear(in_features=30, out_features=12, bias=True)\n","  (rtg_embed): Linear(in_features=1, out_features=12, bias=True)\n","  (pos_embed): Embedding(4096, 12)\n","  (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n","  (transformerGPT): ModuleList(\n","    (0): DecoderBlock(\n","      (attn): MaskedSelfAttention(\n","        (proj_q): Linear(in_features=128, out_features=128, bias=True)\n","        (proj_k): Linear(in_features=128, out_features=128, bias=True)\n","        (proj_v): Linear(in_features=128, out_features=128, bias=True)\n","        (proj_out): Linear(in_features=128, out_features=128, bias=True)\n","        (attn_dropout): Dropout(p=0.1, inplace=False)\n","        (resid_dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","      (mlp): MLP(\n","        (fc1): Linear(in_features=128, out_features=512, bias=True)\n","        (act): GELU(approximate='none')\n","        (fc2): Linear(in_features=512, out_features=128, bias=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (rtg_pred): Linear(in_features=12, out_features=1, bias=True)\n","  (state_pred): Linear(in_features=12, out_features=120, bias=True)\n","  (act_pred): Sequential(\n","    (0): Linear(in_features=12, out_features=30, bias=True)\n","    (1): Tanh()\n","  )\n",")"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["#Creamos instancia decision transformer con nuestra config\n","model_dt = DecisionTransformer(**model_cfg)\n","model_dt"]},{"cell_type":"markdown","metadata":{"id":"2NApHsQGt2bw"},"source":["## DataSet\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2695,"status":"ok","timestamp":1707244731722,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"FVJsd0cKb_FT","outputId":"f8abb7b0-9f00-4e9e-8d0a-f8cd1eb0e3e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["pybullet build time: Feb  9 2024 18:21:48\n","\n"," Observations: [ 0.          0.          1.          0.          0.          0.\n","  0.         -0.          0.93191123  0.          1.0711064   0.\n","  0.03378947  0.          0.        ]\n","\n"," Actions: [-0.7135147  -0.45422366 -0.9843897 ]\n","\n"," Rewards: 0.0\n","\n"," Terminals: 0.0\n"]},{"name":"stderr","output_type":"stream","text":["/home/shuanglong/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"]}],"source":["#Source:  https://github.com/takuseno/d4rl-pybullet\n","\n","# dataset will be automatically downloaded into ~/.d4rl/datasets\n","env = gym.make('hopper-bullet-mixed-v0')\n","\n","# interaction with its environment\n","dataset = env.get_dataset()\n","\n","#Hacemos print de Observations/Actions/Rewards/Terminals\n","print(\"\\n Observations:\", dataset['observations'][0]) # observation data in N x dim_observation. O.Aguilera: Mostramos la Observation en el timestep \"num_timestep\" ->[num_timestep]\n","print(\"\\n Actions:\", dataset['actions'][0]) # action data in N x dim_action. O.Aguilera: Mostramos la Action en el timestep \"num_timestep\" ->[num_timestep]\n","print(\"\\n Rewards:\", dataset['rewards'][0]) # reward data in N x 1. O.Aguilera: Mostramos la Rewards \"num_timestep\" ->[num_timestep]\n","print(\"\\n Terminals:\", dataset['terminals'][0]) # terminal flags in N x 1. O.Aguilera: Mostramos la Terminals \"num_timestep\" ->[num_timestep]. Indica si ha terminat l'episodi (Todo FALSE menos ultimo TRUE)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#Automatically download and return the dataset\n","dataset = env.get_dataset()\n","\n","#We can acces the dataset, and we will obtain Numpy arrays\n","arrayObservations = dataset['observations'] # Observation data in a [N x dim_observation] numpy array  ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 15]\n","arrayActions = dataset['actions'] # Action data in [N x dim_action] numpy array ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 3]\n","arrayRewards = dataset['rewards'] # Reward data in a [N x 1] numpy array ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 1]\n","arrayTerminals = dataset['terminals'] # Terminal flags in a [N x 1] numpy array ==> Para 'hopper-bullet-mixed-v0\" = [59345 x 1]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def get_episodes(terminals):\n","    terminals = terminals.astype('int32')\n","    #Las posiciones donde estan los Terminal=1\n","    if terminals[-1] == 0 : \n","        terminals[-1] = 1  \n","    terminal_pos = np.where(terminals==1)[0]\n","    return terminal_pos.tolist(), len(terminal_pos)\n","\n","def get_rtgs(t_positions, rewards):\n","    # Initialize the starting index of the sub-list in B\n","    start_idx = 0\n","    rtgs = []\n","\n","    \n","    for t in t_positions:\n","        end_idx = t + 1\n","        sub_list = rewards[start_idx:end_idx]\n","        #print(sub_list)\n","        for i in range(0, len(sub_list)):\n","            rtgs.append(sum(sub_list[i+1:]))\n","        start_idx = end_idx\n","    return rtgs\n","\n","def optimized_get_rtgs(t_positions, rewards):\n","\n","    rewards = np.array(rewards, dtype=np.float64)\n","    t_positions = np.array(t_positions)\n","\n","    cumsum_rewards = np.cumsum(rewards)\n","    \n","    # Initialize an array to hold the RTGs\n","    rtgs = np.array([], dtype=int)\n","    \n","    # Keep track of the start index of the sub-list in rewards\n","    start_idx = 0\n","    for end_idx in t_positions:\n","        \n","        segment_rtgs = cumsum_rewards[end_idx] - cumsum_rewards[start_idx:end_idx]\n","        segment_rtgs = np.append(segment_rtgs, 0)\n","        rtgs = np.concatenate((rtgs, segment_rtgs))\n","    \n","        start_idx = end_idx+1\n","    return rtgs.tolist()\n","\n","def list_episodes(terminals_idxs):\n","    episode_ends = np.array(terminals_idxs)\n","    episode_starts=np.roll(episode_ends, shift=1) + 1\n","    episode_starts[0] = 0\n","    return list(zip(episode_starts, episode_ends +1))\n","\n","def get_timesteps(episodes, size):\n","    # Initialize the array of timesteps\n","    arrayTimesteps = np.zeros(size, dtype=int)\n","\n","    # List to hold the total steps per episode\n","    steps_per_episode = []\n","\n","    # Generate timesteps for each episode\n","    for start, end in episodes:\n","        episode_length = end - start\n","        steps_per_episode.append(episode_length)\n","        arrayTimesteps[start:end] = np.arange(episode_length)\n","    return arrayTimesteps, steps_per_episode\n","    # Initialize the array of timesteps\n","    arrayTimesteps = np.zeros(n, dtype=int)\n","\n","    # List to hold the total steps per episode\n","    steps_per_episode = []\n","\n","    # Generate timesteps for each episode\n","    for start, end in episodes:\n","        episode_length = end - start \n","        steps_per_episode.append(episode_length)\n","        arrayTimesteps[start:end] = np.arange(episode_length)\n","    return arrayTimesteps, steps_per_episode"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: Showing episodes information...\n","INFO: \n","+----------------+----------+\n","|                |    Value |\n","+================+==========+\n","| Total episodes |  581     |\n","+----------------+----------+\n","| Max duration   | 1001     |\n","+----------------+----------+\n","| Min duration   |    6     |\n","+----------------+----------+\n","| Mean duration  |  102.143 |\n","+----------------+----------+\n","INFO: Removing 393 eps out of 581 eps...\n","INFO: Remaining episoded should be 188 eps.\n","INFO: Final total samples: 41764 out of 59345 original samples.\n"]}],"source":["terminals_pos, num_episodes = get_episodes(arrayTerminals)\n","logging.info(f'Showing episodes information...')\n","\n","rtgs = optimized_get_rtgs(terminals_pos, dataset['rewards'])\n","episodes = list_episodes(terminals_pos)\n","\n","timesteps, steps_per_episode = get_timesteps(episodes, len(arrayObservations))\n","max_timestep = np.max(steps_per_episode)\n","min_timestep = np.min(steps_per_episode)\n","mean_timestep= np.mean(steps_per_episode)\n","\n","ep_data =  [[\"Total episodes\", num_episodes],\n","            [\"Max duration\", max_timestep],\n","            [\"Min duration\", min_timestep],\n","            [\"Mean duration\",mean_timestep]]\n","col_head = [\"\", \"Value\"]\n","\n","tb = tabulate(ep_data, headers=col_head,tablefmt=\"grid\")\n","logging.info(f'\\n{tb}')\n","\n","### Remove episodes wiht lees than mean_timestep\n","\n","rm_eps_idx = [idx for idx, mean in enumerate(steps_per_episode) if mean < mean_timestep]\n","logging.info(f'Removing {len(rm_eps_idx)} eps out of {len(episodes)} eps...')\n","logging.info(f'Remaining episoded should be {len(episodes) - len(rm_eps_idx)} eps.')\n","final_eps = [(start,end) for start, end in episodes if (end-start) >= mean_timestep]\n","\n","assert len(episodes) - len(rm_eps_idx) == len(final_eps), \"Error: Episodes size\"\n","\n","final_obs = [arrayObservations[start:end] for start, end in final_eps]\n","final_act = [arrayActions[start:end] for start, end in final_eps]\n","final_rew = [arrayRewards[start:end] for start, end in final_eps]\n","final_ter = [arrayTerminals[start:end] for start, end in final_eps]\n","\n","final_obs = np.concatenate(final_obs, axis=0)\n","final_act = np.concatenate(final_act, axis=0)\n","final_rew = np.concatenate(final_rew, axis=0)\n","final_ter = np.concatenate(final_ter, axis=0)\n","\n","logging.info(f'Final total samples: {final_obs.shape[0]} out of {arrayObservations.shape[0]} original samples.')"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["[9, 25, 37, 47, 57]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["terminals_pos, num_episodes = get_episodes(arrayTerminals)\n","terminals_pos[:5]"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","      dtype=float32)"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["dataset['terminals'][:50]"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["rtgs = optimized_get_rtgs(terminals_pos, dataset['rewards'])"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["[(0, 10), (10, 26), (26, 38), (38, 48), (48, 58)]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["episodes = list_episodes(terminals_pos)\n","episodes[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timesteps,steps_per_ep = get_timesteps(episodes[:5], len(terminals_pos))\n","timesteps, steps_per_ep"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["16"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["np.max(steps_per_ep)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["1019.9430876479018"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["np.max(rtgs)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,\n","        8,  9, 10, 11, 12, 13, 14, 15])"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["timesteps[0:25]"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"data":{"text/plain":["array([3, 6, 8])"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["A = np.array([0,0,0,1,0,0,1,0,1])\n","B = np.where(A ==1)[0]\n","B"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["terminals = np.array([0,0,0,1,0,0,1,0,1], dtype=int)\n","input = np.array(np.arange(len(terminals)), dtype=int)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["(array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([0, 0, 0, 1, 0, 0, 1, 0, 1]))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["input, terminals"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["array([3, 6, 8])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["terminal_pos=np.where(terminals==1)[0]\n","terminal_pos"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<zip object at 0x7f446622e700>\n","<zip object at 0x7f446622e700>\n","<zip object at 0x7f4466820780>\n"]}],"source":["episodes = list_episodes(terminal_pos)\n","\n","# Initialize the array of timesteps\n","arrayTimesteps = np.zeros(len(input), dtype=int)\n","\n","# List to hold the total steps per episode\n","steps_per_episode = []\n","\n","# Generate timesteps for each episode\n","for start, end in episodes:\n","    print(zip(episode_starts, episode_ends))\n","    episode_length = end - start\n","    steps_per_episode.append(episode_length)\n","    arrayTimesteps[start:end] = np.arange(episode_length)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_obs = [final_obs[start:end] for start, end in train_episodes]\n","train_act = [final_act[start:end] for start, end in train_episodes]\n","train_rew = [final_rew[start:end] for start, end in train_episodes]\n","train_ter = [final_ter[start:end] for start, end in train_episodes]\n","\n","final_train_obs = np.concatenate(train_obs, axis=0)\n","final_train_act = np.concatenate(train_act, axis=0)\n","final_train_rew = np.concatenate(train_rew, axis=0)\n","final_train_ter = np.concatenate(train_ter, axis=0)\n","\n","val_obs = [final_obs[start:end] for start, end in val_episodes]\n","val_act = [final_act[start:end] for start, end in val_episodes]\n","val_rew = [final_rew[start:end] for start, end in val_episodes]\n","val_ter = [final_ter[start:end] for start, end in val_episodes]\n","\n","final_val_obs = np.concatenate(val_obs, axis=0)\n","final_val_act = np.concatenate(val_act, axis=0)\n","final_val_rew = np.concatenate(val_rew, axis=0)\n","final_val_ter = np.concatenate(val_ter, axis=0)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["(array([0, 1, 2, 3, 0, 1, 2, 0, 1]), [4, 3, 2])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["arrayTimesteps, steps_per_episode"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","El episodio con mayor numero de timesteps de nuestro dataset durÃ³ un total de 1001 timesteps\n"]}],"source":["max_timesteps = max(timesteps)\n","print(\"\\nEl episodio con mayor numero de timesteps de nuestro dataset durÃ³ un total de\",max_timesteps,\"timesteps\")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class MyDataset(Dataset):\n","    def __init__(self, observations, actions, steps, rtgs, terminals, blocks):\n","        self.observations = observations\n","        self.actions = actions\n","        self.steps = steps\n","        self.rtgs = rtgs\n","        self.terminals = terminals\n","        self.blocks = blocks\n","\n","    def __len__(self):\n","        return len(self.observations)\n","\n","    def __getitem__(self, idx):\n","        # to avoid blocks in between of 2 trajectories, if the idx is too close to the end of a trajectory, re-position\n","        # the idx to a block_size away to the end of the trajectory\n","        episode_ends = np.array(self.terminals)\n","        episode_starts=np.roll(episode_ends, shift=1) + 1\n","        episode_starts[0] = 0\n","\n","        print(\"episode start\", len(episode_starts))\n","        print(\"episode end\", len(episode_ends))\n","        print(idx)\n","        start, end = list(zip(episode_starts, episode_ends +1))[idx]\n","\n","        episode_length = end - start\n","\n","        # Sample a start point for the sequence within the episode\n","        if episode_length >= self.blocks:\n","            seq_start = np.random.randint(start, end - self.blocks + 1)\n","            seq_end = seq_start + self.blocks\n","            n_padding = 0\n","        else:\n","            seq_start = start\n","            seq_end = start + episode_length - 1\n","            n_padding = self.blocks - episode_length + 1\n","        \n","\n","        states = (self.observations[seq_start : seq_end])\n","        actions = (self.actions[seq_start : seq_end])\n","        rtgs = (self.rtgs[seq_start : seq_end])\n","        steps = (self.steps)\n","        \n","        if n_padding > 0:\n","            padding = np.zeros(n_padding)\n","\n","            states = np.concatenate(states, padding)\n","            actions = np.concatenate(actions, padding)\n","            rtgs = np.concatenate(rtgs, padding)\n","            steps = np.concatenate(steps, padding)\n","        \n","        states = torch.FloatTensor(states)\n","        actions = torch.FloatTensor(actions)\n","        rtgs = torch.FloatTensor(rtgs)\n","        steps = torch.FloatTensor(steps)\n","\n","        return states, actions, rtgs, steps"]},{"cell_type":"markdown","metadata":{},"source":["### DataSet && DataLoader"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["blocks = 16\n","dataset = MyDataset(arrayObservations, arrayActions, timesteps, rtgs, terminals_pos, blocks)\n","\n","DTDataLoader = DataLoader(dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["\n","# Definimos la funciÃ³n de pÃ©rdida\n","criterion = nn.MSELoss()\n","\n","# Definir el optimizador\n","optimizer = optim.Adam(model_dt.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{},"source":["### Train"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["episode start 581\n","episode end 581\n","0\n"]},{"ename":"TypeError","evalue":"only integer scalar arrays can be converted to a scalar index","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# Inicializar la pÃ©rdida total para el epoch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# IteraciÃ³n sobre los lotes de datos\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m states, actions, rtgs, steps \u001b[38;5;129;01min\u001b[39;00m DTDataLoader:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Paso 1: Reiniciar los gradientes\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#timestep += 1 ==> No es necesario para el training, solo para evaluation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Paso 2: PropagaciÃ³n hacia adelante (Forward pass)\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/anaconda3/envs/aidl-bullet/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[17], line 48\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_padding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     46\u001b[0m     padding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_padding)\n\u001b[0;32m---> 48\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(actions, padding)\n\u001b[1;32m     50\u001b[0m     rtgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(rtgs, padding)\n","\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"]}],"source":["#Bucle de training\n","\n","num_epochs = 5\n","timestep = 0\n","max_timesteps = max_timesteps #Calculated according to the longest episode in the dataset/env loaded.\n","for epoch in range(num_epochs):\n","    total_loss = 0.0  # Inicializar la pÃ©rdida total para el epoch\n","\n","    # IteraciÃ³n sobre los lotes de datos\n","\n","    for states, actions, rtgs, steps in DTDataLoader:\n","        # Paso 1: Reiniciar los gradientes\n","        #timestep += 1 ==> No es necesario para el training, solo para evaluation\n","        optimizer.zero_grad()\n","\n","        # Paso 2: PropagaciÃ³n hacia adelante (Forward pass)\n","        _, _, act_preds = model_dt(steps, max_timesteps, states, actions, rtgs) # timestep, max_timesteps, states, actions, returns_to_go\n","        #outputs = model(batch_obs)\n","\n","        # Paso 3: Calcular la pÃ©rdida\n","        loss = criterion(act_preds, actions)\n","\n","        # Paso 4: PropagaciÃ³n hacia atrÃ¡s (Backward pass)\n","        loss.backward()\n","\n","        # Paso 5: ActualizaciÃ³n de los parÃ¡metros del modelo\n","        optimizer.step()\n","\n","        # Sumar la pÃ©rdida del batch a la pÃ©rdida total del epoch\n","        total_loss += loss.item()\n","\n","    # Calcular la pÃ©rdida media del epoch\n","    epoch_loss = total_loss / len(DTDataLoader)\n","\n","    # Imprimir la pÃ©rdida media del epoch\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n","\n","    # Paso 6 (Opcional): EvaluaciÃ³n del modelo en un conjunto de datos de evaluaciÃ³n\n","    # AquÃ­ puedes agregar cÃ³digo para evaluar el modelo en un conjunto de datos de evaluaciÃ³n si lo tienes disponible\n","\n","# Paso 7 (Opcional): VisualizaciÃ³n de resultados o mÃ©tricas de rendimiento\n","# AquÃ­ puedes agregar cÃ³digo para mostrar otras mÃ©tricas de rendimiento que desees analizar"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["episode_ends = np.array([3,7,15])\n","episode_starts = np.roll(A, shift=1)+ 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 4, 8])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["episode_starts\n","episode_starts[0] = 0\n","episode_starts"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["[(0, 4), (4, 8), (8, 16)]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["a = list(zip(episode_starts, episode_ends +1))\n","a\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Mostramos los maximos rewards para los Terminal=1 recogidos en \"terminal_pos\"\n","\n","sample=terminal_pos[0]\n","print(\"\\nRewards example:\",arrayRewards[sample])\n","\n","#Construimos el array de rewards to go\n","arrayReturnToGo = []\n","\n","for i in terminal_pos:\n","    arrayReturnToGo.append(arrayRewards[i])\n","\n","len(arrayReturnToGo)\n","\n","#Creamos tensor de Returnstogo\n","tensorReturnToGo = torch.FloatTensor(arrayReturnToGo)\n","tensorReturnToGo.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos un array \"timesteps\" donde se identificaran los timesteps para cada episodio respecto al total del dataset\n","def get_timestep():\n","    start_index = 0\n","    arrayTimesteps = np.zeros(len(arrayActions), dtype=int)\n","    for i in terminal_pos:\n","        arrayTimesteps[start_index:i] = np.arange(i - start_index)\n","        start_index = i\n","    return arrayTimesteps\n","print(\"\\nEl array Timesteps tendra la misma dimension que las samples del dataset:\",len(arrayTimesteps),\" samples\")\n","print(\"\\nEjemplo muestreo hasta el episodio 25:\\n\", arrayTimesteps[0:25])\n","\n","#Comprovamos en el dataset (concretamente en el arrayTimesteps), cual es el episodio mas largo. Ese sera nuestro \"max_timesteps\"\n","max_timesteps = max(arrayTimesteps)\n","print(\"\\nEl episodio con mayor numero de timesteps de nuestro dataset durÃ³ un total de\",max_timesteps,\"timesteps\")\n","\n","#Lo convertimos a tensor\n","tensorTimesteps = torch.FloatTensor(arrayTimesteps)\n","#tensorTimesteps.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prueba_omar = np.unique(arrayActions[0:20])\n","print('action possible numbers: ',prueba_omar )\n","#assert hparams['vocab_size'] == len(np.unique(arrayActions))\n","len(prueba_omar)\n","\n","arrayActions[0:20]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#We transform all the arrays to Float tensors\n","if torch.cuda.is_available():\n","  tensorObservations = torch.cuda.FloatTensor(arrayObservations)\n","  tensorActions = torch.cuda.FloatTensor(arrayActions)\n","  tensorRewards = torch.cuda.FloatTensor(arrayRewards)\n","  tensorTerminals = torch.cuda.FloatTensor(arrayTerminals)\n","  print(\"\\n Tensors in the GPU\")\n","  print(\"\\n////////////////////////////////////////////////////////////////////////////////\")\n","else:\n","  tensorObservations = torch.FloatTensor(arrayObservations)\n","  tensorActions = torch.FloatTensor(arrayActions)\n","  tensorRewards = torch.FloatTensor(arrayRewards)\n","  tensorTerminals = torch.FloatTensor(arrayTerminals)\n","  print(\"\\n Tensors in the CPU\")\n","\n","# Tensors shape\n","print(\"\\nObservations shape:\",tensorObservations.shape)\n","print(\"\\nActions shape:\",tensorActions.shape)\n","print(\"\\nRewards shape:\",tensorRewards.shape)\n","print(\"\\nTerminals shape:\",tensorTerminals.shape)\n","print(\"\\n////////////////////////////////////////////////////////////////////////////////\")\n","\n","sample = 59343\n","# Tensors content at certain timestep\n","print(\"\\nObservations example:\",tensorObservations[sample])\n","print(\"\\nActions example:\",tensorActions[sample])\n","print(\"\\nRewards example:\",tensorRewards[sample])\n","print(\"\\nTerminals example:\",tensorTerminals[sample])"]},{"cell_type":"markdown","metadata":{"id":"ZfbaABN2gpMP"},"source":["# Pasar este dataset al DT (Shuang/Omar)!!!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4476,"status":"ok","timestamp":1707075864981,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"9X78mWt6iwIR","outputId":"a1025993-822d-4118-834a-29fe7e38aca3"},"outputs":[],"source":["#Source: PyBullet Environment: https://pybullet.org/wordpress/\n","#                              https://github.com/bulletphysics/bullet3/tree/master\n","\n","import numpy as np\n","import gym\n","import pybullet_envs\n","import argparse\n","import os\n","import torch\n","\n","from tqdm import tqdm\n","#from .sac import SAC, seed_everything\n","#from .utility import save_buffer\n","\n","\n","def collect(env, sac, logdir, final_step, deterministic):\n","    buffer = []\n","    frames = []\n","\n","    step = 0\n","    pbar = tqdm(total=final_step)\n","    while step < final_step:\n","        obs_t = env.reset()\n","        ter_t = False\n","        rew_t = 0.0\n","\n","\n","        while step < final_step and not ter_t:\n","            #act_t = sac.act([obs_t], deterministic=deterministic)[0] #SAC (Soft Actor Critic) es un algoritmo de RL\n","            frames.append(env.render(mode=\"rgb_array\"))\n","            act_t = env.action_space.sample() # Temporal. Aqui tendriamos que la salida/action del DT.\n","            buffer.append([obs_t, act_t, [rew_t], [ter_t]])\n","\n","            obs_t, rew_t, ter_t, _ = env.step(act_t)   #O.Aguilera (04/02/2024): La dimensio no es correcte.\n","\n","            step += 1\n","            pbar.update(1)\n","\n","        if ter_t:\n","            buffer.append([obs_t, np.zeros_like(act_t), [rew_t], [ter_t]])\n","\n","    #save_buffer(buffer[:final_step], logdir)\n","\n","    print('Collected data has been saved.')\n","    return frames\n","\n","''' if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--env', type=str)\n","    parser.add_argument('--seed', type=int, default=0)\n","    parser.add_argument('--final-step', type=int, default=1000000) #\n","    parser.add_argument('--load', type=str)\n","    parser.add_argument('--gpu', action='store_true')\n","    args = parser.parse_args() '''\n","\n","#env = gym.make(args.env)\n","env = gym.make('hopper-bullet-mixed-v0')\n","#env.seed(args.seed)\n","env.seed(1)\n","#seed_everything(args.seed)\n","#seed_everything(1)\n","\n","observation_size = env.observation_space.shape[0]\n","action_size = env.action_space.shape[0]\n","device = 'cuda:0'\n","\n","#sac = SAC(observation_size, action_size, device)\n","'''\n","if args.load:\n","    sac.load(args.load)\n","    name = 'medium'\n","    deterministic = True\n","else:'''\n","name = 'random'\n","deterministic = False\n","\n","#logdir = os.path.join('logs', '{}_{}_{}'.format(args.env, name, args.seed))\n","#os.makedirs(logdir)\n","\n","\n","prova=collect(env, None, None, 100, deterministic)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1707075893010,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"5ZZdymFuo-CM","outputId":"63bc8868-19a7-4e82-bbda-8b6448e3cac2"},"outputs":[],"source":["prova[0]\n","prova[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":2268,"status":"ok","timestamp":1707075967418,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"0qz16feApxN-","outputId":"8ecd95c7-f127-463b-918e-2d7b7a0f144b"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","plt.imshow(prova[0], interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793},"executionInfo":{"elapsed":13985,"status":"ok","timestamp":1707076061860,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"hWjXpRikoxHC","outputId":"d4c4a8f8-df3d-4f22-ec96-2754eeef1197"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":17,"status":"error","timestamp":1707242998732,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"cO_CMXRVqdUd","outputId":"d04f2456-fd48-465c-e041-c33bd1401157"},"outputs":[],"source":["from notebook_video_writer import VideoWriter\n","with VideoWriter(fps=40) as vw:\n","    for i in range(len(prova)):\n","        vw.add(prova[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1707076908060,"user":{"displayName":"Omar Aguilera","userId":"14215123272507422446"},"user_tz":-60},"id":"87dKrBuaoJFq","outputId":"c3495c99-361a-4c49-b51f-3b9862b31903"},"outputs":[],"source":["env = gym.make('hopper-bullet-mixed-v0')\n","print(env.action_space.sample())"]},{"cell_type":"markdown","metadata":{"id":"Na1sduHdtoOe"},"source":["## Notas Google Meet Domingo 04/02/2024\n","\n","\n","Edgar Planell\n","19:33\n","https://github.com/takuseno/d4rl-pybullet/blob/master/requirements.txt\n","\n","Edgar Planell\n","19:37\n","pip install git+https://github.com/takuseno/d4rl-pybullet\n","\n","Edgar Planell\n","19:59\n","pip setuptools wheel\n","\n","TÃº\n","19:59\n","brew install hdf5\n","\n","Edgar Planell\n","20:01\n","versioned-hdf5\n","\n","Edgar Planell\n","20:13\n","    import numpy as np\n","    import gym\n","    import pybullet_envs\n","    import argparse\n","    import os\n","\n","    from tqdm import tqdm\n","    from .sac import SAC, seed_everything\n","    from .utility import save_buffer\n","\n","\n","    def collect(env, sac, logdir, final_step, deterministic):\n","        buffer = []\n","\n","        step = 0\n","        pbar = tqdm(total=final_step)\n","        while step < final_step:\n","            obs_t = env.reset()\n","            ter_t = False\n","            rew_t = 0.0\n","            while step < final_step and not ter_t:\n","                act_t = sac.act([obs_t], deterministic=determin\n","\n","      import numpy as np\n","      import gym\n","      import pybullet_envs\n","      import argparse\n","      import os\n","\n","      from tqdm import tqdm\n","      from .sac import SAC, seed_everything\n","      from .utility import save_buffer\n","\n","\n","      def collect(env, sac, logdir, final_step, deterministic):\n","          buffer = []\n","\n","          step = 0\n","          pbar = tqdm(total=final_step)\n","          while step < final_step:\n","              obs_t = env.reset()\n","              ter_t = False\n","              rew_t = 0.0\n","              while step < final_step and not ter_t:\n","                  act_t = sac.act([obs_t], deterministic=determin\n","https://github.com/takuseno/d4rl-pybullet/blob/master/d4rl_pybullet/collect.py\n","\n","Edgar Planell\n","20:30\n","https://github.com/bulletphysics/bullet3/tree/master\n","\n","Edgar Planell\n","20:32\n","https://github.com/bulletphysics/bullet3/blob/master/examples/pybullet/gym/pybullet_examples/biped2d_pybullet.py\n","\n","Edgar Planell\n","20:37\n","https://github.com/benelot/pybullet-gym/tree/master\n","\n","Josep Maria Bach RamÃ­rez\n","20:43\n","env.render(mode=\"rgb_array\")\n","\n","Josep Maria Bach RamÃ­rez\n","20:45\n","from matplotlib import pyplot as plt\n","plt.imshow(prova[0], interpolation='nearest')\n","plt.show()\n","\n","Josep Maria Bach RamÃ­rez\n","20:47\n","!apt-get install ffmpeg\n","!pip install notebook-video-writer\n","\n","Josep Maria Bach RamÃ­rez\n","20:48\n","from notebook_video_writer import VideoWriter\n","with VideoWriter(fps=40) as vw:\n","    for i in range(len(prova)):\n","        vw.add(prova[i])\n","        \n","Josep Maria Bach RamÃ­rez\n","20:52\n","https://gymnasium.farama.org/api/env/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Og2T3r8m_YR"},"outputs":[],"source":["''' import pybullet as p\n","import pybullet_data\n","import os\n","import time\n","GRAVITY = -9.8\n","dt = 1e-3\n","iters = 2000\n","import pybullet_data\n","\n","physicsClient = p.connect(p.GUI)\n","p.setAdditionalSearchPath(pybullet_data.getDataPath())\n","p.resetSimulation()\n","#p.setRealTimeSimulation(True)\n","p.setGravity(0, 0, GRAVITY)\n","p.setTimeStep(dt)\n","planeId = p.loadURDF(\"plane.urdf\")\n","cubeStartPos = [0, 0, 1.13]\n","cubeStartOrientation = p.getQuaternionFromEuler([0., 0, 0])\n","botId = p.loadURDF(\"biped/biped2d_pybullet.urdf\", cubeStartPos, cubeStartOrientation)\n","\n","#disable the default velocity motors\n","#and set some position control with small force to emulate joint friction/return to a rest pose\n","jointFrictionForce = 1\n","for joint in range(p.getNumJoints(botId)):\n","  p.setJointMotorControl2(botId, joint, p.POSITION_CONTROL, force=jointFrictionForce)\n","\n","#for i in range(10000):\n","#     p.setJointMotorControl2(botId, 1, p.TORQUE_CONTROL, force=1098.0)\n","#     p.stepSimulation()\n","#import ipdb\n","#ipdb.set_trace()\n","import time\n","p.setRealTimeSimulation(1)\n","while (1):\n","  #p.stepSimulation()\n","  #p.setJointMotorControl2(botId, 1, p.TORQUE_CONTROL, force=1098.0)\n","  p.setGravity(0, 0, GRAVITY)\n","  time.sleep(1 / 240.)\n","time.sleep(1000) '''"]}],"metadata":{"colab":{"provenance":[{"file_id":"11OpZevRdnWN9dDLwj3OdXT2sDwBwxJec","timestamp":1707249437132}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
