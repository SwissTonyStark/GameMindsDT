{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/takuseno/d4rl-atari\n",
        "\n",
        "# ACHTUNG You will get an error but don't worry. Press the button 'restart session' and run this cell again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fhg-3TX6CQY",
        "outputId": "07023cee-3889-48cc-d1e9-08151a0f8955"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/takuseno/d4rl-atari\n",
            "  Cloning https://github.com/takuseno/d4rl-atari to /tmp/pip-req-build-2xmrmw38\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/takuseno/d4rl-atari /tmp/pip-req-build-2xmrmw38\n",
            "  Resolved https://github.com/takuseno/d4rl-atari to commit 039d1a935ca932b916c544feaa63b9b6ae73e293\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: atari-py in /usr/local/lib/python3.10/dist-packages (from d4rl-atari==0.1) (0.2.9)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from d4rl-atari==0.1) (0.25.2)\n",
            "Requirement already satisfied: gsutil in /usr/local/lib/python3.10/dist-packages (from d4rl-atari==0.1) (5.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from d4rl-atari==0.1) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from d4rl-atari==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from atari-py->d4rl-atari==0.1) (1.16.0)\n",
            "Requirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (3.2.2)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (1.7)\n",
            "Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (0.19)\n",
            "Requirement already satisfied: gcs-oauth2-boto-plugin>=3.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (3.0)\n",
            "Requirement already satisfied: google-apitools>=0.5.32 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (0.5.32)\n",
            "Requirement already satisfied: httplib2==0.20.4 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (0.20.4)\n",
            "Requirement already satisfied: google-reauth>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (0.1.1)\n",
            "Requirement already satisfied: monotonic>=1.4 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (1.6)\n",
            "Requirement already satisfied: pyOpenSSL>=0.13 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (24.0.0)\n",
            "Requirement already satisfied: retry-decorator>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (1.1.1)\n",
            "Requirement already satisfied: google-auth[aiohttp]>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->d4rl-atari==0.1) (2.17.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2==0.20.4->gsutil->d4rl-atari==0.1) (3.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->d4rl-atari==0.1) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->d4rl-atari==0.1) (0.0.8)\n",
            "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.10/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->d4rl-atari==0.1) (4.7.2)\n",
            "Requirement already satisfied: boto>=2.29.1 in /usr/local/lib/python3.10/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->d4rl-atari==0.1) (2.49.0)\n",
            "Requirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil->d4rl-atari==0.1) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil->d4rl-atari==0.1) (0.5.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (0.3.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (2.31.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (3.9.3)\n",
            "Requirement already satisfied: pyu2f in /usr/local/lib/python3.10/dist-packages (from google-reauth>=0.1.0->gsutil->d4rl-atari==0.1) (0.1.5)\n",
            "Requirement already satisfied: cryptography<43,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=0.13->gsutil->d4rl-atari==0.1) (42.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (4.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43,>=41.0.5->pyOpenSSL>=0.13->gsutil->d4rl-atari==0.1) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil->d4rl-atari==0.1) (2023.11.17)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43,>=41.0.5->pyOpenSSL>=0.13->gsutil->d4rl-atari==0.1) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO maybe it's not necessary\n",
        "!pip install gym[atari]\n",
        "!pip install autorom[accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLzbZo0z6IY2",
        "outputId": "2190f960-0c91-46a1-fde5-529db968750d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (0.0.8)\n",
            "Collecting ale-py~=0.7.5 (from gym[atari])\n",
            "  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[atari]) (6.1.1)\n",
            "Installing collected packages: ale-py\n",
            "Successfully installed ale-py-0.7.5\n",
            "Collecting autorom[accept-rom-license]\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]) (2023.11.17)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=75409d4538adedabbad4f3cbf6550b958fc3b4a37c35aacdea74f3d093e375aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DECISION TRANSFORMER\n",
        "A new class that inherits from  GPT2 model but modifying the input and output to work with sequences of actions, states and returns-to-go.\n",
        "\n",
        "inspired in\n",
        "https://github.com/kzl/decision-transformer\n",
        "\n",
        "A modification of the Hugging Face transformer.\n",
        "look at: gym/decision_transformer/decision_transformer.py\n"
      ],
      "metadata": {
        "id": "kHthx6_zjoaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "OPv4bFlo2-7G"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer architecture\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://lilianweng.github.io/lil-log/assets/images/transformer.png\" width=\"1000px\" alt=\"Zoom in to the Transformer\"/>\n",
        "</p>"
      ],
      "metadata": {
        "id": "wekMUPvt4Xdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ATTENTION"
      ],
      "metadata": {
        "id": "i_rPVTib4zNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default GPT2 values?\n",
        "hparams = {\n",
        "    'n_layer':6, # num of blocks?\n",
        "    'n_head': 8, #\n",
        "    'n_embd':128,\n",
        "    'context_length':30,\n",
        "    'block_size':90, # context_length * 3\n",
        "    'dropout':0.1, # dropout value\n",
        "    'bias': True, # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster. warning! nn.LayerNorm doesn't support bias=False\n",
        "    'vocab_size':4, # in breakout, 6 in Pong\n",
        "    'batch_size': 2,\n",
        "    'model_type':'reward_conditioned',\n",
        "    'num_workers': 4,\n",
        "    'max_timesteps': 2654,\n",
        "    'path': '/content/',\n",
        "}"
      ],
      "metadata": {
        "id": "3C8ay4GGDWI9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
        "    It is possible to use torch.nn.MultiheadAttention\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_embd = hparams['n_embd'] # embeding dimensionality, includes all heads\n",
        "        self.n_head = hparams['n_head'] #  num heads\n",
        "        self.block_size = hparams['block_size']\n",
        "        assert self.n_embd % self.n_head == 0\n",
        "\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.key = nn.Linear(self.n_embd, self.n_embd, bias=hparams['bias'])\n",
        "        self.query = nn.Linear(self.n_embd, self.n_embd, bias=hparams['bias'])\n",
        "        self.value = nn.Linear(self.n_embd, self.n_embd, bias=hparams['bias'])\n",
        "\n",
        "        # regularization\n",
        "        self.attn_drop = nn.Dropout(hparams['dropout'])\n",
        "        self.resid_drop = nn.Dropout(hparams['dropout'])\n",
        "\n",
        "        # output projection\n",
        "        self.proj = nn.Linear(self.n_embd, self.n_embd, bias=hparams['bias'])\n",
        "\n",
        "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "        # every token only comunicates with the previous ones\n",
        "        # This is typically used to register a buffer that should not to be considered a model parameter.\n",
        "        # creates -> self.mask\n",
        "        #self.register_buffer(\"mask\", torch.tril(torch.ones(self.block_size, self.block_size))\n",
        "        #                             .view(1, 1, self.block_size, self.block_size))\n",
        "        self.register_buffer(\"mask\", torch.tril(torch.ones(self.block_size + 1, self.block_size + 1))\n",
        "                                     .view(1, 1, self.block_size + 1, self.block_size + 1))\n",
        "\n",
        "        #self._reset_parameters() # uncomment if we need to initialize as the original transformer\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        # Original Transformer initialization\n",
        "        nn.init.xavier_uniform_(self.c_attn.weight)\n",
        "        nn.init.xavier_uniform_(self.proj.weight)\n",
        "        self.c_attn.bias.data.fill_(0)\n",
        "        self.proj.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        head_size = self.n_head, C // self.n_head\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, seqLen, numHeads, headSize) -> (B, numHeads, seqLen, headSize)\n",
        "        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, numHeads, seqLen, headSize) x (B, numHeads, headSize, seqLen) -> (B, numHeads, seqLen, seqLen)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf')) # aplying the softmax -inf become 0\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_drop(att)\n",
        "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.proj(y)\n",
        "        y = self.resid_drop(y)\n",
        "        return y"
      ],
      "metadata": {
        "id": "2ikQ6v2l4xBW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MLP"
      ],
      "metadata": {
        "id": "SaTWkxbwPZIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2MLP(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_embd = hparams['n_embd']\n",
        "\n",
        "        self.c_fc    = nn.Linear(self.n_embd, 4 * self.n_embd, bias=hparams['bias']) # expand to dim*4\n",
        "        self.act    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * self.n_embd, self.n_embd, bias=hparams['bias'])\n",
        "        self.dropout = nn.Dropout(hparams['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.act(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "40LRBd5rPXgx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BLOCK\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://www.researchgate.net/publication/365625866/figure/fig2/AS:11431281098698218@1669051398448/Structure-of-the-applied-GPT-2-medium-architecture_W640.jpg\" width=\"280px\" alt=\"Zoom in to the Transformer\"/>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "3hovnlOXfBzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_embd = hparams['n_embd']\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(self.n_embd, bias=hparams['bias'])\n",
        "        self.ln2 = nn.LayerNorm(self.n_embd, bias=hparams['bias'])\n",
        "        self.attn = CausalSelfAttention()\n",
        "        #self.mlp = GPT2MLP()\n",
        "        self.mlp = nn.Sequential(\n",
        "          nn.Linear(self.n_embd, 4 * self.n_embd, bias=hparams['bias']), # expand to dim*4\n",
        "          nn.GELU(),\n",
        "          nn.Linear(4 * self.n_embd, self.n_embd, bias=hparams['bias']),\n",
        "          nn.Dropout(hparams['dropout'])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x)) # LayerNorm -> attention -> Add ???? no hauria de layerNOrm després de l'attention?\n",
        "        x = x + self.mlp(self.ln2(x)) # like x = self.ln_2(x + self.mlp(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "jaZwlkh4fGQQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRANSFORMER style GTP2\n",
        "\n",
        "https://d2l.ai/_images/vit.svg"
      ],
      "metadata": {
        "id": "tmsL7TpX6l-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "    \"\"\" GPT Language Model \"\"\"\n",
        "\n",
        "    def __init__(self, max_timestep):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block_size = hparams['block_size']\n",
        "        self.vocab_size = hparams['vocab_size']\n",
        "        self.n_embd = hparams['n_embd']\n",
        "        self.model_type = hparams['model_type']\n",
        "        self.max_timestep = max_timestep\n",
        "\n",
        "        # input embedding stem\n",
        "        self.tok_emb = nn.Embedding(self.vocab_size, self.n_embd)  # n_embd includes all heads -> tok embedding\n",
        "        # self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, self.block_size + 1, self.n_embd))\n",
        "        self.global_pos_emb = nn.Parameter(torch.zeros(1, self.max_timestep+1, self.n_embd))\n",
        "        self.drop = nn.Dropout(hparams['dropout'])\n",
        "\n",
        "        # transformer\n",
        "        #self.blocks = nn.ModuleList([GPT2Block() for _ in range(hparams['n_layer'])])\n",
        "        self.blocks = nn.Sequential(*[Block() for _ in range(hparams['n_layer'])])\n",
        "\n",
        "        # decoder head\n",
        "        self.ln_f = nn.LayerNorm(self.n_embd)\n",
        "\n",
        "        # out linear\n",
        "        self.head = nn.Linear(self.n_embd, self.vocab_size, bias=False)\n",
        "\n",
        "        # init all weights, and apply a special scaled init to the residual projections, per GPT-2 paper\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # STATE encoding\n",
        "        self.state_encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 32, 8, stride=4, padding=0), # stack 4 frames -> 4 channel in\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, self.n_embd),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # RETURN embedding\n",
        "        self.ret_emb = nn.Sequential(\n",
        "            nn.Linear(1, self.n_embd),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # ACTION embedding\n",
        "        self.action_embeddings = nn.Sequential(\n",
        "            nn.Embedding(self.vocab_size, self.n_embd),\n",
        "            nn.Tanh())\n",
        "        # initialization\n",
        "        nn.init.normal_(self.action_embeddings[0].weight, mean=0.0, std=0.02)\n",
        "\n",
        "\n",
        "        # report number of parameters\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        print(\"number of parameters: %.2fM\" % (n_params/1e6,))\n",
        "\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    # state, action, and return\n",
        "    def forward(self, states, actions, targets=None, rtgs=None, timesteps=None):\n",
        "        # states: (batch, block_size, 4*84*84)\n",
        "        # actions: (batch, block_size, 1)\n",
        "        # targets: (batch, block_size, 1)\n",
        "        # rtgs: (batch, block_size, 1)\n",
        "        # timesteps: (batch, 1, 1)\n",
        "        #batch_size = states.shape[0]\n",
        "\n",
        "\n",
        "        # PLAN:\n",
        "        # 1. Compute embeddings for tokens\n",
        "        # pos_embedding = embed_t(t) # per-timestep (note: not per-token)\n",
        "        # s_embedding = embed_s(s) + pos_embedding\n",
        "        # a_embedding = embed_s(a) + pos_embedding\n",
        "        # R_embedding = embed_R(R) + pos_embedding\n",
        "\n",
        "        # STATE embedding\n",
        "        # TODO STACK*4 i gestionar blocks de 4 imatges x capturar moviment\n",
        "        state_embeddings = self.state_encoder(states.reshape(-1, 4, 84, 84).type(torch.float32).contiguous()) # (batch * block_size, n_embd)\n",
        "\n",
        "        #state_embeddings = self.state_encoder(states) # (batch * block_size, n_embd)\n",
        "        state_embeddings = state_embeddings.reshape(states.shape[0], states.shape[1], self.n_embd) # (batch, block_size, n_embd)\n",
        "\n",
        "        # create tokens\n",
        "        if actions is not None and self.model_type == 'reward_conditioned':\n",
        "            # RETURN & ACTION embeddings\n",
        "            rtg_embeddings = self.ret_emb(rtgs.type(torch.float32))\n",
        "            action_embeddings = self.action_embeddings(actions.type(torch.long).squeeze(-1)) # (batch, block_size, n_embd)\n",
        "\n",
        "            # token_embeddings inclou els 3 embeddings\n",
        "            token_embeddings = torch.zeros((states.shape[0], states.shape[1]*3 - int(targets is None), self.n_embd), dtype=torch.float32, device=state_embeddings.device)\n",
        "            token_embeddings[:,::3,:] = rtg_embeddings\n",
        "            token_embeddings[:,1::3,:] = state_embeddings\n",
        "            token_embeddings[:,2::3,:] = action_embeddings[:,-states.shape[1] + int(targets is None):,:]\n",
        "        elif actions is None and self.model_type == 'reward_conditioned': # only happens at very first timestep of evaluation\n",
        "            rtg_embeddings = self.ret_emb(rtgs.type(torch.float32))\n",
        "\n",
        "            token_embeddings = torch.zeros((states.shape[0], states.shape[1]*2, self.n_embd), dtype=torch.float32, device=state_embeddings.device)\n",
        "            token_embeddings[:,::2,:] = rtg_embeddings # really just [:,0,:]\n",
        "            token_embeddings[:,1::2,:] = state_embeddings # really just [:,1,:]\n",
        "        elif actions is not None and self.model_type == 'naive':\n",
        "            action_embeddings = self.action_embeddings(actions.type(torch.long).squeeze(-1)) # (batch, block_size, n_embd)\n",
        "\n",
        "            token_embeddings = torch.zeros((states.shape[0], states.shape[1]*2 - int(targets is None), self.n_embd), dtype=torch.float32, device=state_embeddings.device)\n",
        "            token_embeddings[:,::2,:] = state_embeddings\n",
        "            token_embeddings[:,1::2,:] = action_embeddings[:,-states.shape[1] + int(targets is None):,:]\n",
        "        elif actions is None and self.model_type == 'naive': # only happens at very first timestep of evaluation\n",
        "            token_embeddings = state_embeddings\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "        # 2. interleave tokens as (R_1,s_1, a_1, ...., R_K, s_K)\n",
        "        # input_embeds = stack (R_embedding, s_embedding, a_embeding)\n",
        "        # position embeddings of shape (1, t=seq_len, n_embd)\n",
        "\n",
        "        all_global_pos_emb = torch.repeat_interleave(self.global_pos_emb, hparams['batch_size'], dim=0) # batch_size, traj_length, n_embd\n",
        "        position_embeddings = torch.gather(all_global_pos_emb, 1, torch.repeat_interleave(timesteps, self.n_embd, dim=-1)) + self.pos_emb[:, :token_embeddings.shape[1], :]\n",
        "\n",
        "\n",
        "        # 3. use transformer to get hidden states\n",
        "        # hidden_states = transformer(input_embeds=input_embeds)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        # token embeddings of shape (b, t=seq_len, n_embd)\n",
        "        # position embeddings of shape (1, t=seq_len, n_embd)\n",
        "        # 1 position embedding for every 3 tokens\n",
        "        x = self.drop(token_embeddings + position_embeddings)\n",
        "\n",
        "        x = self.blocks(x)\n",
        "\n",
        "        # 4. select hidden states for action prediction tokens\n",
        "        # a_hidden = unstack(hidden_states).actions\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        if actions is not None and self.model_type == 'reward_conditioned':\n",
        "            logits = logits[:, 1::3, :] # only keep predictions from state_embeddings\n",
        "        elif actions is None and self.model_type == 'reward_conditioned':\n",
        "            logits = logits[:, 1:, :]\n",
        "        elif actions is not None and self.model_type == 'naive':\n",
        "            logits = logits[:, ::2, :] # only keep predictions from state_embeddings\n",
        "        elif actions is None and self.model_type == 'naive':\n",
        "            logits = logits # for completeness\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        #Atari -> discrete actions -> logits = probability of different classes -> loss = cross entropy\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.reshape(-1).long())\n",
        "\n",
        "        # 5. predict action\n",
        "        # return pred_a(a_hidden)\n",
        "        return logits, loss\n",
        "\n"
      ],
      "metadata": {
        "id": "1pDnX5-l6rSp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SET THE ENVIRONMENT"
      ],
      "metadata": {
        "id": "pTP7OlDMtHBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import d4rl_atari\n",
        "# TODO triar l'expert\n",
        "env = gym.make('breakout-mixed-v4', stack=True) # 4 stacked gray-scale images\n",
        "\n",
        "\n",
        "obsservation_0 = env.reset() # (4, 84, 84)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgmere8H6ZNG",
        "outputId": "6e3b73a7-f8c7-4be3-930b-71b0c36ea7dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:137: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'gym.wrappers.frame_stack.LazyFrames'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:226: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
            "  logger.warn(\"Casting input x to numpy array.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP THE DATASET"
      ],
      "metadata": {
        "id": "8Hs-TmZOEEr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_dataset():\n",
        "\n",
        "      # GET THE DATA !!\n",
        "      dataset = env.get_dataset()\n",
        "\n",
        "      obs_data = dataset['observations'] # observation data in (1000000, 1, 84, 84)\n",
        "      action_data = dataset['actions'] # action data in (1000000,)\n",
        "      reward_data = dataset['rewards'] # reward data in (1000000,)\n",
        "      terminal_data = dataset['terminals'] # terminal flags in (1000000,)\n",
        "\n",
        "      plt.imshow(obs_data[1000][0])\n",
        "      plt.show()\n",
        "      print('action_data ', action_data.shape)\n",
        "\n",
        "      terminal_pos = np.where(terminal_data==1)[0]\n",
        "      terminal_data = None # de-allocate mem\n",
        "      print(\"num episodes \", terminal_pos.shape)\n",
        "\n",
        "      # -- create reward-to-go dataset\n",
        "      start_index = 0\n",
        "      rtg = np.zeros_like(reward_data)\n",
        "      for i in terminal_pos:\n",
        "          curr_traj_returns = reward_data[start_index:i]\n",
        "          reward_acum = 0\n",
        "          for j in range(i-1, start_index-1, -1): # start from i-1\n",
        "              reward_acum += reward_data[j]\n",
        "              #rtg_j = curr_traj_returns[j-start_index:i-start_index]\n",
        "              rtg[j] = reward_acum\n",
        "          start_index = i\n",
        "      print('max rtg is %d' % max(rtg))\n",
        "\n",
        "      reward_data = None\n",
        "\n",
        "      # -- create timestep dataset ******************************\n",
        "      start_index = 0\n",
        "      timesteps = np.zeros(len(action_data), dtype=int)\n",
        "      for i in terminal_pos:\n",
        "          timesteps[start_index:i] = np.arange(i - start_index)\n",
        "          start_index = i\n",
        "\n",
        "      max_timestep = max(timesteps)\n",
        "      print('max timestep is %d' % max_timestep)\n",
        "      print(\"***** data loaded **********\")\n",
        "\n",
        "      print('action possible numbers: ', np.unique(action_data))\n",
        "      assert hparams['vocab_size'] == len(np.unique(action_data)), \"hparams['vocab_size'] should be the number of possible action values\"\n",
        "\n",
        "      return obs_data, action_data, terminal_pos, rtg, timesteps, max_timestep\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbJHIqoNn_YQ",
        "outputId": "bdd093ca-1905-4a0a-c349-2036dd87ac50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class that picks up a block of data from the dataset\n",
        "class StateActionReturnDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, actions, done_idxs, rtgs, timesteps):\n",
        "        self.block_size = hparams['block_size'] // 3\n",
        "        self.data = data\n",
        "        self.actions = actions\n",
        "        self.done_idxs = done_idxs\n",
        "        self.rtgs = rtgs\n",
        "        self.timesteps = timesteps\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size * 3\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        block_size = self.block_size\n",
        "        # to avoid blocks in between of 2 trajectories, if the idx is too close to the end of a trajectory, re-position\n",
        "        # the idx to a block_size away to the end of the trajectory\n",
        "        done_idx = idx + block_size\n",
        "        for i in self.done_idxs:\n",
        "            if i > idx: # first done_idx greater than idx\n",
        "                done_idx = min(int(i), done_idx)\n",
        "                break\n",
        "        idx = done_idx - block_size\n",
        "        states = torch.tensor(np.array(self.data[idx:done_idx]), dtype=torch.float32).reshape(block_size, -1) # (block_size, 4*84*84)\n",
        "        states = states / 255. # normalize data\n",
        "        actions = torch.tensor(self.actions[idx:done_idx], dtype=torch.long).unsqueeze(1) # (block_size, 1)\n",
        "        rtgs = torch.tensor(self.rtgs[idx:done_idx], dtype=torch.float32).unsqueeze(1)\n",
        "        timesteps = torch.tensor(self.timesteps[idx:idx+1], dtype=torch.int64).unsqueeze(1) # (1,1) it takes only 1 timestep to represent all the block\n",
        "\n",
        "        return states, actions, rtgs, timesteps"
      ],
      "metadata": {
        "id": "vU89QS67vjWM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING"
      ],
      "metadata": {
        "id": "H0vfA0ytJrlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING PARAMS\n",
        "tparams = {\n",
        "    'max_epochs':10,\n",
        "    'learning_rate':3e-4,\n",
        "    'betas':(0.9, 0.95),\n",
        "    'grad_norm_clip':1.0, #??????\n",
        "    #'weight_decay':0.1, # only applied on matmul weights\n",
        "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
        "    #'lr_decay':False,\n",
        "    #'warmup_tokens':375e6, # these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere\n",
        "    #final_tokens = 260e9 # (at what point we reach 10% of original LR)\n",
        "}"
      ],
      "metadata": {
        "id": "1aq2aXXryZcX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def trainer(model, dataloader):\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=tparams['learning_rate'], betas=tparams['betas'])\n",
        "        lr = tparams['learning_rate']\n",
        "\n",
        "        #self.tokens = 0 # counter used for learning rate decay\n",
        "\n",
        "        for epoch in range(tparams['max_epochs']):\n",
        "\n",
        "            model.to(device)\n",
        "            model.train()\n",
        "\n",
        "            loader = DataLoader(dataloader, shuffle=True, pin_memory=True, # pin_memory ???????\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                num_workers=hparams['num_workers'])\n",
        "\n",
        "            losses = []\n",
        "            pbar = tqdm(enumerate(loader), total=len(loader))\n",
        "            for it, (obs, act, rtg, ts) in pbar:\n",
        "\n",
        "                # place data on the correct device\n",
        "                obs = obs.to(device) # size([B, seq_len, 28224])\n",
        "                act = act.to(device) # size([B, seq_len, 1])\n",
        "                rtg = rtg.to(device) # size([B, seq_len, 1])\n",
        "                ts = ts.to(device) #   size([B, 1, 1])\n",
        "\n",
        "                # forward the model\n",
        "                #with torch.set_grad_enabled(True):\n",
        "                logits, loss = model(obs, act, act, rtg, ts)\n",
        "                loss = loss.mean() # collapse all losses if they are scattered on multiple gpus\n",
        "                losses.append(loss.item())\n",
        "\n",
        "                # backprop and update the parameters\n",
        "                model.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), tparams['grad_norm_clip']) # ?????????????\n",
        "                optimizer.step()\n",
        "\n",
        "                    # decay the learning rate based on our progress\n",
        "                    #if config.lr_decay:\n",
        "                    #    self.tokens += (y >= 0).sum() # number of tokens processed this step (i.e. label is not -100)\n",
        "                    #    if self.tokens < config.warmup_tokens:\n",
        "                    #        # linear warmup\n",
        "                    #        lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens))\n",
        "                    #    else:\n",
        "                    #        # cosine learning rate decay\n",
        "                    #        progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
        "                    #        lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "                    #    lr = config.learning_rate * lr_mult\n",
        "                    #    for param_group in optimizer.param_groups:\n",
        "                    #        param_group['lr'] = lr\n",
        "                    #else:\n",
        "                    #    lr = config.learning_rate\n",
        "\n",
        "                    # report progress\n",
        "                pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n"
      ],
      "metadata": {
        "id": "qvI0gU09PSYL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE THE DATASET\n",
        "obss, actions, done_idxs, rtgs, timesteps, maxTimestep = create_dataset()\n",
        "hparams['max_timesteps'] = maxTimestep\n",
        "\n",
        "# CREATE A CLASS FOR THE DATALOADER TO GET DATA\n",
        "train_dataset = StateActionReturnDataset(obss, actions, done_idxs, rtgs, timesteps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "h7kufEszv2dW",
        "outputId": "49ce00e5-4dba-4f9f-ac42-68edb042dbf0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading /root/.d4rl/datasets/Breakout/5/1/observation.gz...\n",
            "loading /root/.d4rl/datasets/Breakout/5/1/action.gz...\n",
            "loading /root/.d4rl/datasets/Breakout/5/1/reward.gz...\n",
            "loading /root/.d4rl/datasets/Breakout/5/1/terminal.gz...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_data  (1000000,)\n",
            "num episodes  (1824,)\n",
            "max rtg is 32\n",
            "max timestep is 1243\n",
            "***** data loaded **********\n",
            "action possible numbers:  [0 1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(done_idxs)\n",
        "#print(rtg[:1000])\n",
        "#print(timesteps[:1000])"
      ],
      "metadata": {
        "id": "2oreWPPzK3VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE THE MODEL\n",
        "# maxTimestep = max steps in a trajectory\n",
        "model_gpt = GPT(hparams['max_timesteps'])\n",
        "model_gpt.to(device)\n",
        "model_gpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlaubXRTal81",
        "outputId": "20756499-6e5b-47db-a80b-b60cee18317b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 2.02M\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (tok_emb): Embedding(4, 128)\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): CausalSelfAttention(\n",
              "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
              "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Block(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): CausalSelfAttention(\n",
              "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
              "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (2): Block(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): CausalSelfAttention(\n",
              "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
              "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (3): Block(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): CausalSelfAttention(\n",
              "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
              "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (4): Block(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): CausalSelfAttention(\n",
              "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
              "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (5): Block(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): CausalSelfAttention(\n",
              "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
              "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "      )\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (1): GELU(approximate='none')\n",
              "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (head): Linear(in_features=128, out_features=4, bias=False)\n",
              "  (state_encoder): Sequential(\n",
              "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (5): ReLU()\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    (7): Linear(in_features=3136, out_features=128, bias=True)\n",
              "    (8): Tanh()\n",
              "  )\n",
              "  (ret_emb): Sequential(\n",
              "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
              "    (1): Tanh()\n",
              "  )\n",
              "  (action_embeddings): Sequential(\n",
              "    (0): Embedding(4, 128)\n",
              "    (1): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN THE MODEL\n",
        "trainer(model_gpt, train_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WgYhJAvXFDqC",
        "outputId": "abf611f9-a62a-4d13-fe1a-326dc43d9bb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 3.03M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0da043091e12>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# TRAIN THE MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EVALUATION\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VuQokT2kPE3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation loop\n",
        "#target_return = 1 # for instance, expert-level return\n",
        "#R,s,a,t, done = `target_return], [env.reset()], [], [1], False\n",
        "#while not done: # autoregressive generation/sampling\n",
        "  # sample next action\n",
        "  #action = DecisionTransformer(R,s,a,t) [-1] # for cta actions\n",
        "  #new_s,r,done,_ = env.step(action)\n",
        "\n",
        "  # append new tokens to sequence\n",
        "  #R = R + [R[-1] - r] # decrease returns-to-go with reward\n",
        "  #s,q,t = s + [new_s], a +[action], t + [len(R)]\n",
        "  #R,s,a,t = R[-K:], ... # only keep context length of K"
      ],
      "metadata": {
        "id": "dOJoCaglN6Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_logits(logits, k):\n",
        "    v, ix = torch.topk(logits, k)\n",
        "    out = logits.clone()\n",
        "    out[out < v[:, [-1]]] = -float('Inf')\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, x, steps, temperature=1.0, sample=False, top_k=None, actions=None, rtgs=None, timesteps=None):\n",
        "    \"\"\"\n",
        "    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in\n",
        "    the sequence, feeding the predictions back into the model each time. Clearly the sampling\n",
        "    has quadratic complexity unlike an RNN that is only linear, and has a finite context window\n",
        "    of block_size, unlike an RNN that has an infinite context window.\n",
        "    \"\"\"\n",
        "    block_size = hparams['batch_size']\n",
        "    model.eval()\n",
        "    for k in range(steps):\n",
        "        # x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # crop context if needed\n",
        "        x_cond = x if x.size(1) <= block_size//3 else x[:, -block_size//3:] # crop context if needed\n",
        "        if actions is not None:\n",
        "            actions = actions if actions.size(1) <= block_size//3 else actions[:, -block_size//3:] # crop context if needed\n",
        "        rtgs = rtgs if rtgs.size(1) <= block_size//3 else rtgs[:, -block_size//3:] # crop context if needed\n",
        "\n",
        "        logits, _ = model(x_cond, actions=actions, targets=None, rtgs=rtgs, timesteps=timesteps)\n",
        "        # pluck the logits at the final step and scale by temperature\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        # optionally crop probabilities to only the top k options\n",
        "        if top_k is not None:\n",
        "            logits = top_k_logits(logits, top_k)\n",
        "        # apply softmax to convert to probabilities\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        # sample from the distribution or take the most likely\n",
        "        if sample:\n",
        "            ix = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "        # append to the sequence and continue\n",
        "        # x = torch.cat((x, ix), dim=1)\n",
        "        x = ix\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "hhWDJ-7rcVQ4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_returns(ret, model):\n",
        "\n",
        "        model = model\n",
        "        model.eval() # for inference\n",
        "        #model.train(False)\n",
        "\n",
        "        T_rewards = []\n",
        "        done = True\n",
        "        for i in range(10): # it will output 10 eval returns\n",
        "            state = env.reset()\n",
        "            #print('***************** get_return ******************')\n",
        "            #print('state ', state.shape)\n",
        "            state = torch.Tensor(state)\n",
        "            state = state.to(device).unsqueeze(0).unsqueeze(0)\n",
        "            rtgs = [ret]\n",
        "            #print('ret ', ret)\n",
        "            #print('state ', state.shape)\n",
        "            # first state is from env, first rtg is target return, and first timestep is 0\n",
        "            sampled_action = sample(model, state, 1, temperature=1.0, sample=True, actions=None,\n",
        "                rtgs=torch.tensor(rtgs, dtype=torch.long).to(device).unsqueeze(0).unsqueeze(-1),\n",
        "                timesteps=torch.zeros((1, 1, 1), dtype=torch.int64).to(device))\n",
        "\n",
        "            j = 0\n",
        "            all_states = state\n",
        "            actions = []\n",
        "            while True:\n",
        "                if done:\n",
        "                    state, reward_sum, done = env.reset(), 0, False\n",
        "                    state = torch.Tensor(state)\n",
        "                    reward_sum = torch.Tensor(reward_sum)\n",
        "                action = sampled_action.cpu().numpy()[0,-1]\n",
        "                actions += [sampled_action]\n",
        "                state, reward, done, _= env.step(action)\n",
        "                state = torch.Tensor(state)\n",
        "\n",
        "                #reward = torch.Tensor(reward)\n",
        "                reward_sum += reward\n",
        "                j += 1\n",
        "\n",
        "                if done:\n",
        "                    T_rewards.append(reward_sum)\n",
        "                    #print(reward_sum)\n",
        "                    break\n",
        "\n",
        "                state = state.unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "                all_states = torch.cat([all_states, state], dim=0)\n",
        "\n",
        "                rtgs += [rtgs[-1] - reward]\n",
        "                # all_states has all previous states and rtgs has all previous rtgs (will be cut to block_size in utils.sample)\n",
        "                # timestep is just current timestep\n",
        "                sampled_action = sample(model, all_states.unsqueeze(0), 1, temperature=1.0, sample=True,\n",
        "                    actions=torch.tensor(actions, dtype=torch.long).to(device).unsqueeze(1).unsqueeze(0),\n",
        "                    rtgs=torch.tensor(rtgs, dtype=torch.long).to(device).unsqueeze(0).unsqueeze(-1),\n",
        "                    timesteps=(min(j, hparams['max_timesteps']) * torch.ones((1, 1, 1), dtype=torch.int64).to(device)))\n",
        "        #env.close()\n",
        "        eval_return = sum(T_rewards)/10.\n",
        "        print('target return ',ret)\n",
        "\n",
        "        return eval_return"
      ],
      "metadata": {
        "id": "TEMQA2-CEroi"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer = Trainer(model, train_dataset, None, tconf)\n",
        "eval_return = get_returns(90, model_gpt)\n",
        "print('eval_return ', eval_return)\n",
        "\n",
        "#'naive': get_returns(0)\n",
        "#'reward_conditioned':\n",
        "#'Breakout': get_returns(90)\n",
        "#'Seaquest': get_returns(1150)\n",
        "#'Qbert': get_returns(14000)\n",
        "#'Pong': get_returns(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkEKQ1yTaH01",
        "outputId": "47e1d8b3-e2dd-46ab-c237-f8c9bb5ea9b2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:137: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'gym.wrappers.frame_stack.LazyFrames'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:226: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
            "  logger.warn(\"Casting input x to numpy array.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target return  90\n",
            "eval_return  tensor([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRA"
      ],
      "metadata": {
        "id": "lKE4iNWBfX6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir training/logs"
      ],
      "metadata": {
        "id": "RRCjbtwmEH9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVE CHECKPOINTS"
      ],
      "metadata": {
        "id": "ZZixIfsLWkz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE MODEL\n",
        "torch.save(model_gpt, hparams['path'])"
      ],
      "metadata": {
        "id": "rke2a7UcW7Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD CHECKPOINTS"
      ],
      "metadata": {
        "id": "1Vr5l-T3XbUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DOWNLOAD CHECKPOINTS\n",
        "!gdown \"https://drive.google.com/uc?id=1ug0o5v2UlNjuLhJp_vDUMvWX32uUjdAy\" # Breakout_123\n",
        "#!gdown \"https://drive.google.com/uc?id=1PFwBV8XJlGcCPxwRMh4Dco2gkdz-Ep-c\" # QBert_123\n",
        "#!gdown \"https://drive.google.com/uc?id=14CJP2aAKsIMmlzBLAMDxLLBGHlnJF71N\" # Seaquest_123\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxQkQBmuXSHe",
        "outputId": "fb2944a6-c6b1-4047-bb91-86f3e58c797a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ug0o5v2UlNjuLhJp_vDUMvWX32uUjdAy\n",
            "To: /content/Breakout_123.pth\n",
            "100% 8.33M/8.33M [00:00<00:00, 18.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD SAVED CHECKPOINTS\n",
        "checkpoint = torch.load('/content/Breakout_123.pth')\n",
        "model_gpt.load_state_dict(checkpoint)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_X9_wNb3CJ8",
        "outputId": "eaf66dd3-9892-454c-d216-8072eaa1e47a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}