{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HParameters"
      ],
      "metadata": {
        "id": "uHcow9hb6yBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAR_seed=123\n",
        "#PAR_context_length=30\n",
        "#PAR_epochs=5\n",
        "PAR_epochs=1\n",
        "PAR_model_type='reward_conditioned'\n",
        "#PAR_num_steps=500000\n",
        "PAR_num_steps=1\n",
        "PAR_num_buffers=1\n",
        "#PAR_num_buffers=50\n",
        "PAR_game='Breakout'\n",
        "#PAR_batch_size=128\n",
        "\n",
        "PAR_trajectories_per_buffer=1 # help='Number of trajectories to sample from each of the buffers.')\n",
        "#PAR_trajectories_per_buffer=10 # help='Number of trajectories to sample from each of the buffers.')\n",
        "PAR_data_dir_prefix='/content/drive/MyDrive/Deep/UPC/Projecte/datasets/'\n",
        "\n",
        "# default GPT2 values?\n",
        "hparams = {\n",
        "    'batch_size': 2,\n",
        "    'context_length':30,\n",
        "    'path':'/content/drive/MyDrive/Deep/UPC/Projecte/datasets/Pong',\n",
        "}"
      ],
      "metadata": {
        "id": "vTM_u1be6nZ_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL"
      ],
      "metadata": {
        "id": "BlhLOoNbyOSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "GPT model:\n",
        "- the initial stem consists of a combination of token encoding and a positional encoding\n",
        "- the meat of it is a uniform sequence of Transformer blocks\n",
        "    - each Transformer is a sequential combination of a 1-hidden-layer MLP block and a self-attention block\n",
        "    - all blocks feed into a central residual pathway similar to resnets\n",
        "- the final decoder is a linear projection into a vanilla Softmax classifier\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return F.gelu(input)\n",
        "\n",
        "class GPTConfig:\n",
        "    \"\"\" base GPT config, params common to all GPT versions \"\"\"\n",
        "    embd_pdrop = 0.1\n",
        "    resid_pdrop = 0.1\n",
        "    attn_pdrop = 0.1\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, **kwargs):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.block_size = block_size\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class GPT1Config(GPTConfig):\n",
        "    \"\"\" GPT-1 like network roughly 125M params \"\"\"\n",
        "    n_layer = 12\n",
        "    n_head = 12\n",
        "    n_embd = 768\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
        "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
        "    explicit implementation here to show that there is nothing too scary here.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads\n",
        "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
        "        # regularization\n",
        "        self.attn_drop = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_drop = nn.Dropout(config.resid_pdrop)\n",
        "        # output projection\n",
        "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "        # self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "        #                              .view(1, 1, config.block_size, config.block_size))\n",
        "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size + 1, config.block_size + 1))\n",
        "                                     .view(1, 1, config.block_size + 1, config.block_size + 1))\n",
        "        self.n_head = config.n_head\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        B, T, C = x.size()\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_drop(att)\n",
        "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_drop(self.proj(y))\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" an unassuming Transformer block \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            nn.Dropout(config.resid_pdrop),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    \"\"\"  the full GPT language model, with a context size of block_size \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "        self.model_type = config.model_type\n",
        "\n",
        "        # input embedding stem\n",
        "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        # self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size + 1, config.n_embd))\n",
        "        self.global_pos_emb = nn.Parameter(torch.zeros(1, config.max_timestep+1, config.n_embd))\n",
        "        self.drop = nn.Dropout(config.embd_pdrop)\n",
        "\n",
        "        # transformer\n",
        "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
        "        # decoder head\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
        "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        self.block_size = config.block_size\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "\n",
        "        logger.info(\"number of parameters: %e\", sum(p.numel() for p in self.parameters()))\n",
        "\n",
        "\n",
        "        self.state_encoder = nn.Sequential(nn.Conv2d(4, 32, 8, stride=4, padding=0), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 64, 4, stride=2, padding=0), nn.ReLU(),\n",
        "                                 nn.Conv2d(64, 64, 3, stride=1, padding=0), nn.ReLU(),\n",
        "                                 nn.Flatten(), nn.Linear(3136, config.n_embd), nn.Tanh())\n",
        "\n",
        "        self.ret_emb = nn.Sequential(nn.Linear(1, config.n_embd), nn.Tanh())\n",
        "\n",
        "        self.action_embeddings = nn.Sequential(nn.Embedding(config.vocab_size, config.n_embd), nn.Tanh())\n",
        "        nn.init.normal_(self.action_embeddings[0].weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def get_block_size(self):\n",
        "        return self.block_size\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        \"\"\"\n",
        "        This long function is unfortunately doing something very simple and is being very defensive:\n",
        "        We are separating out all parameters of the model into two buckets: those that will experience\n",
        "        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).\n",
        "        We are then returning the PyTorch optimizer object.\n",
        "        \"\"\"\n",
        "\n",
        "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
        "        decay = set()\n",
        "        no_decay = set()\n",
        "        # whitelist_weight_modules = (torch.nn.Linear, )\n",
        "        whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv2d)\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        for mn, m in self.named_modules():\n",
        "            for pn, p in m.named_parameters():\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
        "\n",
        "                if pn.endswith('bias'):\n",
        "                    # all biases will not be decayed\n",
        "                    no_decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
        "                    # weights of whitelist modules will be weight decayed\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    # weights of blacklist modules will NOT be weight decayed\n",
        "                    no_decay.add(fpn)\n",
        "\n",
        "        # special case the position embedding parameter in the root GPT module as not decayed\n",
        "        no_decay.add('pos_emb')\n",
        "        no_decay.add('global_pos_emb')\n",
        "\n",
        "        # validate that we considered every parameter\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        inter_params = decay & no_decay\n",
        "        union_params = decay | no_decay\n",
        "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                    % (str(param_dict.keys() - union_params), )\n",
        "\n",
        "        # create the pytorch optimizer object\n",
        "        optim_groups = [\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
        "        return optimizer\n",
        "\n",
        "    # state, action, and return\n",
        "    def forward(self, states, actions, targets=None, rtgs=None, timesteps=None):\n",
        "        # states: (batch, block_size, 4*84*84)\n",
        "        # actions: (batch, block_size, 1)\n",
        "        # targets: (batch, block_size, 1)\n",
        "        # rtgs: (batch, block_size, 1)\n",
        "        # timesteps: (batch, 1, 1)\n",
        "\n",
        "        print('states ',states.shape)\n",
        "        print('actions ',actions.shape)\n",
        "        print('rtgs ',rtgs.shape)\n",
        "        print('timesteps ',timesteps.shape)\n",
        "\n",
        "        print('states_reshape ', states.reshape(-1, 4, 84, 84).type(torch.float32).contiguous().shape)\n",
        "        state_embeddings = self.state_encoder(states.reshape(-1, 4, 84, 84).type(torch.float32).contiguous()) # (batch * block_size, n_embd)\n",
        "        print('state_embeddings ', state_embeddings.shape)\n",
        "        state_embeddings = state_embeddings.reshape(states.shape[0], states.shape[1], self.config.n_embd) # (batch, block_size, n_embd)\n",
        "\n",
        "        if actions is not None and self.model_type == 'reward_conditioned':\n",
        "            print('1_rtg_', rtgs.shape)\n",
        "            rtg_embeddings = self.ret_emb(rtgs.type(torch.float32))\n",
        "            action_embeddings = self.action_embeddings(actions.type(torch.long).squeeze(-1)) # (batch, block_size, n_embd)\n",
        "\n",
        "            token_embeddings = torch.zeros((states.shape[0], states.shape[1]*3 - int(targets is None), self.config.n_embd), dtype=torch.float32, device=state_embeddings.device)\n",
        "            print('token_embeddings ', token_embeddings.shape)\n",
        "            token_embeddings[:,::3,:] = rtg_embeddings\n",
        "            token_embeddings[:,1::3,:] = state_embeddings\n",
        "            token_embeddings[:,2::3,:] = action_embeddings[:,-states.shape[1] + int(targets is None):,:]\n",
        "        elif actions is None and self.model_type == 'reward_conditioned': # only happens at very first timestep of evaluation\n",
        "            rtg_embeddings = self.ret_emb(rtgs.type(torch.float32))\n",
        "\n",
        "            token_embeddings = torch.zeros((states.shape[0], states.shape[1]*2, self.config.n_embd), dtype=torch.float32, device=state_embeddings.device)\n",
        "            token_embeddings[:,::2,:] = rtg_embeddings # really just [:,0,:]\n",
        "            token_embeddings[:,1::2,:] = state_embeddings # really just [:,1,:]\n",
        "        elif actions is not None and self.model_type == 'naive':\n",
        "            action_embeddings = self.action_embeddings(actions.type(torch.long).squeeze(-1)) # (batch, block_size, n_embd)\n",
        "\n",
        "            token_embeddings = torch.zeros((states.shape[0], states.shape[1]*2 - int(targets is None), self.config.n_embd), dtype=torch.float32, device=state_embeddings.device)\n",
        "            token_embeddings[:,::2,:] = state_embeddings\n",
        "            token_embeddings[:,1::2,:] = action_embeddings[:,-states.shape[1] + int(targets is None):,:]\n",
        "        elif actions is None and self.model_type == 'naive': # only happens at very first timestep of evaluation\n",
        "            token_embeddings = state_embeddings\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "        batch_size = states.shape[0]\n",
        "        print('self.global_pos_emb ', self.global_pos_emb.shape)\n",
        "        all_global_pos_emb = torch.repeat_interleave(self.global_pos_emb, batch_size, dim=0) # batch_size, traj_length, n_embd\n",
        "\n",
        "        print('all_global_pos_emb ', all_global_pos_emb.shape)\n",
        "        print('2_', torch.repeat_interleave(timesteps, self.config.n_embd, dim=-1).shape)\n",
        "        print('self.pos_emb ', self.pos_emb.shape)\n",
        "        print('3_', self.pos_emb[:, :token_embeddings.shape[1], :].shape)\n",
        "        position_embeddings = torch.gather(all_global_pos_emb, 1, torch.repeat_interleave(timesteps, self.config.n_embd, dim=-1)) + self.pos_emb[:, :token_embeddings.shape[1], :]\n",
        "\n",
        "        print('token_embeddings ', token_embeddings.shape)\n",
        "        print('position_embeddings ', position_embeddings.shape)\n",
        "        x = self.drop(token_embeddings + position_embeddings)\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        if actions is not None and self.model_type == 'reward_conditioned':\n",
        "            logits = logits[:, 1::3, :] # only keep predictions from state_embeddings\n",
        "        elif actions is None and self.model_type == 'reward_conditioned':\n",
        "            logits = logits[:, 1:, :]\n",
        "        elif actions is not None and self.model_type == 'naive':\n",
        "            logits = logits[:, ::2, :] # only keep predictions from state_embeddings\n",
        "        elif actions is None and self.model_type == 'naive':\n",
        "            logits = logits # for completeness\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "        print('logits_type ', logits.dtype)\n",
        "        print('targets_type ', targets.dtype)\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
        "\n",
        "        return logits, loss\n"
      ],
      "metadata": {
        "id": "ZrsCAjgcweNf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UTILS"
      ],
      "metadata": {
        "id": "QK6tkeMDyUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING"
      ],
      "metadata": {
        "id": "rAgk4PyeycJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Simple training loop; Boilerplate that could apply to any arbitrary neural network,\n",
        "so nothing in this file really has anything to do with GPT specifically.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import logging\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "from collections import deque\n",
        "import random\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "class TrainerConfig:\n",
        "    # optimization parameters\n",
        "    max_epochs = 10\n",
        "    batch_size = 64\n",
        "    learning_rate = 3e-4\n",
        "    betas = (0.9, 0.95)\n",
        "    grad_norm_clip = 1.0\n",
        "    weight_decay = 0.1 # only applied on matmul weights\n",
        "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
        "    lr_decay = False\n",
        "    warmup_tokens = 375e6 # these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere\n",
        "    final_tokens = 260e9 # (at what point we reach 10% of original LR)\n",
        "    # checkpoint settings\n",
        "    ckpt_path = None\n",
        "    num_workers = 0 # for DataLoader\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, train_dataset, test_dataset, config):\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.config = config\n",
        "\n",
        "        # take over whatever gpus are on the system\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.cuda.current_device()\n",
        "            self.model = torch.nn.DataParallel(self.model).to(self.device)\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        # DataParallel wrappers keep raw model object in .module attribute\n",
        "        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
        "        logger.info(\"saving %s\", self.config.ckpt_path)\n",
        "        # torch.save(raw_model.state_dict(), self.config.ckpt_path)\n",
        "\n",
        "    def train(self):\n",
        "        model, config = self.model, self.config\n",
        "        raw_model = model.module if hasattr(self.model, \"module\") else model\n",
        "        optimizer = raw_model.configure_optimizers(config)\n",
        "\n",
        "        def run_epoch(split, epoch_num=0):\n",
        "            is_train = split == 'train'\n",
        "            model.train(is_train)\n",
        "            data = self.train_dataset if is_train else self.test_dataset\n",
        "\n",
        "            loader = DataLoader(data, shuffle=True, pin_memory=True,\n",
        "                                batch_size=config.batch_size,\n",
        "                                num_workers=config.num_workers)\n",
        "\n",
        "            losses = []\n",
        "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
        "            for it, (x, y, r, t) in pbar:\n",
        "\n",
        "                # place data on the correct device\n",
        "                x = x.to(self.device)\n",
        "                y = y.to(self.device)\n",
        "                r = r.to(self.device)\n",
        "                t = t.to(self.device)\n",
        "\n",
        "                # forward the model\n",
        "                with torch.set_grad_enabled(is_train):\n",
        "                    # logits, loss = model(x, y, r)\n",
        "                    #print(\"in_model\",y.shape)\n",
        "                    logits, loss = model(x, y, y, r, t)\n",
        "                    loss = loss.mean() # collapse all losses if they are scattered on multiple gpus\n",
        "                    losses.append(loss.item())\n",
        "\n",
        "                if is_train:\n",
        "\n",
        "                    # backprop and update the parameters\n",
        "                    model.zero_grad()\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    # decay the learning rate based on our progress\n",
        "                    if config.lr_decay:\n",
        "                        self.tokens += (y >= 0).sum() # number of tokens processed this step (i.e. label is not -100)\n",
        "                        if self.tokens < config.warmup_tokens:\n",
        "                            # linear warmup\n",
        "                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens))\n",
        "                        else:\n",
        "                            # cosine learning rate decay\n",
        "                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
        "                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "                        lr = config.learning_rate * lr_mult\n",
        "                        for param_group in optimizer.param_groups:\n",
        "                            param_group['lr'] = lr\n",
        "                    else:\n",
        "                        lr = config.learning_rate\n",
        "\n",
        "                    # report progress\n",
        "                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n",
        "\n",
        "            if not is_train:\n",
        "                test_loss = float(np.mean(losses))\n",
        "                logger.info(\"test loss: %f\", test_loss)\n",
        "                return test_loss\n",
        "\n",
        "        # best_loss = float('inf')\n",
        "\n",
        "        best_return = -float('inf')\n",
        "\n",
        "        self.tokens = 0 # counter used for learning rate decay\n",
        "\n",
        "        for epoch in range(config.max_epochs):\n",
        "\n",
        "            run_epoch('train', epoch_num=epoch)\n",
        "            # if self.test_dataset is not None:\n",
        "            #     test_loss = run_epoch('test')\n",
        "\n",
        "            # # supports early stopping based on the test loss, or just save always if no test set is provided\n",
        "            # good_model = self.test_dataset is None or test_loss < best_loss\n",
        "            # if self.config.ckpt_path is not None and good_model:\n",
        "            #     best_loss = test_loss\n",
        "            #     self.save_checkpoint()\n",
        "\n",
        "            # -- pass in target returns\n",
        "            if self.config.model_type == 'naive':\n",
        "                eval_return = self.get_returns(0)\n",
        "            elif self.config.model_type == 'reward_conditioned':\n",
        "                if self.config.game == 'Breakout':\n",
        "                    eval_return = self.get_returns(90)\n",
        "                elif self.config.game == 'Seaquest':\n",
        "                    eval_return = self.get_returns(1150)\n",
        "                elif self.config.game == 'Qbert':\n",
        "                    eval_return = self.get_returns(14000)\n",
        "                elif self.config.game == 'Pong':\n",
        "                    eval_return = self.get_returns(20)\n",
        "                else:\n",
        "                    raise NotImplementedError()\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "\n",
        "    def get_returns(self, ret):\n",
        "        self.model.train(False)\n",
        "        args=Args(self.config.game.lower(), self.config.seed)\n",
        "        print(\"ENV***** \",args)\n",
        "        env = Env(args)\n",
        "        env.eval()\n",
        "\n",
        "        T_rewards, T_Qs = [], []\n",
        "        done = True\n",
        "        for i in range(10):\n",
        "            state = env.reset()\n",
        "            state = state.type(torch.float32).to(self.device).unsqueeze(0).unsqueeze(0)\n",
        "            rtgs = [ret]\n",
        "            # first state is from env, first rtg is target return, and first timestep is 0\n",
        "            sampled_action = sample(self.model.module, state, 1, temperature=1.0, sample=True, actions=None,\n",
        "                rtgs=torch.tensor(rtgs, dtype=torch.long).to(self.device).unsqueeze(0).unsqueeze(-1),\n",
        "                timesteps=torch.zeros((1, 1, 1), dtype=torch.int64).to(self.device))\n",
        "\n",
        "            j = 0\n",
        "            all_states = state\n",
        "            actions = []\n",
        "            while True:\n",
        "                if done:\n",
        "                    state, reward_sum, done = env.reset(), 0, False\n",
        "                action = sampled_action.cpu().numpy()[0,-1]\n",
        "                actions += [sampled_action]\n",
        "                state, reward, done = env.step(action)\n",
        "                reward_sum += reward\n",
        "                j += 1\n",
        "\n",
        "                if done:\n",
        "                    T_rewards.append(reward_sum)\n",
        "                    break\n",
        "\n",
        "                state = state.unsqueeze(0).unsqueeze(0).to(self.device)\n",
        "\n",
        "                all_states = torch.cat([all_states, state], dim=0)\n",
        "\n",
        "                rtgs += [rtgs[-1] - reward]\n",
        "                # all_states has all previous states and rtgs has all previous rtgs (will be cut to block_size in utils.sample)\n",
        "                # timestep is just current timestep\n",
        "                sampled_action = sample(self.model.module, all_states.unsqueeze(0), 1, temperature=1.0, sample=True,\n",
        "                    actions=torch.tensor(actions, dtype=torch.long).to(self.device).unsqueeze(1).unsqueeze(0),\n",
        "                    rtgs=torch.tensor(rtgs, dtype=torch.long).to(self.device).unsqueeze(0).unsqueeze(-1),\n",
        "                    timesteps=(min(j, self.config.max_timestep) * torch.ones((1, 1, 1), dtype=torch.int64).to(self.device)))\n",
        "        env.close()\n",
        "        eval_return = sum(T_rewards)/10.\n",
        "        print(\"target return: %d, eval return: %d\" % (ret, eval_return))\n",
        "        self.model.train(True)\n",
        "        return eval_return\n",
        "\n",
        "\n",
        "class Args:\n",
        "    def __init__(self, game, seed):\n",
        "        self.device = torch.device('cuda')\n",
        "        self.seed = seed\n",
        "        self.max_episode_length = 108e3\n",
        "        self.game = game\n",
        "        self.history_length = 4\n"
      ],
      "metadata": {
        "id": "_aJnboAzxCdg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATE DATASET"
      ],
      "metadata": {
        "id": "iUf6cfLdye6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test load files"
      ],
      "metadata": {
        "id": "9_WPARxGXVck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Atari dataset from https://console.cloud.google.com/storage/browser/atari-replay-datasets/dqn downloable with the command:\n",
        "#!gsutil -m cp -R gs://atari-replay-datasets/dqn/Pong/1/replay_logs .\n",
        "\n",
        "# But we get the dataset from my drive (Alex)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QhmWAUYTRSF",
        "outputId": "f7cdfbae-bf64-4e63-e80e-f57b7912a270"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixed replay buffer class ??"
      ],
      "metadata": {
        "id": "WUOpD72r9eZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source: https://github.com/google-research/batch_rl/blob/master/batch_rl/fixed_replay/replay_memory/fixed_replay_buffer.py\n",
        "\n",
        "import collections\n",
        "from concurrent import futures\n",
        "from dopamine.replay_memory import circular_replay_buffer\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "import gin\n",
        "\n",
        "gfile = tf.gfile\n",
        "\n",
        "STORE_FILENAME_PREFIX = circular_replay_buffer.STORE_FILENAME_PREFIX\n",
        "\n",
        "class FixedReplayBuffer(object):\n",
        "  \"\"\"Object composed of a list of OutofGraphReplayBuffers.\"\"\"\n",
        "\n",
        "  def __init__(self, data_dir, replay_suffix, *args, **kwargs):  # pylint: disable=keyword-arg-before-vararg\n",
        "    \"\"\"Initialize the FixedReplayBuffer class.\n",
        "    Args:\n",
        "      data_dir: str, log Directory from which to load the replay buffer.\n",
        "      replay_suffix: int, If not None, then only load the replay buffer\n",
        "        corresponding to the specific suffix in data directory.\n",
        "      *args: Arbitrary extra arguments.\n",
        "      **kwargs: Arbitrary keyword arguments.\n",
        "    \"\"\"\n",
        "    self._args = args\n",
        "    self._kwargs = kwargs\n",
        "    self._data_dir = data_dir\n",
        "    self._loaded_buffers = False\n",
        "    self.add_count = np.array(0)\n",
        "    self._replay_suffix = replay_suffix\n",
        "    if not self._loaded_buffers:\n",
        "      if replay_suffix is not None:\n",
        "        assert replay_suffix >= 0, 'Please pass a non-negative replay suffix'\n",
        "        self.load_single_buffer(replay_suffix)\n",
        "      else:\n",
        "        self._load_replay_buffers(num_buffers=50)\n",
        "\n",
        "  def load_single_buffer(self, suffix):\n",
        "    \"\"\"Load a single replay buffer.\"\"\"\n",
        "    replay_buffer = self._load_buffer(suffix)\n",
        "    if replay_buffer is not None:\n",
        "      self._replay_buffers = [replay_buffer]\n",
        "      self.add_count = replay_buffer.add_count\n",
        "      self._num_replay_buffers = 1\n",
        "      self._loaded_buffers = True\n",
        "\n",
        "  def _load_buffer(self, suffix):\n",
        "    \"\"\"Loads a OutOfGraphReplayBuffer replay buffer.\"\"\"\n",
        "    try:\n",
        "      # pytype: disable=attribute-error\n",
        "      replay_buffer = circular_replay_buffer.OutOfGraphReplayBuffer(\n",
        "          *self._args, **self._kwargs)\n",
        "      replay_buffer.load(self._data_dir, suffix)\n",
        "      tf.logging.info('Loaded replay buffer ckpt {} from {}'.format(\n",
        "          suffix, self._data_dir))\n",
        "      # pytype: enable=attribute-error\n",
        "      return replay_buffer\n",
        "    except tf.errors.NotFoundError:\n",
        "      return None\n",
        "\n",
        "  def _load_replay_buffers(self, num_buffers=None):\n",
        "    \"\"\"Loads multiple checkpoints into a list of replay buffers.\"\"\"\n",
        "    if not self._loaded_buffers:  # pytype: disable=attribute-error\n",
        "      ckpts = gfile.ListDirectory(self._data_dir)  # pytype: disable=attribute-error\n",
        "      # Assumes that the checkpoints are saved in a format CKPT_NAME.{SUFFIX}.gz\n",
        "      ckpt_counters = collections.Counter(\n",
        "          [name.split('.')[-2] for name in ckpts])\n",
        "      # Should contain the files for add_count, action, observation, reward,\n",
        "      # terminal and invalid_range\n",
        "      ckpt_suffixes = [x for x in ckpt_counters if ckpt_counters[x] in [6, 7]]\n",
        "      if num_buffers is not None:\n",
        "        ckpt_suffixes = np.random.choice(\n",
        "            ckpt_suffixes, num_buffers, replace=False)\n",
        "      self._replay_buffers = []\n",
        "      # Load the replay buffers in parallel\n",
        "      with futures.ThreadPoolExecutor(\n",
        "          max_workers=num_buffers) as thread_pool_executor:\n",
        "        replay_futures = [thread_pool_executor.submit(\n",
        "            self._load_buffer, suffix) for suffix in ckpt_suffixes]\n",
        "      for f in replay_futures:\n",
        "        replay_buffer = f.result()\n",
        "        if replay_buffer is not None:\n",
        "          self._replay_buffers.append(replay_buffer)\n",
        "          self.add_count = max(replay_buffer.add_count, self.add_count)\n",
        "      self._num_replay_buffers = len(self._replay_buffers)\n",
        "      if self._num_replay_buffers:\n",
        "        self._loaded_buffers = True\n",
        "\n",
        "  def get_transition_elements(self):\n",
        "    return self._replay_buffers[0].get_transition_elements()\n",
        "\n",
        "  def sample_transition_batch(self, batch_size=None, indices=None):\n",
        "    buffer_index = np.random.randint(self._num_replay_buffers)\n",
        "    return self._replay_buffers[buffer_index].sample_transition_batch(\n",
        "        batch_size=batch_size, indices=indices)\n",
        "\n",
        "  def load(self, *args, **kwargs):  # pylint: disable=unused-argument\n",
        "    pass\n",
        "\n",
        "  def reload_buffer(self, num_buffers=None):\n",
        "    self._loaded_buffers = False\n",
        "    self._load_replay_buffers(num_buffers)\n",
        "\n",
        "  def save(self, *args, **kwargs):  # pylint: disable=unused-argument\n",
        "    pass\n",
        "\n",
        "  def add(self, *args, **kwargs):  # pylint: disable=unused-argument\n",
        "    pass"
      ],
      "metadata": {
        "id": "ptbrejw1zBVw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset Function"
      ],
      "metadata": {
        "id": "wDkztYRf9NHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import logging\n",
        "# make deterministic\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from collections import deque\n",
        "import random\n",
        "import torch\n",
        "import pickle\n",
        "#import blosc\n",
        "import argparse\n",
        "#from fixed_replay_buffer import FixedReplayBuffer\n",
        "\n",
        "def create_dataset(num_buffers, num_steps, game, data_dir_prefix, trajectories_per_buffer):\n",
        "    # -- load data from memory (make more efficient)\n",
        "    obss = []\n",
        "    actions = []\n",
        "    returns = [0]\n",
        "    done_idxs = []\n",
        "    stepwise_returns = []\n",
        "\n",
        "    transitions_per_buffer = np.zeros(50, dtype=int)\n",
        "    num_trajectories = 0\n",
        "    while len(obss) < num_steps:\n",
        "        buffer_num = np.random.choice(np.arange(50 - num_buffers, 50), 1)[0]\n",
        "        i = transitions_per_buffer[buffer_num]\n",
        "        print('loading from buffer %d which has %d already loaded' % (buffer_num, i))\n",
        "        print(data_dir_prefix + game + '/1/replay_logs')\n",
        "        frb = FixedReplayBuffer(\n",
        "            data_dir=data_dir_prefix + game + '/1/replay_logs',\n",
        "            replay_suffix=buffer_num,\n",
        "            observation_shape=(84, 84),\n",
        "            stack_size=4,\n",
        "            update_horizon=1,\n",
        "            gamma=0.99,\n",
        "            observation_dtype=np.uint8,\n",
        "            batch_size=32,\n",
        "            replay_capacity=100000)\n",
        "        if frb._loaded_buffers:\n",
        "            done = False\n",
        "            curr_num_transitions = len(obss) # quants timesteps\n",
        "            trajectories_to_load = trajectories_per_buffer\n",
        "            while not done:\n",
        "                states, ac, ret, next_states, next_action, next_reward, terminal, indices = frb.sample_transition_batch(batch_size=1, indices=[i])\n",
        "\n",
        "                #print(\"states \",states.shape)\n",
        "               # plt.imshow(states[0])\n",
        "                states = states.transpose((0, 3, 1, 2))[0] # (1, 84, 84, 4) --> (4, 84, 84)\n",
        "                #print(\"ac \",ac.shape)\n",
        "                #print(\"next_states \",next_states.shape)\n",
        "                #print(\"next_action \",next_action.shape)\n",
        "                #print(\"ret \",ret.shape)\n",
        "\n",
        "                obss += [states]\n",
        "                actions += [ac[0]]\n",
        "                stepwise_returns += [ret[0]]\n",
        "                if terminal[0]:\n",
        "                    done_idxs += [len(obss)]\n",
        "                    returns += [0]\n",
        "                    if trajectories_to_load == 0:\n",
        "                        done = True\n",
        "                    else:\n",
        "                        trajectories_to_load -= 1\n",
        "                returns[-1] += ret[0]\n",
        "                i += 1\n",
        "                if i >= 100000:\n",
        "                    obss = obss[:curr_num_transitions]\n",
        "                    actions = actions[:curr_num_transitions]\n",
        "                    stepwise_returns = stepwise_returns[:curr_num_transitions]\n",
        "                    returns[-1] = 0\n",
        "                    i = transitions_per_buffer[buffer_num]\n",
        "                    done = True\n",
        "            num_trajectories += (trajectories_per_buffer - trajectories_to_load)\n",
        "            transitions_per_buffer[buffer_num] = i\n",
        "        print('this buffer has %d loaded transitions and there are now %d transitions total divided into %d trajectories' % (i, len(obss), num_trajectories))\n",
        "\n",
        "    actions = np.array(actions)\n",
        "    returns = np.array(returns)\n",
        "    stepwise_returns = np.array(stepwise_returns)\n",
        "    done_idxs = np.array(done_idxs)\n",
        "\n",
        "    # -- create reward-to-go dataset\n",
        "    start_index = 0\n",
        "    rtg = np.zeros_like(stepwise_returns)\n",
        "    for i in done_idxs:\n",
        "        i = int(i)\n",
        "        curr_traj_returns = stepwise_returns[start_index:i]\n",
        "        for j in range(i-1, start_index-1, -1): # start from i-1\n",
        "            rtg_j = curr_traj_returns[j-start_index:i-start_index]\n",
        "            rtg[j] = sum(rtg_j)\n",
        "        start_index = i\n",
        "    print('max rtg is %d' % max(rtg))\n",
        "\n",
        "    # -- create timestep dataset\n",
        "    start_index = 0\n",
        "    timesteps = np.zeros(len(actions)+1, dtype=int)\n",
        "    for i in done_idxs:\n",
        "        i = int(i)\n",
        "        timesteps[start_index:i+1] = np.arange(i+1 - start_index)\n",
        "        start_index = i+1\n",
        "    print('max timestep is %d' % max(timesteps))\n",
        "\n",
        "    return obss, actions, returns, done_idxs, rtg, timesteps\n"
      ],
      "metadata": {
        "id": "RxotySlXymL_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environtment"
      ],
      "metadata": {
        "id": "dWYUy4IbAa5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Env():\n",
        "    def __init__(self, args):\n",
        "        self.device = args.device\n",
        "        self.ale = atari_py.ALEInterface()\n",
        "        self.ale.setInt('random_seed', args.seed)\n",
        "        self.ale.setInt('max_num_frames_per_episode', args.max_episode_length)\n",
        "        self.ale.setFloat('repeat_action_probability', 0)  # Disable sticky actions\n",
        "        self.ale.setInt('frame_skip', 0)\n",
        "        self.ale.setBool('color_averaging', False)\n",
        "        self.ale.loadROM(atari_py.get_game_path(args.game))  # ROM loading must be done after setting options\n",
        "        actions = self.ale.getMinimalActionSet()\n",
        "        self.actions = dict([i, e] for i, e in zip(range(len(actions)), actions))\n",
        "        self.lives = 0  # Life counter (used in DeepMind training)\n",
        "        self.life_termination = False  # Used to check if resetting only from loss of life\n",
        "        self.window = args.history_length  # Number of frames to concatenate\n",
        "        self.state_buffer = deque([], maxlen=args.history_length)\n",
        "        self.training = True  # Consistent with model training mode\n",
        "\n",
        "    def _get_state(self):\n",
        "        state = cv2.resize(self.ale.getScreenGrayscale(), (84, 84), interpolation=cv2.INTER_LINEAR)\n",
        "        return torch.tensor(state, dtype=torch.float32, device=self.device).div_(255)\n",
        "\n",
        "    def _reset_buffer(self):\n",
        "        for _ in range(self.window):\n",
        "            self.state_buffer.append(torch.zeros(84, 84, device=self.device))\n",
        "\n",
        "    def reset(self):\n",
        "        if self.life_termination:\n",
        "            self.life_termination = False  # Reset flag\n",
        "            self.ale.act(0)  # Use a no-op after loss of life\n",
        "        else:\n",
        "            # Reset internals\n",
        "            self._reset_buffer()\n",
        "            self.ale.reset_game()\n",
        "            # Perform up to 30 random no-ops before starting\n",
        "            for _ in range(random.randrange(30)):\n",
        "                self.ale.act(0)  # Assumes raw action 0 is always no-op\n",
        "                if self.ale.game_over():\n",
        "                    self.ale.reset_game()\n",
        "        # Process and return \"initial\" state\n",
        "        observation = self._get_state()\n",
        "        self.state_buffer.append(observation)\n",
        "        self.lives = self.ale.lives()\n",
        "        return torch.stack(list(self.state_buffer), 0)\n",
        "\n",
        "    def step(self, action):\n",
        "        # Repeat action 4 times, max pool over last 2 frames\n",
        "        frame_buffer = torch.zeros(2, 84, 84, device=self.device)\n",
        "        reward, done = 0, False\n",
        "        for t in range(4):\n",
        "            reward += self.ale.act(self.actions.get(action))\n",
        "            if t == 2:\n",
        "                frame_buffer[0] = self._get_state()\n",
        "            elif t == 3:\n",
        "                frame_buffer[1] = self._get_state()\n",
        "            done = self.ale.game_over()\n",
        "            if done:\n",
        "                break\n",
        "        observation = frame_buffer.max(0)[0]\n",
        "        self.state_buffer.append(observation)\n",
        "        # Detect loss of life as terminal in training mode\n",
        "        if self.training:\n",
        "            lives = self.ale.lives()\n",
        "            if lives < self.lives and lives > 0:  # Lives > 0 for Q*bert\n",
        "                self.life_termination = not done  # Only set flag when not truly done\n",
        "                done = True\n",
        "            self.lives = lives\n",
        "        # Return state, reward, done\n",
        "        return torch.stack(list(self.state_buffer), 0), reward, done\n",
        "\n",
        "    # Uses loss of life as terminal signal\n",
        "    def train(self):\n",
        "        self.training = True\n",
        "\n",
        "    # Uses standard terminal signal\n",
        "    def eval(self):\n",
        "        self.training = False\n",
        "\n",
        "    def action_space(self):\n",
        "        return len(self.actions)\n",
        "\n",
        "    def render(self):\n",
        "        cv2.imshow('screen', self.ale.getScreenRGB()[:, :, ::-1])\n",
        "        cv2.waitKey(1)\n",
        "\n",
        "    def close(self):\n",
        "        cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "193h0a9sAY6u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#->GO"
      ],
      "metadata": {
        "id": "6PQq1V5zAUDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import logging\n",
        "# make deterministic\n",
        "#from mingpt.utils import set_seed\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "from torch.utils.data import Dataset\n",
        "#from mingpt.model_atari import GPT, GPTConfig\n",
        "#from mingpt.trainer_atari import Trainer, TrainerConfig\n",
        "#from mingpt.utils import sample\n",
        "from collections import deque\n",
        "import random\n",
        "import torch\n",
        "import pickle\n",
        "#import blosc\n",
        "import argparse\n",
        "#from create_dataset import create_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "\n",
        "class StateActionReturnDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, block_size, actions, done_idxs, rtgs, timesteps):\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = max(actions) + 1\n",
        "        self.data = data\n",
        "        self.actions = actions\n",
        "        self.done_idxs = done_idxs\n",
        "        self.rtgs = rtgs\n",
        "        self.timesteps = timesteps\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        block_size = self.block_size // 3\n",
        "        done_idx = idx + block_size\n",
        "        for i in self.done_idxs:\n",
        "            if i > idx: # first done_idx greater than idx\n",
        "                done_idx = min(int(i), done_idx)\n",
        "                break\n",
        "        idx = done_idx - block_size\n",
        "        states = torch.tensor(np.array(self.data[idx:done_idx]), dtype=torch.float32).reshape(block_size, -1) # (block_size, 4*84*84)\n",
        "        states = states / 255.\n",
        "        actions = torch.tensor(self.actions[idx:done_idx], dtype=torch.long).unsqueeze(1) # (block_size, 1)\n",
        "        rtgs = torch.tensor(self.rtgs[idx:done_idx], dtype=torch.float32).unsqueeze(1)\n",
        "        timesteps = torch.tensor(self.timesteps[idx:idx+1], dtype=torch.int64).unsqueeze(1)\n",
        "\n",
        "        return states, actions, rtgs, timesteps\n",
        "\n"
      ],
      "metadata": {
        "id": "j2PIjWNWzouh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obss, actions, returns, done_idxs, rtgs, timesteps = create_dataset(PAR_num_buffers, PAR_num_steps, PAR_game, PAR_data_dir_prefix, PAR_trajectories_per_buffer)\n",
        "\n",
        "# set up logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        ")\n",
        "\n",
        "train_dataset = StateActionReturnDataset(obss, hparams['context_length']*3, actions, done_idxs, rtgs, timesteps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQZrnCS985iZ",
        "outputId": "7b0c3918-9ed2-43c1-91da-e161b1685610"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading from buffer 49 which has 0 already loaded\n",
            "/content/drive/MyDrive/Deep/UPC/Projecte/datasets/Breakout/1/replay_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Unable to find episode_end_indices. This is expected for old checkpoints.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this buffer has 2006 loaded transitions and there are now 2006 transitions total divided into 1 trajectories\n",
            "max rtg is 67\n",
            "max timestep is 1842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
        "                  n_layer=6, n_head=8, n_embd=128, model_type=PAR_model_type, max_timestep=max(timesteps))\n",
        "model = GPT(mconf)\n"
      ],
      "metadata": {
        "id": "9tU54BTU9FBw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# initialize a trainer instance and kick off training\n",
        "epochs = PAR_epochs\n",
        "tconf = TrainerConfig(max_epochs=epochs, batch_size=hparams['batch_size'], learning_rate=6e-4,\n",
        "                      lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*hparams['context_length']*3,\n",
        "                      num_workers=4, seed=PAR_seed, model_type=PAR_model_type, game=PAR_game, max_timestep=max(timesteps))\n",
        "trainer = Trainer(model, train_dataset, None, tconf)\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ygm6860f9HWv",
        "outputId": "af91cd73-f07a-4305-fd24-8fea2bfd7693"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "epoch 1 iter 2: train loss 1.86223. lr 1.054687e-05:   0%|          | 3/958 [00:00<01:31, 10.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 7: train loss 1.41208. lr 2.812500e-05:   1%|          | 6/958 [00:00<01:01, 15.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 11: train loss 1.50917. lr 4.218750e-05:   1%|▏         | 12/958 [00:00<00:50, 18.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 16: train loss 1.40896. lr 5.976562e-05:   2%|▏         | 15/958 [00:00<00:46, 20.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 20: train loss 1.45893. lr 7.382812e-05:   2%|▏         | 21/958 [00:01<00:44, 21.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 25: train loss 1.52335. lr 9.140625e-05:   3%|▎         | 24/958 [00:01<00:44, 20.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 29: train loss 1.06452. lr 1.054687e-04:   3%|▎         | 30/958 [00:01<00:43, 21.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 34: train loss 1.47586. lr 1.230469e-04:   3%|▎         | 33/958 [00:01<00:43, 21.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 39: train loss 1.32099. lr 1.406250e-04:   4%|▍         | 39/958 [00:02<00:42, 21.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 43: train loss 1.19452. lr 1.546875e-04:   4%|▍         | 42/958 [00:02<00:44, 20.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 48: train loss 1.08526. lr 1.722656e-04:   5%|▌         | 48/958 [00:02<00:42, 21.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 52: train loss 1.10582. lr 1.863281e-04:   5%|▌         | 51/958 [00:02<00:41, 21.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 57: train loss 1.70658. lr 2.039062e-04:   6%|▌         | 57/958 [00:02<00:42, 21.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 61: train loss 1.52241. lr 2.179687e-04:   6%|▋         | 60/958 [00:03<00:41, 21.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 65: train loss 1.20162. lr 2.320312e-04:   7%|▋         | 66/958 [00:03<00:42, 21.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 70: train loss 1.12776. lr 2.496094e-04:   7%|▋         | 69/958 [00:03<00:41, 21.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 74: train loss 1.31431. lr 2.636719e-04:   8%|▊         | 75/958 [00:03<00:41, 21.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 79: train loss 1.15102. lr 2.812500e-04:   8%|▊         | 78/958 [00:03<00:41, 21.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 83: train loss 1.31355. lr 2.953125e-04:   9%|▉         | 84/958 [00:04<00:42, 20.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 87: train loss 1.17361. lr 3.093750e-04:   9%|▉         | 87/958 [00:04<00:42, 20.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 92: train loss 1.03117. lr 3.269531e-04:  10%|▉         | 93/958 [00:04<00:40, 21.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 96: train loss 0.95165. lr 3.410156e-04:  10%|█         | 96/958 [00:04<00:40, 21.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 101: train loss 1.08825. lr 3.585937e-04:  10%|█         | 99/958 [00:04<00:40, 21.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 105: train loss 0.77126. lr 3.726562e-04:  11%|█         | 105/958 [00:05<00:40, 21.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 107: train loss 0.98302. lr 3.796875e-04:  11%|█▏        | 108/958 [00:05<00:41, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n",
            "logits_type  torch.float32\n",
            "targets_type  torch.int64\n",
            "states  torch.Size([2, 30, 28224])\n",
            "actions  torch.Size([2, 30, 1])\n",
            "rtgs  torch.Size([2, 30, 1])\n",
            "timesteps  torch.Size([2, 1, 1])\n",
            "states_reshape  torch.Size([60, 4, 84, 84])\n",
            "state_embeddings  torch.Size([60, 128])\n",
            "1_rtg_ torch.Size([2, 30, 1])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "self.global_pos_emb  torch.Size([1, 1843, 128])\n",
            "all_global_pos_emb  torch.Size([2, 1843, 128])\n",
            "2_ torch.Size([2, 1, 128])\n",
            "self.pos_emb  torch.Size([1, 91, 128])\n",
            "3_ torch.Size([1, 90, 128])\n",
            "token_embeddings  torch.Size([2, 90, 128])\n",
            "position_embeddings  torch.Size([2, 90, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-14 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 355, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 508, in Client\n",
            "    answer_challenge(c, authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 757, in answer_challenge\n",
            "    response = connection.recv_bytes(256)        # reject large message\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bc8c541c35af>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-a08c7e55f54c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;31m# if self.test_dataset is not None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m#     test_loss = run_epoch('test')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-a08c7e55f54c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(split, epoch_num)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0;31m# logits, loss = model(x, y, r)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0;31m#print(\"in_model\",y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# collapse all losses if they are scattered on multiple gpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-e8720d5e44b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, states, actions, targets, rtgs, timesteps)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'position_embeddings '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-e8720d5e44b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-e8720d5e44b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, layer_past)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mv\u001b[0m \u001b[0;31m# (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def top_k_logits(logits, k):\n",
        "    v, ix = torch.topk(logits, k)\n",
        "    out = logits.clone()\n",
        "    out[out < v[:, [-1]]] = -float('Inf')\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, x, steps, temperature=1.0, sample=False, top_k=None, actions=None, rtgs=None, timesteps=None):\n",
        "    \"\"\"\n",
        "    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in\n",
        "    the sequence, feeding the predictions back into the model each time. Clearly the sampling\n",
        "    has quadratic complexity unlike an RNN that is only linear, and has a finite context window\n",
        "    of block_size, unlike an RNN that has an infinite context window.\n",
        "    \"\"\"\n",
        "    block_size = model.get_block_size()\n",
        "    model.eval()\n",
        "    for k in range(steps):\n",
        "        # x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # crop context if needed\n",
        "        x_cond = x if x.size(1) <= block_size//3 else x[:, -block_size//3:] # crop context if needed\n",
        "        if actions is not None:\n",
        "            actions = actions if actions.size(1) <= block_size//3 else actions[:, -block_size//3:] # crop context if needed\n",
        "        rtgs = rtgs if rtgs.size(1) <= block_size//3 else rtgs[:, -block_size//3:] # crop context if needed\n",
        "        logits, _ = model(x_cond, actions=actions, targets=None, rtgs=rtgs, timesteps=timesteps)\n",
        "        # pluck the logits at the final step and scale by temperature\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        # optionally crop probabilities to only the top k options\n",
        "        if top_k is not None:\n",
        "            logits = top_k_logits(logits, top_k)\n",
        "        # apply softmax to convert to probabilities\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        # sample from the distribution or take the most likely\n",
        "        if sample:\n",
        "            ix = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "        # append to the sequence and continue\n",
        "        # x = torch.cat((x, ix), dim=1)\n",
        "        x = ix\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "kluVbduNxrLd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([[1, 2, 3], [4, 5, 6]])\n",
        "b=np.array([1, 2])\n",
        "np.savez('/tmp/123.npz', a=a, b=b)\n",
        "data = np.load('/tmp/123.npz')\n",
        "data['a']\n",
        "data['b']\n",
        "data.close()"
      ],
      "metadata": {
        "id": "o4iSOhhdAP6h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}