{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Door Key Offline Training with d3rlpy and Decision Transformer\n",
    "\n",
    "We will use the Door Key 16x16 environment from Minigrid Gym to test the Decision Transformer algorithm from d3rlpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "# Test if we are running on CoLab or not\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on CoLab')\n",
    "  !apt-get install -y xvfb ffmpeg > /dev/null 2>&1\n",
    "  %pip install pyvirtualdisplay pygame moviepy > /dev/null 2>&1\n",
    "  %pip install d3rlpy\n",
    "  %pip install matplotlib\n",
    "else:\n",
    "  print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory creation\n",
    "import os\n",
    "path = \"./models\"\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "  os.makedirs(path)\n",
    "\n",
    "path = \"./datasets\"\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "  os.makedirs(path)\n",
    "\n",
    "path = \"./videos/video-doorkey-dt-d3rlpy\"\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "  os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from minigrid.envs import DoorKeyEnv\n",
    "from gymnasium.core import ActType, ObsType\n",
    "from typing import Any, SupportsFloat\n",
    "import random, math\n",
    "import numpy as np\n",
    "\n",
    "from gymnasium.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id=\"MiniGrid-DoorKey-16x16-v0\",\n",
    "    entry_point=\"minigrid.envs:DoorKeyEnv\",\n",
    "    kwargs={\"size\": 16},\n",
    ")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a PartialObsWrapper to add to flattened partial observations the direction of the agent in only one vector. This is useful to train the Decision Transformer algorithm.\n",
    "\n",
    "We also made a PartialAndFullyObsWrapper to add to flattened partial observations the direction of the agent in only one vector and to add the full observation to the partial observation. This is useful to sample data from the environment with the trained DQN agent, and for save the data in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minigrid\n",
    "from minigrid.core.constants import COLOR_TO_IDX, OBJECT_TO_IDX\n",
    "from gymnasium.core import ObservationWrapper\n",
    "\n",
    "class PartialObsWrapper(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        new_image_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(((self.env.agent_view_size * self.env.agent_view_size *  3) + 1),),  \n",
    "            dtype=\"uint8\",\n",
    "        )\n",
    "\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {**self.observation_space.spaces, \"image\": new_image_space}\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        image = np.concatenate((obs[\"image\"].flatten(), np.array([obs[\"direction\"]])))\n",
    "\n",
    "        return {\"image\": image}\n",
    "\n",
    "class PartialAndFullyObsWrapper(ObservationWrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        new_image_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=255,\n",
    "            shape=(self.env.width, self.env.height, 3),  # number of cells\n",
    "            dtype=\"uint8\",\n",
    "        )\n",
    "\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {**self.observation_space.spaces, \"image\": new_image_space}\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        env = self.unwrapped\n",
    "        full_grid = env.grid.encode()\n",
    "        full_grid[env.agent_pos[0]][env.agent_pos[1]] = np.array(\n",
    "            [OBJECT_TO_IDX[\"agent\"], COLOR_TO_IDX[\"red\"], env.agent_dir]\n",
    "        )\n",
    "\n",
    "        partial_image = np.concatenate((obs[\"image\"].flatten(), np.array([obs[\"direction\"]])))\n",
    "\n",
    "        return {\"partial_image\": partial_image, \"image\": full_grid}\n",
    "\n",
    "def create_env(env_key, max_episode_steps=100, isPartialObs=False, isFullyObs=True, is_video=False):\n",
    "    \n",
    "    render_mode = None\n",
    "\n",
    "    if is_video == True:\n",
    "        render_mode = 'rgb_array'\n",
    "\n",
    "    env = gym.make(env_key, max_episode_steps=max_episode_steps, render_mode=render_mode, see_through_walls=True)\n",
    "\n",
    "    if isPartialObs and isFullyObs:\n",
    "        env =  PartialAndFullyObsWrapper(env)\n",
    "    elif isPartialObs:\n",
    "        env = PartialObsWrapper(env)\n",
    "        env = minigrid.wrappers.ImgObsWrapper(env)\n",
    "    elif isFullyObs:\n",
    "        env = minigrid.wrappers.FullyObsWrapper(env)\n",
    "        env = minigrid.wrappers.ImgObsWrapper(env)\n",
    "\n",
    "    return env\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recover the agent DQN trained in the notebook train-door-key-16x16-dqn.ipynb. We use this agent to sample data from the environment and to save the data in a dataset. This is a way to use the trained agent to generate data for the Decision Transformer algorithm with expert data. This agent is also used to evaluate the performance of the Decision Transformer algorithm. The agent is good enough to solve the environment, but not perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3rlpy\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from d3rlpy.models.encoders import EncoderFactory\n",
    "\n",
    "class CustomConvEncoder(nn.Module):\n",
    "    def __init__(self, observation_shape):\n",
    "        super().__init__()\n",
    "        print(observation_shape)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=1, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2Dropout = nn.Dropout(0.25)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3Dropout = nn.Dropout(0.5)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4Dropout = nn.Dropout(0.5)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5Dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x.permute(0, 3, 1, 2)\n",
    "        h = torch.relu(self.conv1(h))\n",
    "        h = torch.relu(self.conv2Dropout(self.conv2(h)))\n",
    "        h = torch.relu(self.conv3Dropout(self.conv3(h)))\n",
    "        h = torch.relu(self.conv4Dropout(self.conv4(h)))\n",
    "        h = torch.relu(self.conv5Dropout(self.conv5(h)))\n",
    "\n",
    "        h = torch.flatten(h, start_dim=1)\n",
    "        #print(h.shape)\n",
    "\n",
    "        return h\n",
    "    \n",
    "class CustomConvEncoderFactory(EncoderFactory):\n",
    "\n",
    "    def create(self, observation_shape):\n",
    "        return CustomConvEncoder(observation_shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_type() -> str:\n",
    "        return \"custom\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 1,\n",
    "    \"dataset_size\": 10000,\n",
    "    \"epsilon\": 0.3,\n",
    "    \"max_episode_steps\": 200,\n",
    "    \"experiment_name\": \"door-key-16x16\",\n",
    "    \"device\": \"cuda:0\"\n",
    "}\n",
    "\n",
    "env_key = \"MiniGrid-DoorKey-16x16-v0\"\n",
    "\n",
    "env = create_env(env_key, max_episode_steps=config[\"max_episode_steps\"])\n",
    "\n",
    "dqn = d3rlpy.algos.DQNConfig(\n",
    "    encoder_factory=CustomConvEncoderFactory(),\n",
    "    batch_size=100,\n",
    "    gamma=0.9,\n",
    "    target_update_interval=1000,\n",
    "    learning_rate=2.5e-4\n",
    ").create(device=config[\"device\"])\n",
    "\n",
    "dqn.build_with_env(env)\n",
    "\n",
    "dqn.load_model('./models/model_door-key-dqn-16x16.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a CustomReplayBuffer to clip episodes with zero or negative rewards. We want to clip the episodes to only include the steps where the agent is making progress towards the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CustomReplayBuffer(d3rlpy.dataset.ReplayBuffer):\n",
    "    ' Custom Replay Buffer to clip episodes with negative rewards'\n",
    "    \n",
    "    def clip_episode(self, terminated: bool) -> None:\n",
    "        r\"\"\"Clips the current episode.\n",
    "\n",
    "        Args:\n",
    "            terminated: Flag to represent environment termination.\n",
    "        \"\"\"\n",
    "\n",
    "        episode_to_remove = None\n",
    "        # Check if the episode's reward is 0 or negative\n",
    "        if not terminated and self._writer._active_episode.rewards.mean() <= 0:\n",
    "            episode_to_remove = self._writer._active_episode\n",
    "            \n",
    "        self._writer.clip_episode(terminated)\n",
    "\n",
    "        if episode_to_remove is not None:\n",
    "            # Remove all transitions associated with the episode to remove\n",
    "            self._buffer._transitions = [(ep, idx) for ep, idx in self._buffer._transitions if ep is not episode_to_remove]\n",
    "            self._buffer.episodes.remove(episode_to_remove)  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill the buffer dataset with the data sampled from the environment with the trained agent DQN. We use the PartialAndFullyObsWrapper to use the full observation for the DQN agent and to save the partial observation in the dataset. We make samples until we have the dataset filled with only positive rewards. To generate a mixed non-expert / exper data, we start adding more entropy to the actions sampled from the DQN agent and progressively decrease the entropy to generate expert data. It is an slow process, but it is the only way we found to generate expert data automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_data = create_env(env_key, max_episode_steps=config[\"max_episode_steps\"], isPartialObs=True, isFullyObs=False)\n",
    "env_sampler = create_env(env_key, max_episode_steps=config[\"max_episode_steps\"], isPartialObs=True, isFullyObs=True)\n",
    "\n",
    "buffer = d3rlpy.dataset.InfiniteBuffer()\n",
    "dataset = CustomReplayBuffer(buffer, env=env_data, cache_size=config[\"max_episode_steps\"])\n",
    "\n",
    "seed = 1\n",
    "\n",
    "done = False\n",
    "\n",
    "observation, _ = env_sampler.reset()\n",
    "\n",
    "num_steps = 0\n",
    "count_done = 0\n",
    "count_truncated = 0\n",
    "\n",
    "epsilon = 0.5\n",
    "epsilon_min = 0.1\n",
    "epsilon_decrement = (epsilon - epsilon_min) / 10  \n",
    "\n",
    "\n",
    "pbar = tqdm(total=config[\"dataset_size\"])\n",
    "\n",
    "while dataset.size() < config[\"dataset_size\"]:\n",
    "\n",
    "    pbar.update(dataset.size() - pbar.n) \n",
    "\n",
    "    if dataset.size() >= (config[\"dataset_size\"] * (1 - (epsilon - epsilon_min) / (epsilon - epsilon_decrement))):\n",
    "        epsilon = max(epsilon - epsilon_decrement, epsilon_min)\n",
    "\n",
    "    explorer = d3rlpy.algos.ConstantEpsilonGreedy(epsilon=epsilon)\n",
    "\n",
    "    while True:\n",
    "        x = np.expand_dims(observation['image'], axis=0)\n",
    "\n",
    "        action = explorer.sample(dqn, x, 0)[0]\n",
    "\n",
    "        next_observation, reward, done, truncated, _ = env_sampler.step(action)\n",
    "\n",
    "        clip_episode = done or truncated\n",
    "\n",
    "        # store observation\n",
    "        dataset.append(observation['partial_image'], action, float(reward))\n",
    "\n",
    "        # reset if terminated\n",
    "        if clip_episode:\n",
    "            dataset.clip_episode(done)\n",
    "            observation, _ = env_sampler.reset()\n",
    "            if done:\n",
    "                count_done += 1\n",
    "            if truncated:\n",
    "                count_truncated += 1\n",
    "            break\n",
    "        else:\n",
    "            observation = next_observation\n",
    "\n",
    "pbar.close()\n",
    "env.close()\n",
    "\n",
    "print(\"Dataset size: \", dataset.size())\n",
    "print(\"Truncated: \", count_truncated)\n",
    "\n",
    "dataset.dump('./datasets/dataset_door-key-dqn-16x16-mixed.d3')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the DiscreteDecisionTransformer agent with the sampled data from the environment. We use the PartialObsWrapper to add the direction of the agent to the partial observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:07.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int64')], shape=[()])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('uint8')], shape=[(148,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[[1]])\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m7\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int64')], shape=[(1,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('uint8')], shape=[(148,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(1,)])\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m7\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('uint8')], shape=[(148,)]), action_signature=Signature(dtype=[dtype('int64')], shape=[()]), reward_signature=Signature(dtype=[dtype('float32')], shape=[[1]]), action_space=<ActionSpace.DISCRETE: 2>, action_size=7)\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DT_door-key-16x16_1_20240121230754\u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.54\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.55\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
      "\u001b[2m2024-01-21 23:07.55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [148], 'action_size': 7, 'config': {'type': 'discrete_decision_transformer', 'params': {'batch_size': 64, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'context_size': 50, 'max_timestep': 200, 'learning_rate': 0.0001, 'encoder_factory': {'type': 'vector', 'params': {'hidden_units': [128], 'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None, 'exclude_last_activation': True}}, 'optim_factory': {'type': 'adam_w', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}}, 'num_heads': 4, 'num_layers': 3, 'attn_dropout': 0.1, 'resid_dropout': 0.1, 'embed_dropout': 0.1, 'activation_type': 'gelu', 'embed_activation_type': 'tanh', 'position_encoding_type': <PositionEncodingType.GLOBAL: 'global'>, 'warmup_tokens': 10240, 'final_tokens': 30000000, 'clip_grad_norm': 1.0, 'compile': False}}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5138eec91f444993ad2803afbd5edc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:09.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=1 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006913616299629211, 'time_algorithm_update': 0.03026457130908966, 'loss': 0.848791387706995, 'learning_rate': 9.818605497212029e-05, 'time_step': 0.0373171226978302, 'environment': 0.28428515625}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:09.17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_2000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7369ff8ebbc47938dd7e068db0783a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:10.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=2 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006858097910881042, 'time_algorithm_update': 0.028980084180831908, 'loss': 0.7375048235058784, 'learning_rate': 8.835054443637522e-05, 'time_step': 0.03596951162815094, 'environment': 0.67387890625}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:10.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_4000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c9d5e8240948a4afd1a07d4bfc2efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:11.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=3 step=6000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006928563475608825, 'time_algorithm_update': 0.0291766277551651, 'loss': 0.7194353715181351, 'learning_rate': 7.04769782418929e-05, 'time_step': 0.03624347460269928, 'environment': 0.6786953124999999}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m6000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:11.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_6000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8f5323a7d14769bcd2ef371286e4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:13.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=4 step=8000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.007049693107604981, 'time_algorithm_update': 0.029266536712646483, 'loss': 0.7109014772176743, 'learning_rate': 4.8330853337870506e-05, 'time_step': 0.03645717906951904, 'environment': 0.782703125}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m8000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:13.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_8000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115483525da74b249fb2bea33cc588bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:14.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=5 step=10000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006913050174713135, 'time_algorithm_update': 0.029357316613197328, 'loss': 0.7032193146944046, 'learning_rate': 2.6572727688173935e-05, 'time_step': 0.036407352209091186, 'environment': 0.49040234375}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m10000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:14.31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_10000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb2571efaba451f869f92561bdfeaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:15.50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=6 step=12000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006854774832725525, 'time_algorithm_update': 0.029251161575317382, 'loss': 0.700837476849556, 'learning_rate': 1.1513394412753156e-05, 'time_step': 0.03623122715950012, 'environment': 0.5836171875}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m12000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:15.50\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_12000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521942d257694b3a8718e8dc5e8fdef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:17.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=7 step=14000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m7\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006803167223930359, 'time_algorithm_update': 0.029262224793434145, 'loss': 0.7001724973171949, 'learning_rate': 9.999999999999677e-06, 'time_step': 0.03618792617321014, 'environment': 0.57289453125}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m14000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:17.10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_14000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f351b6e6c5014c4eabf0ad4b400503ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:18.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=8 step=16000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m8\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0068625063896179195, 'time_algorithm_update': 0.02899527406692505, 'loss': 0.700576818048954, 'learning_rate': 9.999999999999677e-06, 'time_step': 0.03597722971439361, 'environment': 0.38885546875}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m16000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:18.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_16000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67368568b4ae47edae75bb85f80b2118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:19.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=9 step=18000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m9\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006600202441215515, 'time_algorithm_update': 0.028705960631370545, 'loss': 0.7002915351688862, 'learning_rate': 1.4394318749096963e-05, 'time_step': 0.03543077301979065, 'environment': 0.87271875}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m18000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:19.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_18000.d3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faf5e78962a4d1799959e206e431b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-01-21 23:21.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDT_door-key-16x16_1_20240121230754: epoch=10 step=20000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m10\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.006708921909332276, 'time_algorithm_update': 0.0285303715467453, 'loss': 0.7014753077924252, 'learning_rate': 3.2780393187148524e-05, 'time_step': 0.035367817401885986, 'environment': 0.7673398437500001}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m20000\u001b[0m\n",
      "\u001b[2m2024-01-21 23:21.02\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DT_door-key-16x16_1_20240121230754/model_20000.d3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env_dt = create_env(env_key, max_episode_steps=config[\"max_episode_steps\"], isPartialObs=True, isFullyObs=False)\n",
    "env_dt_eval = create_env(env_key, max_episode_steps=config[\"max_episode_steps\"], isPartialObs=True, isFullyObs=False)\n",
    "\n",
    "buffer = d3rlpy.dataset.InfiniteBuffer()\n",
    "dataset = CustomReplayBuffer(buffer, env=env_dt, cache_size=config[\"max_episode_steps\"])\n",
    "\n",
    "dataset.load('./datasets/dataset_door-key-dqn-16x16-mixed.d3', buffer=buffer)\n",
    "\n",
    "\n",
    "target_return = 1\n",
    "experiment_name = config[\"experiment_name\"]\n",
    "experiment_seed = config[\"seed\"]\n",
    "\n",
    "dt = d3rlpy.algos.DiscreteDecisionTransformerConfig(\n",
    "    batch_size=64,\n",
    "    learning_rate=1e-4,\n",
    "    optim_factory=d3rlpy.models.AdamWFactory(weight_decay=1e-4),\n",
    "    encoder_factory=d3rlpy.models.VectorEncoderFactory(\n",
    "        [128],\n",
    "        exclude_last_activation=True,\n",
    "    ),\n",
    "    #observation_scaler=d3rlpy.preprocessing.StandardObservationScaler(),\n",
    "    #reward_scaler=d3rlpy.preprocessing.MultiplyRewardScaler(0.001),\n",
    "    position_encoding_type=d3rlpy.PositionEncodingType.GLOBAL,\n",
    "    context_size=50,\n",
    "    num_heads=4,\n",
    "    num_layers=3,\n",
    "    max_timestep=200,\n",
    ").create(device=config[\"device\"])\n",
    "\n",
    "\n",
    "dt.fit(                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "    dataset,\n",
    "    n_steps=20000,\n",
    "    n_steps_per_epoch=2000,\n",
    "    eval_env=env_dt_eval,\n",
    "    eval_target_return=1,\n",
    "    eval_action_sampler=d3rlpy.algos.SoftmaxTransformerActionSampler(\n",
    "        temperature=1.0,\n",
    "    ),\n",
    "    experiment_name=f\"DT_{experiment_name}_{experiment_seed}\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a video of the trained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "import numpy as np\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "\n",
    "# start virtual display\n",
    "d3rlpy.notebook_utils.start_virtual_display()\n",
    "\n",
    "env_video = create_env(env_key, max_episode_steps=200, is_video=True, isPartialObs=True, isFullyObs=False)\n",
    "\n",
    "env_video = RecordVideo(env_video, './videos/video-doorkey-dt-d3rlpy')\n",
    "\n",
    "seed = 0\n",
    "\n",
    "\n",
    "# wrap as stateful actor for interaction\n",
    "actor = dt.as_stateful_wrapper(\n",
    "    target_return=1,\n",
    "    action_sampler=d3rlpy.algos.SoftmaxTransformerActionSampler(temperature=1.0,)\n",
    ")\n",
    "\n",
    "done = False\n",
    "\n",
    "actor.reset()\n",
    "observation, reward = env_video.reset(seed=seed)\n",
    "\n",
    "while True:\n",
    "\n",
    "    action = actor.predict(observation, 1) \n",
    "\n",
    "    observation, reward, done, truncated, _ = env_video.step(action)\n",
    "\n",
    "    if done:\n",
    "        print(\"reward:\", reward)\n",
    "        print(\"DONE!!!\")\n",
    "        break\n",
    "    elif truncated:\n",
    "        print(\"Truncated\")\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "\n",
    "d3rlpy.notebook_utils.render_video(\"./videos/video-doorkey-dt-d3rlpy/rl-video-episode-0.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.save_model('./models/model_door-key-dt-16x16-128-d3rlpy.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the DT trained agent comparing it with the DQN agent. We can see that the DT agent is better than the DQN agent. The DT agent solves the environment more often than the DQN agent. The most important think to see is that the DT agent is able to solve the environment with a partial observation, and without rewarding the agent for picking up the key or opening the door. The DT agent is able to solve the environment only with the reward of reaching the goal. Moreover, the DT agent is able to solve the environment only with the data generated by the DQN agent. The DT agent is able to learn from the data generated by the DQN agent. And the result are an agent better than his \"teacher\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to compare the performance of DQN and DT\n",
    "\n",
    "trials = 100\n",
    "\n",
    "def evaluate_policy(env, actor, explorer=None, n_trials=10):\n",
    "\n",
    "    success = 0\n",
    "    for _ in tqdm(range(n_trials)):\n",
    "        \n",
    "        if (explorer is  None):\n",
    "            actor.reset()\n",
    "        obs,_ = env.reset()\n",
    "\n",
    "        done, truncated = False, False\n",
    "        while not (done or truncated):\n",
    "            if explorer is not None:\n",
    "                x = np.expand_dims(obs, axis=0)\n",
    "                action = explorer.sample(actor, x, 0)[0]\n",
    "            else:\n",
    "                action = actor.predict(obs, 1)\n",
    "            obs, reward, done, truncated, _ = env.step(action)\n",
    "            if done and reward > 0:\n",
    "                success += 1\n",
    "    return success / n_trials\n",
    "\n",
    "env_dqn = create_env(env_key, max_episode_steps=config[\"max_episode_steps\"], isPartialObs=False, isFullyObs=True)\n",
    "env_dt = create_env(env_key, max_episode_steps=config[\"max_episode_steps\"], isPartialObs=True, isFullyObs=False)\n",
    "\n",
    "dqn.build_with_env(env_dqn)\n",
    "dqn.load_model('./models/model_door-key-dqn-16x16.pt')\n",
    "\n",
    "#dt.build_with_env(env_dt)\n",
    "#dt.load_model('./models/model_door-key-dt-16x16-128-d3rlpy.pt')\n",
    "\n",
    "explorer_dqn = d3rlpy.algos.ConstantEpsilonGreedy(epsilon=config[\"epsilon\"])\n",
    "\n",
    "actor_dt = dt.as_stateful_wrapper(\n",
    "    target_return=1,\n",
    "    action_sampler=d3rlpy.algos.SoftmaxTransformerActionSampler(temperature=1.0,)\n",
    ")\n",
    "\n",
    "dqn_score = evaluate_policy(env_dqn, dqn, explorer=explorer_dqn, n_trials=trials)\n",
    "dt_score = evaluate_policy(env_dt, actor_dt, n_trials=trials)\n",
    "\n",
    "print(\"DQN score:\", dqn_score)\n",
    "print(\"DT score:\", dt_score)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a bar plot with the rewards of the DQN agent and the DT agent. We can see that the DT agent is able to solve the environment more often than the DQN agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will make a bar chart to compare the performance of DQN and DT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['DQN', 'DT']\n",
    "scores = [dqn_score, dt_score]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "rects1 = ax.bar(x - width/2, scores, width, label='Scores')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by DQN and DT')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision-transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
